\section{Automatically finding bugs}

\subsection{Detecting race bugs with dynamic analysis}

There have been a large number of dynamic program analysis techniques
intended to detect races.  There are three basic approaches here:

\begin{itemize}
\item Lock sets.
\item Happens-before vector clocks.
\item Schedule perturbation.
\end{itemize}

Lock set based systems are the simplest to describe.  In this model,
originally suggested in Eraser~\cite{Savage1997}, the tool maintains,
for each memory location, a set of locks which might possibly protect
that location.  Whenever a thread accesses a memory location, the set
of locks held by the thread at the time is intersected into the set of
locks associated with the field, and an error reported if the
location's lock set becomes empty.  This behaves reasonably for the
most common type of program synchronisation schema, in which each
source-level field or compound structure is protected by some lock,
and where the most common type of bug is simply forgetting to acquire
the necessary locks.  On the other hand, this kind of approach
requires extensive special cases to handle other concurrency
protocols.  A common example of such a protocol is structure
ownership: a given structure is ``owned'' by a particular thread,
which can access the structure without acquiring any locks while other
threads can only access the structure by first acquiring ownership of
it\editorial{It'd be nice to have a cite for that.  Maybe one of the
  RCU papers has something?}.  This is perfectly safe (provided that
ownership transfer is implemented correctly), but leaves most fields
in most structures with empty lock sets.  Extending lock-set based
schemes to handle these other protocols generally requires a large
number of special cases\editorial{Cite some papers which do just
  that.}.

Happens-before vector clocks are another approach to this problem.
These tools rely on a happens-before graph showing the order in which
program operations are ``supposed'' to happen and then flag a warning
whenever the order of two operations is undefined by this graph and
important, in some sense, for the program's execution.  Maintaining
the happens-before graph is itself an moderately complicated
operation.  The simplest approach starts from the assumption that a
complete trace of all of the program's memory accesses is available
and then uses a variant of Lamport's vector clock algorithm\needCite{}
to extract a minimal set of happens-before edges which completely
characterises the order of operations.  If this minimal graph contains
any un-approved edges then a warning is raised\editorial{I could
  describe the VC algorithm itself here, but it has an annoying number
  of special cases and it doesn't really add anything.}.  Recent tools
of this form include RaceTrack\needCite{} and FastTrack\needCite{};
Netzer and Miller 1989 is an earlier example.  These tools are
generally quite effective at finding places in the program's execution
where behaviour depends on the details of the interleaving chosen by
the hardware, and this does include most concurrency bugs.  However,
it also includes a large number of points in the program's execution
which are not bugs.  Most obviously, the races inherent in the
implementation of synchronisation primitives will be detected by these
methods.  This means that practical tools must in some sense
white-list types of edges which are believed to be safe, and missing
some edges generally leads to an excessive number of false positives.
Some tools maintain this whitelist explicitly\needCite{}; others, such
as FastTrack, leave it implicit in the structure of the
implementation.  More fundamentally, simply noticing that permuting
two operations affects their local behaviour does not imply that doing
so will affect the program's global behaviour, and so there will
always be a certain number of false positives with this kind of tool.

These tools may also occasionally suffer from false negatives.  To see
this, notice that, if the edges related to lock operations have
themselves been whitelisted, inserting the sequence ``unlock($x$);
lock($x$)'' into a point in the program where lock $x$ is held can
never cause additional warnings to be generated, but can cause
additional bugs to be introduced.  The underlying algorithm can detect
the additional race on the lock structure itself, but, because it
cannot look at the larger context in which the accesses take place,
cannot determine whether it is safe, and so the tool is forced to use
potentially error-prone heuristics.

DataCollider\needCite{} takes a completely different approach, and one
which is conceptually more similar to SLI's.  Rather than trying to
find races directly, it instead inserts delays into the program's
execution so as to make races more likely, detects them when they
occur, and then potentially flips the order of the race so as to
determine how dangerous that race is.  This approach has a number of
important advantages: it has no false positives (any race reported
will definitely have happened); races can be easily ranked by order of
importance (as the tool can easily cause the other ordering of the
race to occur, and hence determine how dangerous the race really is);
and it has reasonably low overhead (so the program's behaviour during
analysis is likely to be at least broadly similar to that during
normal execution).  I have already described the algorithm in detail
in sections \editorial{Background} and \editorial{Evaluation}, and so
do not do so here.  The bug finding technique described here can in
some ways be regarded as a refinement of DataCollider, using static
analysis to determine more precisely where delays can most profitably
be inserted, hence increasing the likelihood of finding errors whilst
simultaneously reducing the overhead of doing so.

Chess\needCite{} can be thought of as a more systematic approach to
the same idea: rather than inserting delays at randomly selected
points in order to perturb the schedule, Chess systematically
enumerates all possible program schedules.  It can then flag errors
when some schedules exhibit interesting bugs.  This allows Chess to
reproduce a wide variety of bugs quickly and easily.  Chess makes two
major approximations in order to get good results.  The first is the
use of bounded preemptions: Chess only considers schedules with up to
$k$ preemptions, where $k$ is some constant (by default, two).  Bugs
which require more complex schedules cannot be reproduced.  The second
is an unsafe handling of memory-mediated thread interactions: Chess
performs an initial run of the program under a dynamic data race
detector and then assumes that only accesses flagged in that run will
ever suffer data races.  This means that it can sometimes miss
interesting instruction interleavings if instructions race in some
schedules and not others.  Despite this, Chess has been demonstrated
to be an effective way of detecting many interesting bugs in
real-world programs.

\subsection{Detecting race bugs with static analysis}

In addition to these dynamic tools, there have also been a number of
attempts to detect race bugs statically.  The most famous is probably
RacerX\needCite{}.  This tool is essentially a static version of the
dynamic lockset algorithm discussed earlier.  An initial static
analysis determines, for every line in the program, which locks are
held when that line executes.  The tool can then use this to determine
which locks protect each field in a compound structure and then flag
an error if this set is empty\footnote{The actual implementation
  includes a number of additional techniques to reduce false
  positives.}.  The aliasing model used here is very simple, assuming
that there is precisely one instance of every data type.

Relay\editorial{Cite Voung Jhala and Lerner, 2007} attempted to
improve the soundness of RacerX while also improving its scalability.
Key technique is a form of procedure summarisation using symbolic
execution to find out which fields a given function might access and
what it does to the current lockset.

Chord\editorial{Cite Naik Aiken and Whaley, 2006} takes a slightly
different approach, attempting to statically detect pairs of racing
accesses without first inferring the locks which are intended to
protect each field.  Their implementation is for Java, and depends to
some extent on Java's type safety properties, but it would probably
not be excessively difficult to generalise to non-typesafe languages
such as C, at the cost of some precision.  The approach taken here is
essentially to build up an instruction aliasing table, containing the
same information as SLI's but built statically rather than
dynamically, and to then use further static analysis to refine this
table until it only contains entries for instructions which both alias
and race.  These are then reported as potential errors.  It would
potentially be interesting to use these techniques to refine SLI's
aliasing table, which might help to improve performance somewhat,
although generalising them from source-level to binary-level might
prove challenging.



\begin{itemize}
\item
  TESLA?
\item
  Quite a lot of other papers on using runtime monitors for non-concurrency properties.
  Chain refs from ``Partially evaluating finite-state runtime monitors ahead of time'', Bodden, Lam, and Hendren, 2012.
\end{itemize}

\subsection{Other types of bugs}

Not sure about this; there are lots of them and most of them aren't
all that related, but I probably ought to say something.

KLEE is probably the best thing to talk about here.

\section{Automatically characterising bugs}

IGOR is the oldest reference here.  Schedule memoisation and delta
debugging would also be worth talking about.  

\section{Automatically fixing bugs}

There have, of course, been many previous systems which aimed to
automatically fix bugs in programs, and I now give a brief overview of
some of the more important ones.

\subsection{Description of meta-problem}

The meta-problem here is to transform a program into another program,
preserving some properties whilst introducing others.  This is
problematic at the best of times (see: basically all of the theory
underlying compiler design), but in this case we have the particular
difficulty that some or all of the properties will be underspecified
or completely unknown.  This makes the problem, in principle,
impossible to solve, and also impossible to evaluate: given a proposed
auto-fixing transformation, a program to apply it to, and an
arbitrarily intelligent assistant, it is still impossible to tell
whether the transformation was successful.  This is a
challenge.\todo{Rewrite para.}

One potential approach is to consider auto-fixers as being
transformations on the semantics against which the program is written,
rather than as transformations of the program itself.  Whenever a
programmer writes a program, they will have some (usually quite
informal) model of the semantics of the underlying hardware, operating
system, language, etc., and they will have designed their program
against that semantic model.  This semantic model is extremely
unlikely to be exactly the same as the semantics which is actually
implemented by any physical computer (if nothing else, the physical
semantics differ markedly across computers, and most programs are
designed to run on more than one system), and that semantic gap gives
us some room to manoeuvre.  In particular, the programmer's semantic
model will usually leave some parts unspecified, and hence map to a
large set of physical semantics such that any property which is
guaranteed by the programmer's model will be guaranteed by any of the
physical semantics.  This means that we can safely select any physical
semantics from this set, secure in the knowledge that doing so will
preserve whatever correctness the original program might have had, and
it is this flexibility which potentially allows us to fix or mask
errors.

Of course, this does not solve the problem, because we have no way of
knowing what semantics the original programmer had in mind when
writing the program.  We can make some intelligent guesses, however:

\begin{itemize}
\item Some parts of the physical semantics will differ from run to
  run.  One obvious example is the exact memory interleaving when two
  processors run in parallel.  Assuming the program is intended to
  work every time it runs, it is reasonable to assume that the
  programmer's semantics leave this behaviour undefined, and so
  it is safe for the auto-fix tool to change it.

\item Likewise, language specifications and processor architecture
  manuals also often leave certain boundary cases unspecified,
  e.g. the effect of a use-after-free in C\cite{Kernighan1988}.  While
  it is possible for a program to depend on this unspecified
  behaviour, it is usually considered to be poor software engineering
  practise\cite{CWE758}, and so it is often safe to assume that it
  remains unspecified in the programmer's semantic model.

\item Sometimes, an operation is perfectly well defined, but indicates
  an error sufficiently often that we are willing to assume that it
  does so every time, and hence that it is safe to change its meaning.
  For instance, one might reasonably require that a program never
  produces a core dump, and hence allow the meaning of any operation
  which would normally produce a dump to be changed.

\item Many systems leave the exact circumstances under which certain
  components fail undefined, and hence allow us to inject artificial
  errors safely.

\item More controversially, it would be possible to introduce a kind
  of extra memory or hysteresis into the program, such that once it
  has been observed to behave in a certain way a certain number of
  times, it is forced to keep behaving in that way from then on.  For
  instance, if a particular variable is found to be between five and
  ten in every training run, and is then found to be twelve in a
  subsequent one, it could be forcibly changed back to ten.  It is
  hard to imagine any programmer ever using this as their semantic
  model of the hardware, but it might sometimes capture part of their
  model of the program, and hence allow ``sympathetic'' fixes.

\end{itemize}

In order to make a useful bug-healing system, it is generally
necessary to change the semantics in two ways.  First, there must be
some indication that something has gone wrong: in the physical
semantics, every operation has a defined result, and so there is no
way to tell whether a given operation was desired, and so no way of
triggering the automatic healing process.  This issue can be avoided
by declaring certain actions to be bad, so that we can assume that any
such action is considered to be a failure\footnote{Note that it is
  also possible to design always-on systems, which try to fix or
  ameliorate bugs in general without caring about any \emph{specific}
  instance, and in that case no trigger is needed.}.  Second, we must
unconstrain the semantics enough to give us the necessary flexibility
to avoid the bad actions.  The choice of these two changes is one of
the most critical aspects of a program auto-fix system.  In many
cases, they can be changed independently of one another.

Interestingly, the new semantics is not always required to be causal.
It may, in some cases, be useful to respond to an error by rolling
back to an earlier checkpoint and taking a slightly different path.
From the point of view of the program, the error influenced the
behaviour at the checkpoint, even though the error happened strictly
after the checkpoint, and hence, from the program's perspective, this
is a non-causal semantics\footnote{Causality is, of course, maintained
  from the perspective of the auto-fixer itself, and so the semantics
  is paradox-free and implementable.}.

\subsection{Software rejuvenation and micro-reboots}

One of the earliest attempts at fault remediation was software
rejuvenation\cite{Huang1995}, which attempted to ameliorate the
effects of resource leaks by periodically rebooting the affected
systems.  This spawned a surprising amount of work on calculating the
optimum reboot schedule
\cite{Li2002,Vaidyanathan1999,Vaidyanathan2001,Trivedi2000,Garg1998,Garg1995,Garg1998a,Castelli2001}
and, somewhat more usefully, some attempts at reducing the cost of
reboots \cite{Candea2002,Candea2001,Candea,Patterson2002}.  While
historically interesting, these are unlikely to be applicable to the
current problem, and so are not discussed further here.

\subsection{Failure obliviousness and related techniques}
More recently, Rinard et al\cite{Rinard2004} described failure
obliviousness, a technique for disguising certain classes of memory
faults in high-availability systems at the (possible) expense of
reduced integrity.  The core idea here is, essentially, to treat
hardware exceptions as warnings rather than errors, and to try to
execute through them as far as possible in the hope that the error
will self-cleanse rather than propagating further.  Some faults are
trivial to ignore (e.g. a wild write, which can just be ignored),
while others require more sophistication e.g. following a wild read,
the value read must be invented somehow.  The original paper simply
used a manually pre-defined sequence of plausible values; later work
expanded upon this by looking at the dynamic dataflow
context\cite{Nagarajan2009} or by using a lookaside table of recently
discarded writes\cite{Rinard2005a}.  There might be some scope for
using static analysis to find more useful values to return, but, given
how well simpler techniques appear to work, I suspect this scope would
be limited.

The reactive immune system\cite{Sidiroglou2005} starts from a similar
conceptual basis, but more explicitly tries to trigger existing error
handling code, in the hope that this will help the protected program
reconverge more quickly.  The initial implementation did this by
forcing functions to return immediately with an error value, obtained
by type analysis on the source code; this was refined in the ASSURE
system\cite{Sidiroglou2005} to instead take snapshots at places where
it is convenient to inject errors and then roll back when an error is
detected.  Of course, error handling is often rather buggy itself, and
so recovery to error handling is not always useful.  This issue was
investigated in detail by S\"{u}\ss{}kraut et al.\cite{Susskraut2006},
who also propose some techniques for automatically improving its
robustness.

One potentially interesting approach, proposed by Elkarablieh et
al.\cite{Elkarablieh2007} in a slightly different context, would be to
try to mine the program for information about the intended contents of
data structures.  This would then provide useful information when
deciding how to synthesise the results of wild reads so as to minimise
the potential for error propagation, or even, in a somewhat extreme
form, to proactively fix data structures which have suffered
corruption.  This potentially increases the effectiveness of error
hiding, but also potentially increases the potential for the program
to generate completely nonsense results.  In the original paper, these
data structure invariants were obtained from \verb|assert()|-like
statements in the program source, combined with some basic static
analysis.  A later version, proposed by Malik et al.\cite{Malik}, used
Daikon\cite{Ernst2007}-like detection of statistically justified
invariants during normal program operation, which allowed the
technique to be applied without source code, but is also utterly
terrifying\editorial{phraseology}.  ClearView\cite{Perkins} refines
this approach by combining it with an automated testing system to try
to reduce the risk of introducing new bugs.

DieHard\cite{Berger2006} is another application of the failure
oblivious concept to heap-related issues.  In this system, however, no
attempt is made to discover or to enforce data structure invariants;
instead, the heap is structured so as to minimise the probability of
certain common types of bugs causing user-visible errors.  The authors
use two main techniques to achieve this:

\begin{itemize}
\item First, the heap is expanded, such that there are likely to be
  large dead zones between any two allocations.  This makes buffer
  overflows much less dangerous.
\item Second, they avoid reusing heap locations quickly after they
  have been \verb|free()|d, which reduces the risk of use-after-free
  bugs actually causing problems.
\end{itemize}

Neither of these techniques will eliminate bugs, but they can
dramatically reduce the probability of their causing user-visible
problems (at the expense of dramatically increasing memory
requirements and marginally increasing runtimes).
Exterminator\cite{Novark2007} further builds on this work by using
heuristics on the expanded heap to try to identify probably bugs, and
then modifying the allocator to only apply heap expansion to
allocations which are likely to benefit from it.  Assuming that all
such allocations are detected, this retains all of the bug-fixing
benefits of DieHard while noticeably reducing its overhead (at least
in the common case where only a small number of allocations actually
need padding).

The AutoPaG system\cite{Lin2007} tackled a related problem, that of
overflows of stack-based buffers.  In this work, the authors assume
that a buffer overflow has already been identified by some mechanism
(a CCured\cite{Necula2005}-like safe compiler in the paper, but others
are possible), and then apply static analysis to find its root cause
at the source code level.  They then generate a source-level patch
which redirects any out-of-bounds accesses to the array back to a safe
location, in what is essentially a variant of failure obliviousness.
This allows them to mask the bug until a true fix can be obtained,
with very low run-time overhead in both time and space.
Unfortunately, their static analysis is not complete, and so they
must occasionally fall back to a dynamic scheme.

\subsection{Hardware-based fixes for data races}
Of course, memory errors are only one class of bugs.  Synchronisation
errors form another important class, and a number of projects have
investigated remediation strategies for these.  One of the earliest
was ReEnact\cite{Prvulovic2003a}, which used modified thread-level
speculation hardware to capture precisely what happened during a data
race or atomicity violation, and then to control instruction
scheduling during subsequent re-executions so as to avoid the bug in
future.  This is similar to the intent of the fixes generated by SLI,
with a few exceptions:

\begin{itemize}
\item The ReEnact scheme requires unusual hardware support, whereas
  SLI is purely software-based.
\item Their fixes are dynamic, in the sense that the program must be
  constantly monitored to ensure it does not follow a bad schedule,
  whereas the SLI fixes statically introduce required locking so that
  bad schedules become impossible.
\item They require some (quite modest) amount of programmer
  involvement in order to identify which races are critical to a
  particular bug and hence to direct the fixing process, except in a
  few unusual special cases.  SLI will, hopefully, be able to generate
  fixes entirely automatically.
\end{itemize}

Despite these limitations, ReEnact was able to fix some bugs, and
shows reasonably low run-time overhead (mostly on the order of ten
percent, depending on the benchmark).

Atom-Aid\cite{Lucia2009} is another scheme which tries to use unusual
hardware features to protect against data race and atomicity violation
bugs, but Atom-Aid using hardware transactional memory rather than
thread-level speculation.  This paper grew out of an earlier
observation that, in some cases, processor performance can be improved
by bundling sequences of memory accesses into transactions, and hence
batching interconnect operations and amortising their
costs\cite{Ceze2007}.  This has the interesting side effect of
eliminating a large number potential instruction interleavings, and
hence a large number of potential synchronisation bugs.  Atom-Aid
attempts to maximise this effect by carefully tweaking transaction
boundaries in response to the program's observed behaviour.  This
allows them to hide most atomicity violations with very low
overhead\footnote{The paper asserts that they have negligible
  overhead, but does not attempt to quantify or justify that
  statement, and so the true overhead is rather difficult to
  evaluate.}.  Unfortunately, the necessary hardware changes are
unlikely to be widely deployed in the near future, and it is hard to
see how to adapt the system into a software-only implementation, which
makes these techniques somewhat less interesting.

\subsection{Software-based fixes for data races}
ConTest\cite{Krena2007} provides one of the simplest approaches to
fixing data races using software rather than hardware.  In this work,
races are detected using the ERASER\cite{Savage1997} algorithm, and an
implicit assumption is made that all data races are bugs which need to
be eliminated.  Elimination is performed using a small number of
pre-defined synchronisation patterns\footnote{In the paper, the only
  race pattern considered is wrapping a load followed by a store in a
  lock, but others could be added easily.}.  It is unclear from the
paper whether this is actually a useful thing to do, because the
majority of races are benign, and the majority which are not are more
complicated than their patterns can describe.  Tallam et
al.\cite{Tallam2008} suggested essentially the same mechanism a year
later, but restricted themselves to uniprocessor execution (so the
only parallelism is the coarse-grained variant provided by the
operating system's thread abstraction); this allowed them to make some
simplifications to their implementation, but further reduced the
useful scope of the technique.

ToleRace\cite{Kirovski2007}, which attempts to provide toleration for
asymmetric races, provides another useful point in the design space.
An asymmetric race is defined by the authors to be a situation where
some thread correctly follows a locking discipline (which must be
manually specified by the programmer), but another thread does not,
and thus causes the correct thread to fail.  This presents a challenge
when debugging, as most na\"{i}ve approaches to postmortem analysis
will blame the wrong thread for the crash.  ToleRace ameliorates this
class of problems by arranging that when a thread acquires a
particular lock, a local snapshot of all of the values protected by
the lock is taken, with any accesses to protected variables made while
holding the lock redirected to the snapshot.  This prevents the
correct thread from seeing the effects of incorrect threads while it
is in the critical section, which makes the race much less likely to
cause serious problems, but does not guarantee to produce a consistent
snapshot of the protected data.  ISOLATOR\cite{Ramalingam2009} fixes
this defect by introducing implicit per-page locks, which are enforced
using virtual memory techniques.  However, it is still necessary for
the programmer to provide a manually-specified lock discipline, which
makes these techniques difficult to use in practise.

\subsection{Deadlock bugs}
The final class of bugs considered here is deadlocks.  Techniques for
healing deadlocks in multithreaded applications have only been
investigated relatively recently (deadlock avoidance has been studied
in other contexts for much longer; see e.g. \cite{Viswanadham1990} or
\cite{Dijkstra2004}).  One of the earliest, proposed by Nir-Buchbinder
et al.\cite{Nir-Buchbinder2008}, was to build the dynamic lock graph
as the program runs, discover any strongly-connected components
(SCCs), and then reducing every SCC to a single lock.  This eliminates
the potential for any lock order reversal deadlock involving that
cluster of locks, and would, if a complete lock graph were available,
it would completely eliminate all LOR deadlocks in the program.
Unfortunately, dynamically collected lock graphs are inherently
potentially incomplete, and this means that the healing is incomplete,
and can in fact introduce new deadlocks in certain situations.  The
need to potentially combine large sets of locks into a single large
lock can also lead to excessive serialisation, and hence poor
performance.

Gadara\cite{Wang2008} tackled both of these problems.  First, they
used static analysis to build a conservative approximation of the lock
graph (rather than the optimistic one produced by a dynamic analysis).
Second, they use discrete control theory to derive a ``controller''
which inserts delays in the dynamic program execution in some minimal
set of places so as to avoid deadlocks without introducing unnecessary
serialisation.  Of course, the use of a conservative approximation
means that they will occasionally detect a deadlock where none is
actually possible, and this will lead to additional synchronisation
operations; it is unclear from the paper whether Gadara-protected
systems are more or less serialised than Nir-Buchbinder-protected
ones.  At a high-level this controller is conceptually similar to the
message-passing machines used in SLI's crash enforcers, although the
details and purpose of the technique are significantly different.

It is also possible to make progress on these problems in a purely
dynamic system.  For instance, Dimmunix\cite{Jula2008} waits until a
deadlock is observed at run time, then captures a signature for that
particular deadlock, and arranges that the signature never reappears
by delaying lock acquire operations.  The hope is that preventing the
signature will also prevent the deadlock, and hence that the program
will, over time, become immune to whatever deadlocks might be lurking
in it.  Because it only fix deadlocks which have actually been
observed, serialisation is kept low and the need for complete locking
information is side-stepped, although at the cost of having to suffer
every deadlock at least once in order to fix it.

Of course, this approach will only be successful if the deadlock
signatures accurately capture the cause of the deadlock, without
capturing too much extraneous information.  The suggestion in the
paper is to use the set of locks held by every thread, combined with a
(slightly summarised) backtrace captured when the lock was acquired.
Earlier versions of the paper (e.g. \cite{Jula2008b}) mentioned
alternative schemes; I assume the fact that the discussion was dropped
implies that the alternatives were investigated and found to be
unhelpful.  That would be consistent with the rest of the evaluation.


\subsection{Concurrency bugs}

\begin{itemize}
\item Maybe mention HEALERS here?
\item AtomRace
\item MUVI
\item AVIO
\item RX
\item Assure
\item Aviso
\end{itemize}

\subsection{Other bugs}

\begin{itemize}
\item SOAP
\end{itemize}

\section{Other program analysis things}

\begin{itemize}
\item Balakrishnan has a bunch of papers on this.  WYSINWYX is the big
  one.  Also talk about CodeSurfer.
\item Jakstab is probably worth a few sentences.  Maybe even talk
  about IDA Pro for a bit as well?
\item BAP -- binary analysis platform.
\item Stanford Java Checker, maybe?  It's done on Java bytecode rather
  than machine code, but it's the same sort of idea.
\item Maybe mention KLEE again here.
\item Quick overview of a couple of model checking-type systems here.
\end{itemize}

\section{Other stuff}

\begin{itemize}
\item Data structure invariant inference: DAIKON, DIDUCE
\item I desperately need to go and mine the compilers literature to
  figure out how novel the various simplification steps are.
\item
  Joisher, Schieder, et al, On a technique for transparently empowering classical compiler optimizations on multithreaded code, 2012.
\item
  Something about separation logic?
\item
  Synchronisation removal: Choi et al, Escape analysis for Java, 1999; Ruf 2000.
\item
  Procedural concurrency graph: Joisher, Schieder, et al, On a technique for transparently empowering classical compiler optimizations on multithreaded code, 2012.
\item
  Something on parallel execution graphs and may-happen-in-parallel e.g. Li and Verbrugge 2004, A practical MHP information analysis for concurrent Java programs
\item
  Thread escape analysis: Choi et al, Escape analysis for Java, 1999.
\item
  Have a look at Chugh et al, 2008, RADAR.  Dataflow analysis for concurrent programs using datarace detection.
\end{itemize}

\subsection{Deterministic replay}

Deterministic replay of concurrent shared memory programs has been
investigated for a long time.  Traditional systems rely on recording
every nondeterministic event in the program's execution (see, for
instance, \cite{LeBlanc1987} or \cite{Dunlap2002}), which potentially
has very high overhead.  This high overhead made the technique
difficult to apply in production environments.  Some recent work has
demonstrated that it is not always necessary to record all of this
information, which allows overheads to be significantly reduced.

\begin{itemize}
\item ODR
\item PRES
\item ESD
\end{itemize}

\input{related_work/summary}

Verification condition bits:

\begin{itemize}
\item
  Dijkstra's weakest precondition thing.
\item
  Jager and Brumley, Efficient directionless weakest preconditions, 2010.
\item
  Find some simple SMT solvers and see if they actually win anything over just using the SLI sat checker.
  e.g. CVC3, Yices.
\end{itemize}
