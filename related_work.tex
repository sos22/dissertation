\chapter{Related work}
\label{chapter:related_work}

Previous chapters have described the {\technique} technique and
{\implementation}, my implementation of it, explaining how it should
work and showing that it does.  This chapter places {\technique} in
context by comparing it to related existing systems, discussing ways
in which {\technique} improves or complements prior work in the area.

\section{Automatically finding bugs}

Automatically detecting and characterising bugs in programs has been
an active area of research for many years.  Some of the more important
and relevant are summarised in \autoref{fig:rw:find_char}; the rest of
the section describes them in more detail.

\begin{sidewaysfigure}
  \begin{figgure}
  \begin{tabular}{l>{\RaggedRight\arraybackslash}p{5.5cm}lp{10.3cm}}
    Technique family           & Type of error discovered                     & Static/dynamic  & Example systems \\
    \hline
    Locksets                   & Locking protocol violations                  & Static          & RacerX~\cite{Engler2003},RELAY~\cite{Voung2007} \\
                               &                                              & Dynamic         & Eraser~\cite{Savage1997} \\
    \hgreyline
    Happens-before             & Memory races                                 & Dynamic         & RaceTrack~\cite{Yu2005}, FastTrack~\cite{Flanagan2009}, Netzer~\cite{Netzer1991} \\
    \hgreyline
    Concurrent aliasing        & Memory races                                 & Static          & Chord~\cite{Naik2006} \\
    \hgreyline
    Schedule perturbation      & Timing dependencies                          & Dynamic         & DataCollider~\cite{Erickson2010}, AtomRace~\cite{FFFLetko2008}, CTrigger~\cite{Zhou} \\
                               &                                              & Hybrid          & Chess~\cite{Musuvathi2008} \\
    \hgreyline
    Stereotyping               & Anomalous behaviour                          & Dynamic         & Anomaly-based IDSes~\cite{Forrest1996a}, Pu and Wei~\cite{Pu2006}, HeapMD~\cite{Chilimbi2006}, DIDUCE~\cite{Hangal2002}, MUVI~\cite{Lu2007} \\
                               &                                              & Static          & Bugs as deviant behaviours~\cite{Engler2001}\\
    \hgreyline
    Extended assertions        & \multirow{2}{*}{\parbox{5.5cm}{Violations of programmer-identified properties}} & Dynamic        & TESLA~\cite{FFFLocielski2011,FFFWatson2013}, Uppuluri et al.~\cite{Uppuluri2005} \\
                               &                                              & Static          & Meta-compilation~\cite{Engler2000a}\\
    \hgreyline
    Typestate systems          & \multirow{2}{*}{\parbox{5.5cm}{\raggedright Object access protocol sequencing violations}} & Dynamic & Gradual typestates~\cite{FFFWolff2011}, 2ndStrike~\cite{Gao2011} \\
                               &                                                                             & Static  & Plaid~\cite{Sunshine2011}\\
                               &                                                                             & Hybrid  & Clara~\cite{FFFBodden2010}\\
    \hgreyline
    Symbolic execution         & Most forms of bugs                           & Static          & SLAM~\cite{Ball2011}, KLEE~\cite{Cadar}, JPF~\cite{Havelund2000} \\
                               & Most forms of bugs                           & Hybrid          & S2E~\cite{Chipounov2011} \\
                               & Memory management errors                     & Static          & SLAyer~\cite{Berdine2011} \\
                               & Infinite loops                               & Static          & Terminator~\cite{Cook2006a} \\
  \end{tabular}
  \caption{Summary of some existing bug detection techniques.}
  \label{fig:rw:find_char}
  \end{figgure}
\end{sidewaysfigure}

\subsection{Lockset analysis}

When software developers design concurrent software, they usually have
a plan for avoiding concurrency errors, and this plan is usually
expressed as a concurrency protocol defining the acceptable forms of
concurrency and the actions which the program must take to ensure that
only those forms are possible.  These protocols can take many
differing forms, reflecting the differing desired behaviour of the
programs for which they are designed, but the majority have at their
core a simple lock discipline which associates locks with program
structures and requires the program hold the lock when operating on
the structure.  Lockset-type tools detect concurrency errors by
inferring this lock discipline and then flagging an error whenever the
program violates it.

Eraser~\cite{Savage1997} was the earliest tool of this form.  It is a
dynamic analysis which observes the running program's lock and memory
operations so as to build a mapping from memory locations to the set
of locks which might conceivably protect them.  A location's lock set
initially contains every lock in the program and is intersected with
the set of currently-held locks whenever a thread accesses the
location.  If the set ever becomes empty then there is no locking
discipline which is compatible with the program's behaviour, and so
the tool flags a potential concurrency error.\kern-.5pt\fnote{There is a
  similarity here with {\technique}'s dynamic alias analysis
  (\autoref{sect:program_model}), in that both approaches justify
  their analysis with reference to the fields of high-level language
  structures but must perform the actual analysis on memory locations,
  and hence the two techniques make similar assumptions about memory
  type stability.}

Eraser is both sound and complete, in the sense that if it reports a
lock discipline violation there has definitely been such a violation,
and conversely if it reports no errors then there must exist a
discipline which is compatible with the observed behaviour.  These are
not, though, the properties most desired by most developers.  Very few
concurrency protocols consist entirely of a lock discipline, and so
following the lock discipline does not necessarily imply following the
(far more important) concurrency protocol.  It might, for instance, be
that the program contains some multi-access regions which must behave
atomically; a simple lock discipline can ensure that individual
accesses are protected, but cannot express this higher-level
requirement.  It is also possible to define correct concurrency
protocols which are incompatible with any lock discipline if, for
instance, the program uses any lock-free algorithms, and so violating
the lock discipline does not imply that the concurrency protocol has
also been violated.  In the sense which matters most, then, lockset
analysis is neither totally sound nor totally complete.  In practice,
though, it is usually sound enough and complete enough and this,
combined with its good performance, makes it a useful tool.

Lockset analysis can also be applied statically as in, for instance,
RacerX~\cite{Engler2003}.  In RacerX, an initial static analysis
determines, for every line in the program, which locks are held when
that line executes, and hence which locks protect each compound
structure field.  Any fields with an empty lock set are potentially
insufficiently synchronised and are reported as a potential error.  As
a lockset analysis, RacerX shares many of the same weaknesses as
Eraser (multi-access concurrency errors cannot be detected; lock-free
algorithms are always reported as errors) and, as a static analysis,
adds several more (complete program source must be available; program
behaviour is aggressively approximated).  Its chief advantage is that,
because it is a static analysis, it considers all possible program
behaviour, rather than just behaviour exhibited in one particular run,
making it easier to be confident in its results.

In order to scale its static analysis to very large software systems,
RacerX was forced to make several approximations.  The most important
is the use of a very simple aliasing model which assumes that there is
precisely one instance of every data type.  This greatly simplified
scaling the analysis to very large programs, but at the expense of
reducing its soundness.  RELAY~\cite{Voung2007} was one attempt to
alleviate this limitation.  The key technique used was to summarise
the program's procedures~\cite{Qadeer2004} using symbolic execution,
recording what locks each acquired and released and which structure
fields it accessed, allowing the tool to perform cross-function race
analysis without needing to consider the full body of each function
every time.  This provided useful improvements in both scalability and
soundness.

These techniques could be used to refine {\technique} in two main ways
of ways.  Most obviously, including a lockset table in the
\gls{programmodel} could potentially allow many of the false positive
\glspl{verificationcondition} to be eliminated far more easily,
simultaneously reducing both the cost of the analysis and the number
of bugs which must be checked at run time.  This would need to be done
with some care if the lockset table were derived dynamically (if the
end result is that {\technique} detects a bug only when Eraser does
then there would be little point in having both tools), but would be
relatively easy with the (more conservative) static tables built by
RacerX and RELAY.  Beyond that, there might also be some scope for
integrating RELAY-style procedure summaries into the {\technique}
analysis, both to automate the generation of library stubs
(\autoref{sect:derive:library_functions}) and, more interestingly, to
summarise frequently-used procedures within the program itself so as
to aid analysis of functions which call them.

\subsection{Happens-before}

Lockset analysis is most effective when the program's concurrency
protocol consists solely of a simple lock discipline, but, as
discussed above, most program's protocols are more complicated than
that.  There is a class of more powerful tools, such as
RaceTrack~\cite{Yu2005} or FastTrack~\cite{Flanagan2009}, which can
detect concurrency bugs whilst imposing far weaker requirements on the
structure of the program to be analysed.  At their core, these tools
consist of a mechanism to build a partial order of the program's
accesses to memory, determine which parts of that partial order might
affect the program's operation, and flag a potential error if the
program is dependent on an unsafe property of the ordering.  A tool
might, for instance, declare that a program is allowed to depend on
the order in which threads are granted a lock when they contend for it
but that it must not depend on the order of concurrent accesses to the
same memory location; such a tool would detect some kinds of data
races.  In principle, it is possible to do this by building the entire
happens-before graph~\cite{Netzer1991}, but for performance reasons
most practical tools model only the most relevant part of it using a
variant of Lamport's vector clock algorithm~\cite{Lamport1978}.

Ordering-based schemes can also be applied statically as in, for
instance, the Chord static race detector~\cite{Naik2006}.  At a high
level, Chord works by first building a model of the program's existing
synchronisation structure, in what they call the lock analysis phase,
and then performing a second analysis to determine when two memory
accesses in different threads might alias, in what they call the
escaping pairs computation.  The structure constructed by the lock
analysis phase describes the safe edges of a happens-before partial
ordering and the escaping pairs computation describes the unsafe ones.
Any unsafe edges which are not prevented by safe ones are reported as
potential program bugs.  There would be some scope for combining their
model of the program's safe edges into {\technique}'s
\gls{programmodel}, reducing the number of concurrent interleavings
which would have to be considered in the initial analysis phase and
hence the number of \glspl{verificationcondition} requiring runtime
verification, although converting between their source-level analysis
and {\technique}'s machine code-level one might be challenging.

\subsection{Schedule perturbation}

One reasonable definition of a concurrency bug is a bug whose
behaviour depends on the precise relative timing of parts of a program
which run concurrently.  That suggests an alternative scheme for
finding such bugs: simply alter the program's timing and see what
happens.  This is the approach taken by
DataCollider~\cite{Erickson2010}.  Rather than trying to find races
directly, it instead inserts delays into the program's execution so as
to make races more likely and detects them when they occur.  This
approach has a number of important advantages: it has no false
positives (any race reported will definitely have happened); it has
reasonably low overhead (so the program's behaviour during analysis is
likely to be at least broadly similar to that during normal
execution); and it requires relatively little in the way of supporting
machinery (so it can be used in constrained environments such as
kernel-mode drivers or embedded systems).  The parallels with
{\technique}'s \glspl{bugenforcer} are obvious.  The important
difference is that {\technique} makes use of an initial analysis phase
to discover the best places to insert delays, allowing it to reproduce
bugs far faster than DataCollider.

CTrigger~\cite{Zhou} is another variant of a similar idea.  The
approach taken in that work is to perform an initial static analysis
on a program so as to discover some potential atomicity violations and
to then construct alternative schedules which attempt to trigger those
violations, in the hope that some of them correspond to a bug.  This
is, again, rather similar to {\technique}'s \gls{bugenforcer}
mechanism.  There are several important differences between the two
techniques, though: CTrigger operates on the program's source, whereas
{\technique} operates on machine code; CTrigger considers only simple
two-variable atomicity violations, whereas {\technique} considers a
much broader class of atomicity violations; CTrigger aims to reproduce
atomicity violations, whereas {\technique} attempts to reproduce
actual bugs; and CTrigger reproduces simple instruction interleavings,
whereas {\technique} can reproduce complex data-dependent schedules.

Chess~\cite{Musuvathi2008} can be thought of as a more systematic
approach to the same idea.  Rather than inserting delays at randomly
selected points in order to perturb the schedule, Chess enumerates all
possible program schedules and flags any which exhibit interesting
behaviour, allowing it to reproduce a wide variety of bugs quickly and
easily.  Chess makes two major approximations in order to get good
results:
\begin{enumerate}
\item \emph{Bounded preemptions} Most concurrency bugs can be
  reproduced without requiring particularly complicated concurrent
  behaviour~\cite{Musuvathi2007}.  Chess takes advantage of this by
  limiting the number of times it switches between threads in any
  given run of the program, vastly reducing the number of program
  schedules which must be considered at the expense of failing to
  detect bugs which depend on more complex interleavings.  A similar
  idea could be added to {\technique}'s symbolic execution engine
  without much difficulty, although, as discussed in
  \autoref{sect:eval:complex_hb}, {\technique} is already able to
  handle relatively complicated graphs with little difficulty, and so
  the potential for improving performance by doing so is limited.
\item \emph{Race induction} Chess's main analysis considers only a
  single thread at a time and switches between threads at defined
  preemption points.  For race-free programs, the only preemption
  points needed are at synchronisation-related library functions such
  as \texttt{WaitForSingleObject} or \texttt{ReleaseMutex}, and these
  are easily identified.  For other programs, it is also necessary to
  consider switching threads whenever the program experiences a data
  race, and these are much less obvious in a running program.  Chess
  identifies racing accesses by applying a standard data race detector
  to the first few schedules it considers and then simply assuming
  that those schedules contained all of the program's possible data
  races.  This means that Chess will sometimes miss data-dependent
  races, and hence potentially miss some real bugs, but dramatically
  reduces the computational cost of the analysis.

  {\Technique} makes a similar but weaker assumption as part of its
  dynamic alias analysis: Chess assumes that two accesses can race if
  they are observed to race, whereas {\technique} assumes that they
  can race if they are observed to access the same memory location
  without an intervening call to a memory retyping instruction such as
  \texttt{free}.  This implies that {\technique} is less likely to
  fail to analyse a bug due to an incorrect induction, but is also
  largely responsible for {\technique}'s far weaker scalability to
  bugs which depend on complicated memory access patterns.
\end{enumerate}
Despite these approximations, Chess has been demonstrated to be
remarkably effective at reproducing interesting bugs in real-world
programs and that, combined with its good performance, makes it an
attractive tool for this kind of problem.

\subsection{Stereotyping}
\label{sect:rw:stereotyping}

All of the approaches discussed so far rely on some pre-defined notion
of what it means for a program to have a bug.  An alternative approach
is to simply define a bug to be anything which the program does
rarely.  Tools based on this idea start by building up a model of how
a stereotypical execution of the program behaves and then report any
deviation from the stereotype as a potential bug.  This is essentially
the same problem as is solved by anomaly detecting intrusion detection
systems~\cite{Forrest1996a}, and such systems can be regarded as a kind
of bug detector.  In practice, though, systems designed for detecting
intrusions are not usually well-suited to detecting bugs, as they tend
to operate at the wrong level of abstraction, and I do not consider
them in detail here.

Daikon~\cite{Ernst2007} is a particularly interesting approach to this
idea.  Their basic approach is to collect one or more traces of the
program while it is operating normally, recording the values of local
variables and function parameters at important points in the program's
execution, and to then mine these traces to find statistically
well-supported correlations between values.  These correlations are
converted into assertions and inserted into the program, and any which
fail reported as potential bugs.  The earlier DIDUCE~\cite{Hangal2002}
can be regarded as a kind of dual of Daikon: rather than trying to
find conditions which are true for all known executions, it starts
with a condition that nothing at all is possible and then weakens it
until it allows all of the known behaviour.  This tends to lead to
sharper inferred invariants, in the sense of allowing less behaviour,
and so DIDUCE tends to find more bugs but with a higher false-positive
rate.

The model-building parts of these tools could usefully be combined
with {\technique} so as to expand its \gls{programmodel}, potentially
giving useful improvements in both analysis performance and precision.
HeapMD~\cite{Chilimbi2006}, which uses this kind of method to build up
a model of the heap, would be particularly interesting to investigate
in this respect.  More simply, it might be possible to use techniques
similar to those deployed in Laika~\cite{Cozzie2008} to automatically
identify parts of the program which behave like memory allocators,
removing the one place in which {\technique} currently relies on
manual assistance.

These techniques can also be applied statically, as in, for example,
Engler's ``Bugs as deviant behaviour'' system~\cite{Engler2001}.  The
idea here is to perform a kind of statistical static analysis to
identify common patterns in a program's source code and to then flag a
warning whenever any of these patterns are violated.  It might be, for
instance, that a call to \texttt{spin\_lock} is almost always followed
by a call to \texttt{spin\_unlock}, so that the remaining calls to
\texttt{spin\_lock} are likely to be bugs.  Systems based on this
observation are able to discover interesting violations of
program-specific invariants without ever having to be told what those
invariants are.  MUVI~\cite{Lu2007}, which discovers rules related to
when variables are likely to be accessed together, is particularly
relevant in the context of concurrency bugs, as many atomicity
violation bugs will violate at least one of those rules.  Information
from such an analysis might be able to provide useful hints in
{\technique}'s symbolic execution phases, encouraging it to spend more
time on paths which are more likely to lead to interesting bugs and
less on those which are probably safe.

\subsection{Extended assertions}

All of the schemes discussed so far in this section are intended to
discover bugs automatically.  An alternative approach is to instead
make it easier for the programmer to find the errors themselves.  One
particularly attractive mechanism for doing so, originally proposed in
the \textit{metal} meta-compilation system~\cite{Engler2000a}, is to
allow developers to extend the compiler with domain-specific semantic
knowledge, allowing the compiler to generate relevant domain-specific
warnings.  It might be, for instance, that a developer knows that
calls to \texttt{lock} must always be followed by calls to
\texttt{unlock} within the same function.  Semantic constraints of
this form are easily identified when implementing \texttt{lock} and
\texttt{unlock} but are easily forgotten when using them, and so
having the compiler check them automatically can detect a useful
number of bugs for relatively little cost.

The TESLA project~\cite{FFFLocielski2011,FFFWatson2013} represents
another approach to this idea.  In the TESLA model, the programmer
provides an approximation of the desired state machine for some
fragment of the program, expressed as a formula in a linear-time
temporal logic.  This is then compiled into a co-program which runs
alongside the program and checks that it conforms to this state
machine.  There are close parallels here with {\technique}'s
\glspl{bugenforcer}.  It would be interesting to combine the two
approaches by, for instance, using TESLA assertions as input to the
\gls{bugenforcer} building algorithm, rather than trying to infer them
directly from the binary; doing so would simultaneously alleviate
{\technique}'s greatest weakness, that building
\glspl{verificationcondition} is difficult for complex bugs, and
increase TESLA's ability to reproduce rare behaviour.

\subsection{Typestate systems}

Typestate systems~\cite{Strom1986a} are an older mechanism allowing
programmers to express, and automated tools to check, complex
properties of programs.  In this model, assertions are described by
extending program types with some number of states and specifying how
they move between them and which operations are valid in each.  These
assertions are typically checked at run time~\cite{FFFWolff2011},
whether in an ad-hoc~\cite[pages~305--314]{Gamma1995} or
systematic~\cite{Aldrich2009} manner, but can also in some cases be
checked statically~\cite{Lam2005}.  Some systems, such as
Clara~\cite{FFFBodden2010}, take an intermediate position between these
two extremes, checking as much as possible statically and deferring
the rest to run time.  This gives them a great deal of flexibility to
trade the incompleteness of dynamic analysis off against the high
computational cost of sound static analysis.  There is some scope for
combining this sort of technique with {\technique}'s enforcer
mechanism to evaluate some side-conditions statically, potentially
reducing the overhead which enforcers impose on running programs.

2ndStrike~\cite{Gao2011} is a typestate checking system which is
particularly relevant to {\technique}.  In that work, the authors
examined traces of a concurrent program's execution so as to find
places where it ``nearly'' violated a typestate-style correctness
specification, allowing them to derive alternative schedules which
were more likely to actually violate it.  At a high level, this is
rather similar to {\technique}'s approach of finding potential bugs
using symbolic execution and then trying to reproduce them by forcing
the program to follow a particular schedule.  There is even a useful
parallel between 2ndStrike's typestate protocols and {\technique}'s
side-condition checking logic.  The key advantage of {\technique} is
that it can infer the side-condition for itself, whereas 2ndStrike
relies on a programmer manually specifying the typestate protocol.
This does, however, allow 2ndStrike to investigate more complex bugs
than {\technique} can handle.

\subsection{Symbolic execution}

There is a very large body of existing literature which investigates
ways of automatically detecting various classes of non-concurrency
bugs using symbolic execution.  JPF, the Java
Pathfinder~\cite{Havelund2000}, is a particularly important example of
such a system.  It has been used both as a research platform for new
approaches to the symbolic execution problem
itself~\cite{D'Amorim2008,Gligoric2010} and to verify large-scale
systems in an industrial context~\cite{FFFPCZsCZreanu2008}.  As such,
it represents one of the most well-developed symbolic execution
systems in use today; it is certainly far more so than the quite
primitive symbolic execution engine used by {\implementation}.  JPF
cannot, however, be applied as easily to binary programs, as it relies
in many ways on the far greater information available in Java
bytecode~\cite{Lindholm2013}.

KLEE~\cite{Cadar}, a symbolic execution engine for LLVM
bitcode~\cite{FFFLattner2013}, is a more recent example.  The aim of
this tool is to automatically generate test suites which exercise the
maximum amount of program functionality with the minimum amount of
testing.  At a sufficiently high level, it is quite similar to
{\technique}'s enforcer mechanism, in that both systems perform an
initial static analysis to find plausible bugs and then build tests to
check which are actually reproducible.  The difference is that
{\technique}'s tests are expressed in terms of the concurrency
schedules which are to be exercised, whereas KLEE's are expressed in
terms of the inputs to the program.\fnote{KLEE itself can be
  parallelised, as in, for instance, Cloud9~\cite{Ciortea2010}, but
  this is not the same as exploring parallel schedules in the program
  under test.}  It would be possible to combine the two techniques by,
for instance, using KLEE to find program inputs which allow
{\technique} enforcer side-conditions to be satisfied.  Such a
composite system would represent a useful improvement on KLEE, by
increasing its ability to find interesting concurrency bugs, and on
{\technique}, by reducing the number of enforcer's with unsatisfiable
side conditions which require run-time checking.

SLAM~\cite{Ball2011}, and the many systems based on it, such as
SLAyer~\cite{Berdine2011} and Terminator~\cite{Cook2006a}, is another
important example.  Unlike KLEE, it operates primarily at the level of
source code.  Most SLAM-based analyses are primarily thread-local,
considering only the sequential execution case, and so are not
directly relevant here.~~\cite{Cook2007} is one important exception.
In that work, the authors investigated ways of extending SLAM to
perform termination checking on multi-threaded programs.  The heart of
their approach is to reduce their equivalent of the
\glspl{interferingthread} to what they term an agreement, specifying
precisely what changes it can make to shared variables and hence how
it can interfere with the \gls{crashingthread}.  Their cross product
is between the \gls{crashingthread} and this agreement, rather than
directly between the two threads, dramatically reducing the total size
of the search space.  At a high level, {\technique}'s simplifiers and
the distinction between local and non-local side effects in the cross
product algorithm exploit a similar redundancy, but, judging from
their paper, are somewhat less effective than their mechanism.  On the
other hand, their mechanism relies on more complete aliasing
information than the {\technique} ones, and, as noted in the
evaluation, {\technique} is far more limited by alias analysis than it
is by an explosion of interleavings, making it difficult to apply
their technique in this context.

There have been many refinements proposed to the basic symbolic
execution method, such as counter-example guided abstraction
refinement~\cite{Clarke2003} (CEGAR), lazy
abstraction~\cite{Henzinger2002}, concollic execution~\cite{Sen2005},
or selective symbolic execution~\cite{Chipounov2011}.  The main thrust
of this work has been to mitigate symbolic execution's high cost by
initially using some kind of approximate execution and only switching
to a more refined mechanism when necessary to achieve adequate
coverage.  {\Technique}'s lazy aliasing resolution can be regarded as
a special case of an essentially similar idea, in that \state{Load}
operations initially return an abstraction representation which
``contains'' every possible result of the load and {\technique} only
determines the actual loaded value once it reaches a point in the
{\StateMachine}'s execution where it actually matters.  Integrating
some of these existing refinements could potentially expand this to
cover the effects of states other than \state{Load}, which might give
a useful reduction in analysis times.

\section{Automatically characterising bugs}
\label{sect:rw:auto_characterise}

As part of its operation, {\technique} derives characterisations of
bugs in the form of \glspl{verificationcondition}.  This problem had
previously been tackled by the Delta Debugging~\cite{Cleve2005}
project.  In that approach, a tool compares execution traces taken
from a program when it was working correctly to ones taken while it
was exhibiting a bug so as to find parts of the traces which most
effectively predict whether the program will suffer the bug being
investigated.  These predictors can then be used to locate the root
cause of the bug.  The approach was later extended to include actively
modifying a program's state as it runs and observing the
effects~\cite{Jeffrey2009}.

Delta Debugging was originally developed in the context of
single-threaded programs, but was subsequently extended to include
concurrent ones~\cite{Choi2002}.  Their basic approach is to record a
program's action in a deterministic replay system and to then replay
it under slightly varying schedules, allowing them to determine which
parts of the schedule are necessary for the bug to reproduce and hence
to produce a minimal bug-reproducing schedule.
Narayanasamy~\cite{Narayanasamy2007} later proposed a similar
algorithm using a different replay framework.  The key difference
between these characterisations and the ones produced by {\technique}
is one of emphasis: Delta Debugging aims to produce a characterisation
which is useful to a human developer, whereas {\technique} aims to
produce one which is useful for automatically building
\glspl{bugenforcer} and bug fixes.  This influences which information
is preserved and which abstracted away.  The two techniques also
impose slightly different restrictions on the type of bug which is to
be investigated: as discussed in \autoref{sect:types_of_bugs},
{\technique} considers simple atomicity violation crashes, whereas
Delta Debugging considers concurrency bug which can be reproduced
under their deterministic replay system.

Delta Debugging characterises a bug by comparing a program's behaviour
across multiple executions.  It is also possible to make progress by
analysing its behaviour within a single execution or by statically
analysing its structure without reference to any specific execution.
This is the core idea behind program slicing.  Program slicing systems
work by taking some representation of a program, which can be either
its static text~\cite{Weiser1981} or a log of its
execution~\cite{Agrawal1990a}, and transforming and filtering it so
that it contains only information relevant to some specific bug.
Program slices are conceptually similar to {\technique}'s
{\StateMachines}, albeit derived in a different way and for a
different purpose.  The key difference between the two schemes is that
a program slice is usually represented in the same language as the
original program, whereas {\StateMachines} are expressed in an
analysis language.  This makes them easier to analyse, at the expense
of also making them more difficult to derive and more difficult to
relate to the original program's behaviour.

\section{Automatically fixing bugs}

There have been many previous systems which aimed to automatically fix
bugs in programs, and I now give a brief overview of some of the more
important ones.

\subsection{Software rejuvenation and micro-reboots}

In practice, by far the most common approach to ``fixing'' software
bugs, once the software has been released, is simply to restart the
affected system and hope that the problem does not recur.  This is
essentially the idea between software rejuvenation~\cite{Huang1995}.
Later refinements included attempts to calculate the optimum reboot
schedule~\cite{FFFGarg1998,Li2002,Vaidyanathan2001}, and also some
attempts at reducing the cost of
reboots~\cite{Candea2002,Patterson2002}.  While undeniably effective,
this is a rather inelegant approach to the problem, and carries very
high cost; most other work on automatic fault remediation can be
regarded as attempts to reduce the frequency with which operators must
fall back on these techniques.

\subsection{Failure obliviousness and related techniques}
More recently, Rinard et al~\cite{FFFRinard2004} described failure
obliviousness, a technique for disguising certain classes of memory
faults in high-availability systems at the (possible) expense of
reduced integrity.  The core of this approach is, in essence, to
downgrade hardware exceptions from errors to warnings, allowing the
program to execute through them in the hope that the problem will
self-cleanse rather than propagating further.  Some faults are trivial
to ignore (stores through bad pointers, for instance, can be simply
discarded).  Others require more sophistication.  In particular, loads
of bad pointers must somehow synthesise a loaded value, and the choice
of value can affect the effectiveness of the technique in important
ways.  The original paper simply used a manually pre-defined sequence
of plausible values; later work expanded upon this by looking at the
dynamic dataflow context~\cite{Nagarajan2009} or by using a lookaside
table of recently discarded stores~\cite{Rinard2005a}.

The idea behind the reactive immune system~\cite{Sidiroglou2005} is
similar, except that rather than trying to discard memory operations
they instead try to convert errors from unhandleable memory errors
into whatever sort of errors the program can handle.  The initial
implementation did this by forcing functions to return immediately
with an error value, obtained by type analysis on the source code;
this was refined in the ASSURE system~\cite{Sidiroglou2009} to instead
take snapshots at places where it is convenient to inject errors and
then roll back when an error is detected.  Unfortunately, error
handling is often rather buggy itself, and so recovery to error
handling is not always useful.  This issue was investigated in detail
by S\"{u}\ss{}kraut et al.~\cite{FFFSusskraut2006}, who also propose
some techniques for automatically improving its robustness.

One potentially interesting approach, proposed by Elkarablieh et
al.~\cite{Elkarablieh2007} in a slightly different context, would be
to try to mine the program for information about the intended contents
of data structures.  This would then provide useful information when
deciding how to synthesise the results of wild reads so as to minimise
the potential for error propagation, or even, in a somewhat extreme
form, to proactively fix data structures which have suffered
corruption.  This potentially increases the effectiveness of error
hiding, but also potentially increases the scope for the program to
generate completely nonsensical results.  In the original paper, these
data structure invariants were obtained from \verb|assert()|-like
statements in the program source, combined with some basic static
analysis.  A later version, proposed by Malik et al.~\cite{Malik},
used Daikon-like detection of statistically justified invariants
during normal program operation, allowing the technique to be applied
without source code.  ClearView~\cite{Perkins} refined this approach
by combining it with an automated testing system to try to reduce the
risk of introducing new bugs.

DieHard~\cite{Berger2006} is another application of the failure
oblivious concept to heap-related issues.  In this system, however, no
attempt is made to discover or to enforce data structure invariants;
instead, the heap is structured so as to minimise the probability of
certain common types of bugs causing user-visible errors.  The authors
used two main techniques to achieve this:
\begin{itemize}
\item First, the heap is expanded such that there are likely to be
  large dead zones between any two allocations, making buffer
  overflows much less dangerous.
\item Second, they avoid reusing heap locations quickly after they
  have been \texttt{free()}d, reducing the risk of use-after-free
  errors causing recognisable bugs.
\end{itemize}
Neither of these techniques will eliminate bugs, but they can
dramatically reduce the probability of their causing user-visible
problems (at the expense of dramatically increasing memory
requirements and marginally increasing runtimes).
Exterminator~\cite{Novark2007} further built on this work by using
heuristics to identify probable bugs and only applying heap expansion
to allocations which are likely to benefit from it.  Assuming that all
such allocations are detected, this retains all of the bug-fixing
benefits of DieHard while noticeably reducing its overhead in the
common case where only a small number of allocations actually need
padding.

The AutoPaG system~\cite{Lin2007} tackled the related problem of
overflows of stack-based buffers.  In this work, the authors assume
that a buffer overflow has already been identified by some mechanism
(a CCured~\cite{Necula2005}-like safe compiler in the paper, but
others are possible), and then apply static analysis to find its root
cause at the source code level.  They then generate a source-level
patch which redirects any out-of-bounds accesses to the array back to
a safe location, in what is essentially a variant of failure
obliviousness.  This allows them to mask the bug until a true fix can
be obtained, with very low run-time overhead in both time and space.
Unfortunately, their static analysis is not complete, and so they must
occasionally fall back to a dynamic scheme.

\subsection{Input rectification}

Rather than trying to fix bugs in a program, another strategy is to
sanitise the program's inputs so that it never sees anything which
might upset it.  RX~\cite{Qin2007} is one example of such a system.
RX protects a program reactively.  When it notices that something has
gone wrong, it rolls the program to an earlier checkpoint and then
replays it in a slightly different environment, with slightly
different inputs and a slightly different thread schedule, in the hope
that doing so will avoid the bug.  When it finds a strategy which
works it caches the details of the modifications it made so that next
time it encounters a similar failure it can simply repeat those
modifications.  In this way it is able to protect the program from the
dangerous inputs without needing any knowledge of the program
structure and with very little knowledge of its interactions with the
environment.  First-Aid~\cite{Gao2009} extended RX to handle certain
kinds of heap-related errors using a similar strategy of rolling the
program back and then trying it again with slightly different heap
behaviour; it can be thought of as the union of RX and DieHard.
Bouncer~\cite{Costa2007} and Vigilante~\cite{Costa2008} used similar
techniques to quickly protect network-facing services from
newly-released worms.

RX's main weakness is that it has no knowledge of the structure of a
program's inputs, and so when it establishes that a bug was triggered
by a particular input it has no choice but to discard it completely.
SOAP~\cite{Long2012} tries to rectify this weakness by instead finding
safe approximations to dangerous inputs.  The core of SOAP is a
learning engine which augments a (manually specified) file format
description with a set of safety constraints generated by comparing
the results of a taint analysis to a set of known-safe inputs.  Future
inputs to the program are then rectified so that they satisfy these
constraints.  By providing this intermediate step between passing an
input to the program unchanged and dropping it completely input
rectification gives SOAP much more flexibility than RX when faced with
complex input-dependent bugs, and so gives SOAP-protected programs
better availability than RX-protected ones.  The main disadvantage of
the approach is that these manipulated inputs will often be more
likely to trigger other undesirable program behaviour; whether this
trade-off is worthwhile will depend on the nature of the program to be
protected.

\subsection{Hardware-based fixes for data races}
All of the fault remediation systems discussed so far concentrated
primarily on memory errors such as bad pointer dereferences or buffer
overflows.  There have also been many systems which attempted to
automatically fix concurrency errors.  One of the earliest was
ReEnact~\cite{Prvulovic2003a}, which used modified thread-level
speculation hardware to capture what happened during a data race and
to control instruction scheduling so as to avoid the bug in future.
This is similar to the intent of the fixes generated by {\technique},
with a few exceptions:
\begin{itemize}
\item The ReEnact scheme requires unusual hardware support, whereas
  {\technique} is purely software-based.
\item ReEnact fixes are dynamic, in the sense that the program must be
  constantly monitored to ensure it does not follow a bad schedule,
  whereas the {\technique} fixes statically introduce required locking
  so that bad schedules become impossible.
\item ReEnact requires some (quite modest) amount of programmer
  involvement in order to identify which races are critical to a
  particular bug and hence to direct the fixing process, except in a
  few unusual special cases.  {\Technique}, by contrast, requires some
  minimal programmer involvement to identify some properties of the
  program, but, once that has been done, requires no further manual
  assistance to process each bug.
\end{itemize}
Despite these limitations, ReEnact was able to fix some bugs, and
shows reasonably low run-time overhead (mostly on the order of ten
percent, depending on the benchmark).

Atom-Aid~\cite{Lucia2009} is another scheme which uses unusual
hardware features to protect against data race and atomicity violation
bugs, but in this case using hardware transactional
memory~\cite{Herlihy1993} rather than thread-level speculation.  This
paper grew out of an earlier observation that, in some cases,
processor performance can be improved by bundling sequences of memory
accesses into transactions, and hence batching interconnect operations
and amortising their costs~\cite{Ceze2007}.  This has the useful side
effect of eliminating a large number potential instruction
interleavings, and hence a large number of potential synchronisation
bugs.  Atom-Aid attempts to maximise this effect by carefully
adjusting transaction boundaries in response to the program's observed
behaviour in a way which, heuristically, prevents most forms of
atomicity violation bugs.  Unfortunately, the necessary hardware
changes are unlikely to be widely deployed in the near future, and it
is hard to see how to adapt the system into a software-only
implementation, which limits the technique's applicability.

\subsection{Software-based fixes for data races}
It is also possible to fix data races using ordinary software rather
than exotic hardware.  ConTest~\cite{FFFKrena2007} provides one
approach to doing so.  The idea here is quite simple: the program is
run under a data race detection algorithm\footnote{The original paper
  used an ERASER~\cite{Savage1997}-based algorithm, but others would
  work equally well.} and any detected races matched against a library
of manually-defined fix patterns which describe how to eliminate a
particular family of race bugs.  In principle, this could be used to
automatically eliminate every race bug in the program, if it can be
analysed for long enough with a sufficiently diverse workload and if
the fix pattern library is sufficiently complete.  In practice, it is
not clear that it is possible to build such a complete library using
the techniques presented in the paper,\fnote{The paper only considers
  simple two-access atomicity violation bugs, with more complicated
  patterns deferred to future work.} making the technique's generality
questionable.  Beyond this, ConTest also suffers the more
philosophical objection that races are not all concurrency bugs and
not all concurrency bugs are races, and so eliminating races is in
some sense solving the wrong problem.  Tallam et al.~\cite{Tallam2008}
suggested essentially the same mechanism a year later, but restricted
themselves to uniprocessor execution (so the only parallelism is the
coarse-grained variant provided by the operating system's thread
abstraction); this allowed them to make some simplifications to their
implementation, but further reduced the useful scope of the technique.

ToleRace~\cite{Kirovski2007}, which attempts to provide toleration for
asymmetric races, provides another useful point in the design space.
An asymmetric race is defined by the authors to be a situation where
some thread correctly follows a locking discipline (which must be
manually specified by the programmer), but another thread does not and
thus causes the correct thread to fail.  This presents a challenge
when debugging, as most na\"{i}ve approaches to postmortem analysis
will blame the wrong thread for the crash.  ToleRace ameliorates this
class of problems by arranging that when a thread acquires a
particular lock, a local copy of all of the values protected by the
lock is taken, with any accesses to protected variables made while
holding the lock redirected to the copy.  This prevents the correct
thread from seeing the effects of incorrect threads while it is in the
critical section, and so the race is much less likely to cause serious
problems.  The scheme used by ToleRace did not, however, guarantee
that this copy was itself internally consistent in the presence of
asymmetric races, as the copying process was not atomic, and so
correct threads could still easily be undermined by races with
incorrect ones.  \textsc{Isolator}~\cite{Ramalingam2009} fixes this
defect by introducing implicit per-page locks enforced using virtual
memory techniques.  However, it is still necessary for the programmer
to provide a manually-specified locking discipline, which makes these
techniques difficult to use in practice.

AVIO~\cite{Lu} is another approach to automatically fixing
concurrency-related bugs.  It is essentially the application of
program stereotyping ideas (\autoref{sect:rw:stereotyping}) to shared
memory concurrency: the program's execution is observed for some
amount of time whilst AVIO builds up a model of how its memory
accesses interleave when it is behaving normally, and future
executions are then shepherded so that only those normal interleavings
are possible.  The intuition here is that bugs are unusual events, and
so preventing anything unusual from happening will prevent any bugs
from occurring.  The flaw in this approach is that sometimes something
unusual does happen (if, for instance, the program receives some input
which was not adequately covered by the training data), and AVIO will
be unable to provide protection in this case.  AVIO also has the
weakness that it requires unusual hardware support in order to achieve
good performance.  While it can be implemented purely in software, the
software implementation causes a roughly twenty-five-fold slow-down,
making it impractical to use in production systems.

Kivati~\cite{Chew2010} can be thought of as a refinement to AVIO which
mitigates these weaknesses.  In Kivati, the access interleaving
invariants are discovered by means of a static analysis conducted
before the program starts running.  This set is usually far smaller
than the set which is discovered by AVIO.  That then allows Kivati's
second refinement, which is to enforce the invariants using the
processor's watchpoint registers~\cite[Chapter 16.2: Debug
  Registers]{Intel2009}, obviating the need for custom hardware.  The
result is a similar level of protection to AVIO but with far less
overhead, usually on the order of a few tens of percent.  Kivati's
main weakness is that it can only protect against single-variable
races, due to limitations in the static analysis used.  Even if the
static analysis were extended, limitations on processor watchpoint
facilities would prevent it from considering large numbers of
variables at the same time.  {\Technique} does not share this
limitation, and the fixes it generates have noticeably lower overhead.
The downside, of course, is that {\technique}'s initial analysis phase
is far more expensive than Kivati's.

AFix~\cite{Jin2011} is another example of a system for automatically
fixing concurrency bugs.  It works by patching additional lock
operations into LLVM bitcode so as to eliminate atomicity violation
bugs.  At a high level, the algorithm is quite similar to that used to
generate {\technique} fixes: convert a description of the atomicity
violation into critical sections, map those critical sections onto
contiguous fragments of the program's \gls{cfg}, and then introduce
additional synchronisation so as to make those \gls{cfg} fragments run
atomically with respect to each other.  There are, however, several
important differences.  Most obviously, the AFix algorithm considers
only simple two-access critical sections, whereas the {\technique} one
can enforce more complex $n$-access ones.  Even where there are
precisely two accesses to be protected, the set of instructions in the
critical section can differ slightly, because {\technique} will exit
the critical section if the thread leaves the {\StateMachine}'s
dynamic \gls{cfg}, whereas AFix exits if the thread cannot reach
another protected instruction in the current function invocation.
This can be either an advantage or a disadvantage, depending on why an
instruction is missing from the {\StateMachine} \gls{cfg}.  Some
instructions will be missing because they were cut off by the
\gls{alpha} limit on the \gls{analysiswindow}; releasing the lock for
these instructions is usually undesirable, as it re-introduces some of
the concurrent interleavings which the patch was supposed to
eliminate.  Other instructions will be missing because an earlier
analysis phase has shown that the program cannot suffer the bug if it
follows that path; releasing the lock here is safe, and can sometimes
lead to better parallelism and liveness behaviour.

AFix was later generalised to CFix~\cite{Jin2012}, which adds support
for fixing certain ordering violations by patching in condition
variable operations.  Most other automated bug-fixing systems
(including {\technique}) largely ignore ordering violations.  Such
bugs account for roughly a third of real-world concurrency
errors~\cite{Lu2008}, and so this is a large problem which is not
well-addressed by other work.  CFix considers only a subset of order
violation bugs (roughly, those in which one thread spawns an
additional thread and then assumes that the new thread advances more
quickly than the original one does), and even within that class relies
on fix-generating heuristics which cannot fix every possible bug.
Nevertheless, it was able to fix a variety of otherwise difficult to
fix bugs in widely-used software, and so represents a potentially
interesting starting point for future work in the area.

ConAir~\cite{Zhang2013} and ConMem~\cite{Zhang2010} take a completely
different approach to fixing concurrency bugs.  Rather than trying to
prevent the bad interleavings from happening, they instead allow the
program to suffer the bug, and then roll the one buggy thread back and
retry it in isolation, in the hope that whatever it was that caused it
to go wrong will have resolved itself.  Until the failure is detected,
ConAir does not make any modifications to the program's behaviour.
This gives it very low overhead, but makes it problematic to roll
threads back after they have performed any non-idempotent
transformations of the program state, including most modifications to
shared memory.  The restriction to idempotent re-execution regions is
similar to {\technique}'s \gls{w-isolation} assumption: ConAir can
only re-execute regions which cannot influence another thread's
behaviour, and {\technique}, when the \gls{w-isolation} assumption is
enabled, can only analyse \glspl{crashingthread} which do not
influence the \gls{interferingthread}'s behaviour.  In fact, the
restriction on ConAir is somewhat stronger than the \gls{w-isolation}
assumption, as it cannot re-execute any code which \emph{might}
influence another thread, whereas \gls{w-isolation} is only violated
if every path which triggers the bug involves that kind of influence.

Aviso~\cite{Lucia2013} presents another variant on this approach.
Like ConAir, Aviso starts by allowing the program to suffer the bug at
least once and then protects future executions so that it does not
suffer it again.  Unlike ConAir, though, Aviso does not attempt to
roll-back any threads, but instead records that the schedule is bad.
By comparing this bad schedule to a library of good ones collected
while the program is running normally, they are able to infer
\emph{why} it is bad, in much the same manner as Delta Debugging, and
hence to ensure that the bad features of the schedule never reproduce.
Assuming that the cause of the misbehaviour has been correctly
identified, this eliminates the bug.  Because threads never need to
roll back, there is no danger of a rollback failing, and Aviso can
protect against a broader class of bugs than ConAir.  The
disadvantage, of course, is that threads never roll back, and so any
misbehaviour in a thread will be externally visible, whereas ConAir's
rollback strategy can often fix the damage caused by the race before
it can propagate outside of the one afflicted thread.

\subsection{Deadlock bugs}
The final class of bugs considered here is deadlocks.  Techniques for
healing deadlocks in multithreaded applications have only been
investigated relatively recently.\fnote{Deadlock avoidance has been
  studied in other contexts for much longer; see
  e.g.~\cite{Dijkstra2004} or~\cite{Viswanadham1990}.}  One of the
earliest, proposed by Nir-Buchbinder et al.~\cite{Nir-Buchbinder2008},
was to build the dynamic lock graph as the program runs, discover any
strongly-connected components (SCCs), and then reduce every SCC to a
single lock.  This eliminates the potential for any lock order
reversal (LOR) deadlock involving that cluster of locks, and would, if
a complete lock graph were available, completely eliminate all LOR
deadlocks in the program.  Unfortunately, dynamically collected lock
graphs are inherently potentially incomplete, and this means that the
healing is incomplete (and can in fact introduce new deadlocks in
certain situations).  Even when the lock order graph is complete, this
approach can sometimes require a very large number of locks to be
merged, leading to excessive loss of concurrency and a concomitant
high performance cost.

Gadara~\cite{FFFWang2008} tackled both of these problems.  First, they
used static analysis to build a conservative approximation of the lock
graph (rather than the optimistic one produced by a dynamic analysis).
Second, they use discrete control theory to derive a ``controller''
co-program which inserts delays in the dynamic program execution in
some minimal set of places so as to avoid deadlocks, without
introducing unnecessary serialisation.  The use of a conservative
approximation means that they will occasionally defend against a
deadlock which is already impossible, and this will lead to additional
redundant synchronisation operations; it is unclear from the paper
whether Gadara-protected systems are more or less serialised than
Nir-Buchbinder-protected ones.  At a high-level this controller is
similar to the message-passing machines used in {\technique}'s crash
enforcers, although the details and purpose of the technique are
significantly different.

It is also possible to make progress on these problems in a purely
dynamic system.  For instance, Dimmunix~\cite{Jula2008} waits until
the program deadlocks, characterises the deadlock by means of a
``signature'', and then delays future lock acquire operations so as to
ensure that the signature cannot reoccur.  The hope is that preventing
the signature will also prevent the deadlock, and hence that the
program will, over time, become immune to whatever deadlocks might be
concealed within it.  Because it only fix deadlocks which have
actually been observed, serialisation is kept low and the need for
complete locking information is side-stepped, although at the cost of
having to suffer every deadlock at least once.

\subsection{Deterministic multi-threading}

Deterministic multi-threading systems, such as
Determinator~\cite{Aviram2010} or dOS~\cite{Bergan2010}, take a
different approach to concurrency bugs.  Rather than trying to detect
or fix such bugs, they instead design the runtime environment as to
make such bugs deterministic.  Concurrency bugs in a deterministically
multi-threaded system will either reproduce every time, in which case
they will be fixed quickly, or will never reproduce at all, in which
case they do not matter.

The most direct way of ensuring determinism, recommended by
Determinator, is to make the API presented to programmers manifestly
deterministic, so that there is simply no way for applications to do
anything which even appears to be non-deterministic.  In the case of
Determinator, this means that the main form of parallelism supported
is fork-join, with shared-memory parallelism implemented as a merge
operation on memory, analogous to the merge operation in a distributed
version control system~\cite{FFFHamano2013}.  This is easy to
understand and has very respectable performance, and would arguably
have been a very good idea thirty years ago; unfortunately, deploying
it today would require that vast amounts of existing software be
re-implemented to use the new API, making it impractical for any but
quite specialist environments.

Rather than requiring that the API itself be deterministic, it is also
possible to implement an existing API in a deterministic way, allowing
determinism to be retrofitted to existing operating systems without
discarding the existing investment in concurrent software.  This is
the approach advocated by dOS~\cite{Bergan2010} and
\textsc{DThreads}~\cite{Liu2011}.  The key observation behind these
systems is that most APIs are mostly deterministic, and so in practice
most parts of a program's execution are also inherently deterministic.
It is therefore only necessary to impose additional ordering on a
small number of operations.  \textsc{DThreads} and dOS achieve this by
dividing a program's execution into concurrent epochs, in which every
program thread advances but none are allowed to perform
ordering-dependent operations such as racing memory accesses, and
non-concurrent ones, in which only a single thread runs but that
thread is allowed to perform any operation.  Careful management of the
transition between epochs allows these systems to ensure that
executions are always completely deterministic, and hence that bugs
either reproduce every time or never reproduce at all.

These approaches might appear to obviate the need for
{\technique}-like techniques.  This is not entirely true.  First,
deterministic threading techniques impose some performance overheads
and, while this overhead is far less than that of {\atechnique}
\gls{bugenforcer}, it is an overhead which must be suffered whenever
the program runs, whereas \glspl{bugenforcer} only impose any overhead
at all when investigating a particular bug.  Second, and more subtly,
deterministic threading can be argued to merely hide bugs rather than
completely removing them.  The behaviour of programs written for
systems such as dOS is, in practice, highly dependent on the precise
placement of epoch boundaries, which is itself dependent on complex
global properties of the program's structure.  This makes it difficult
to reason locally about the impact of a given modification,
potentially leading to unfortunate program maintenance issues.
Techniques such as {\technique} remain useful for understanding these
latent bugs.

\section{Decompilation and machine code analysis}

{\Technique}'s approach to generating {\StateMachines} from machine
code can be viewed as a form of decompilation, in the sense that it
takes a low-level representation of a program and converts it to a
higher-level one.  The most important difference is that decompilation
aims to preserve all of the behaviours of the program, whereas
{\technique} seeks only to preserve those behaviours which are most
relevant to the bug which is being investigated.  Cifuentes'
dissertation~\cite{Cifuentes1994} provides a thorough, if now quite
outdated, overview of the field; Emmerik and
Waddington~\cite{Emmerik2004} described some of the issues commonly
encountered when attempting to use these techniques in practice.

CodeSurfer~\cite{Balakrishnan2008,Balakrishnan2005a}, also known as
WYSINWYX, is a recent example of a decompilation platform.  The intent
here is to provide a human user with assistance in determining what a
binary-only program does, rather than supporting extensive automated
analyses.  It has only limited support for multi-threaded programs,
making it hard to compare directly to {\technique}.  On the other
hand, it does support an advanced memory aliasing analysis, value-set
analysis~\cite{Balakrishnan2004}.  Aliasing analysis is currently one
of {\technique}'s major weaknesses, and so combining these techniques
might produce interesting results.

Decompilation is not the only kind of analysis which has been applied
to machine code.  BAP, the Binary Analysis
Platform~\cite{Brumley2011}, is one of the more recent examples.  It
is a set of tools used to convert machine code into an intermediate
language suitable for other forms of analysis.  Along the same lines,
the BitBlaze~\cite{Song2008} project designed a number of analyses on
machine code intended to uncover security problems given only a binary
program.  Both have important parallels to {\technique}'s
{\StateMachine} building process.  The chief difference is that those
earlier systems had only very limited support for multi-threaded
programs, whereas accurately analysing threading-related effects is
one of the main aims of {\technique}.

\section{Theorem proving and SAT solving techniques}

{\Technique} represents its \glspl{verificationcondition} and most
internal predicates as \glspl{bdd} whose variables are expressions in
the {\StateMachine} expression language (see
\autoref{sect:derive:state_machines}), augmented with some simple
arithmetic simplification and canonicalisation rules.  A
\gls{verificationcondition} is considered to be satisfiable if these
cannot reduce the \gls{bdd} to \false.  This can be thought of as a
very simple Satisfiability Modulo Theory (SMT)
solver~\cite{Barrett2009}, with the \gls{bdd} library implementing the
satisfiability part and the arithmetic rules providing the theory.  As
such, it might be interesting to investigate replacing these
components with an existing standard SMT solver such as
Z3~\cite{FFFMoura2008} or Yices~\cite{FFFDutertre2006}.  This might
eliminate some of the analysis phase's false positives, and hence
reduce the number of \glspl{bugenforcer} which need to be generated
and tested.

\section{Discussion}

This chapter described and summarised the most important existing work
in the field of automatically detecting, characterising, and fixing
program bugs, including older systems which concentrated on
memory-related errors and more modern ones which investigated
concurrency-related ones.  None of these systems represent a panacea,
even within their restricted bug classes, but all can be valuable
under certain circumstances.  Compared to these prior systems,
{\technique} has two particularly unusual features:
\begin{itemize}
\item {\Technique}'s \glspl{bugenforcer} make extensive use of
  non-concurrency preconditions for concurrency bugs, allowing them to
  more effectively target their efforts when attempting to reproduce
  those bugs.  Previous systems, such as Kivati and AVIO, considered
  only the happens-before graph component of the bug precondition.
\item {\Technique} operates primarily at the level of machine code,
  whereas most existing systems operate with much higher-level
  representations such as LLVM bitcode, or even with the program's
  original source code.  The few existing systems which do consider
  machine code, such as CodeSurfer and BAP, generally restrict
  themselves to single-threaded programs.  I am not aware of any prior
  work which was able to fix concurrency bugs by making small,
  targeted, static changes to a program's machine code without access
  to any more abstract representations.
\end{itemize}
These features imply certain weaknesses as well as strengths.  In
particular, \gls{bugenforcer}'s use of those non-concurrency
preconditions means that {\technique} must perform an initial analysis
step to discover what they are, and operating at such a low level of
abstraction means that that analysis is comparatively expensive.
These weaknesses could, to some extent, be mitigated by incorporating
insights, or even implementations, from some of these previous
systems; I have indicated in the preceding text where I believe that
this would be most profitable.

Even with these refinements, it is unlikely that techniques derived
from {\technique} will ever be truly light-weight: a {\technique}
\gls{verificationcondition} contains far more information than the bug
characterisations derived by other tools such as AFix or ConTest, and
so will usually require longer to derive, assuming equal quality of
implementation.  {\Technique} relies for its viability on being able
to use this additional information effectively.  The \gls{bugenforcer}
mechanism, as I have already shown, does so.  The automatic fix
generation mechanism, by contrast, makes relatively little use of this
additional information, and so it is plausible that a careful
hybridisation of {\technique} and a prior system could produce a new
one which preserves the good performance of {\technique}'s fixes
without the expensive initial analysis phase.

I have now described {\technique}, including how it characterises,
reproduces, and fixes bugs, evaluated the performance of
{\implementation}, my implementation of it, and placed it in the
context of existing work in the field.  The final two chapters of this
dissertation will discuss some possible ways in which {\technique}
could be extended, in \autoref{sect:fw}, and then summarise the most
important results and conclusions, in \autoref{sect:concl}.

