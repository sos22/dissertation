\chapter{Related work}
\label{chapter:related_work}

Previous chapters have described the {\technique} technique and
{\implementation}, my implementation of it, explaining how it should
work and showing that it does.  This chapter places {\technique} in
context by comparing it to related existing systems, discussing ways
in which {\technique} improves or complements prior work in the area.

\section{Automatically finding bugs}

Automatically detecting and characterising bugs in programs has been
an active area of research for many years.  Some of the more important
and relevant are summarised in \autoref{fig:rw:find_char}; the rest of
the section describes them in more detail.

\begin{sidewaysfigure}
  \begin{figgure}
  \begin{tabular}{l>{\RaggedRight\arraybackslash}p{5.5cm}lp{10.3cm}}
    Technique family           & Type of error discovered                     & Static/dynamic  & Example systems \\
    \hline
    Locksets                   & Locking protocol violations                  & Static          & RacerX\cite{Engler2003},RELAY\cite{Voung2007} \\
                               &                                              & Dynamic         & Eraser\cite{Savage1997} \\
    \hdashline
    Happens-before             & Memory races                                 & Dynamic         & RaceTrack\cite{Yu2005}, FastTrack\cite{Flanagan2009}, Netzer\cite{Netzer1991} \\
    \hdashline
    Concurrent aliasing        & Memory races                                 & Static          & Chord\cite{Naik2006} \\
    \hdashline
    Schedule perturbation      & Timing dependencies                          & Dynamic         & DataCollider\cite{Erickson2010}, AtomRace\cite{Letko2008}, CTrigger\cite{Zhou} \\
                               &                                              & Mixed           & Chess\cite{Musuvathi2008} \\
    \hdashline
    Stereotyping               & Anomalous behaviour                          & Dynamic         & Anomaly-based IDSes\cite{Forrest1996a}, Pu and Wei\cite{Pu2006}, HeapMD\cite{Chilimbi2006}, DIDUCE\cite{Hangal2002}, MUVI\cite{Lu2007} \\
                               &                                              & Static          & Bugs as deviant behaviours\cite{Engler2001}\\
    \hdashline
    Extended assertions        & \multirow{2}{*}{\parbox{5.5cm}{Violations of programmer-identified properties}} & Dynamic        & TESLA\cite{Watson2013}\editorial{Need a better cite}, Uppuluri et al.\cite{Uppuluri2005} \\
                               &                                              & Static          & Meta-compilation\cite{Engler2000a}\\
    \hdashline
    Typestate systems\cite{Strom1986a}& \multirow{2}{*}{\parbox{5.5cm}{Object access protocol sequencing violations}} & Dynamic & Gradual typestates\cite{Wolff2011}, 2ndStrike\cite{Gao2011} \\
                               &                                                                             & Static  & Plaid\cite{Sunshine2011}\\
                               &                                                                             & Hybrid  & Clara\cite{Bodden2010}\\
    \hdashline
    Symbolic execution         & Most forms of bugs                           & Static          & SLAM\cite{Ball2011}, KLEE\cite{Cadar}, JPF\cite{Havelund2000} \\
                               & Most forms of bugs                           & Hybrid          & S2E\cite{Chipounov2011} \\
                               & Memory management errors                     & Static          & SLAyer\cite{Berdine2011} \\
                               & Infinite loops                               & Static          & Terminator\cite{Cook2006a} \\
    \hline
    Bug characterisation       & Value replacement                            & Dynamic online  & Value replacement\cite{Jeffrey2009} \\
                               & Delta debugging                              & Dynamic offline & Delta Debugging\cite{Cleve2005,Choi2002} \\
                               & Static program slicing                       & Static          & Weiser\cite{Weiser1981} \\
                               & Dynamic program slicing                      & Dynamic         & Dynamic program slicing\cite{Agrawal1990a} \\
                               & Assisted debugging                           & Interactive     & Model Inference System\cite{Shapiro1982} \\
  \end{tabular}
  \caption{Summary of some existing bug detection and characterisation
    techniques.}
  \label{fig:rw:find_char}
  \end{figgure}
\end{sidewaysfigure}

\subsection{Lockset analysis}

When software developers design concurrent software, they usually have
a plan for avoiding concurrency errors, and this plan is usually
expressed as a concurrency protocol defining the acceptable forms of
concurrency and the actions which the program must take to ensure that
only those forms are possible.  These protocols can take many
differing forms, reflecting the differing desired behaviour of the
programs for which they are designed, but the majority have at their
core a simple lock discipline which associates locks with program
structures and requires the program hold the lock when operating on
the structure.  Lockset-type tools detect concurrency errors by
inferring this lock discipline and then flagging an error whenever the
program violates it.

Eraser\cite{Savage1997} was the earliest tool of this form.  It is a
dynamic analysis which observes the running program's lock operations
and memory accesses so as to build a mapping from memory locations to
sets of locks which might conceivably protect them.  A location's lock
set initially contains every lock in the program and is intersected
with the set of currently-held locks whenever a thread accesses the
location.  If the set ever becomes empty then there is no locking
discipline which is compatible with the program's behaviour, and so
the tool flags a potential concurrency error\footnote{There is an
  similarity here with {\technique}'s dynamic alias analysis
  (\autoref{sect:program_model}), in that both approaches justify
  their analysis with reference to the fields of high-level language
  structures but must perform the actual analysis on memory locations,
  and hence the two techniques make similar assumptions about memory
  type stability.}.

Eraser is both sound and complete, in the sense that if it reports a
lock discipline violation there has definitely been such a violation,
and conversely if it reports no errors then there must exist a
discipline which is compatible with the observed behaviour.  These are
not, though, the properties most desired by most developers.  Very few
concurrency protocols consist entirely of a lock discipline, and so
following the lock discipline does not necessarily imply following the
(far more important) concurrency protocol.  It might, for instance, be
that the program contains some multi-access regions which must behave
as-if atomically; a simple lock discipline can ensure that individual
accesses are protected, but cannot express this higher-level
requirement.  It is also possible to define correct concurrency
protocols which are incompatible with any lock discipline if, for
instance, the program uses any lock-free algorithms, and so violating
the lock discipline does not imply that the concurrency protocol has
also been violated.  In the sense which matters most, then, lockset
analysis is neither totally sound nor totally complete.  In practice,
though, it is usually sound enough and complete enough and this,
combined with its good performance, makes it a useful tool.

Lockset analysis can also be applied statically as in, for instance,
RacerX\cite{Engler2003}.  In RacerX, an initial static analysis
determines, for every line in the program, which locks are held when
that line executes, and hence which locks protect each compound
structure field.  Any fields with an empty lock set are potentially
insufficiently synchronised and are reported as a potential error.  As
a lockset analysis, RacerX shares many of the same weaknesses as
Eraser (multi-access concurrency errors cannot be detected; lock-free
algorithms are always reported as errors) and, as a static analysis,
adds several more (complete program source must be available; program
behaviour is aggressively approximated).  Its chief advantage is that,
as a static analysis, it considers all possible program behaviour,
rather than just behaviour exhibited in one particular run, making it
easier to be confident in its results and eliminating any potential
probe effects.

The chief approximation made by RacerX's static analysis is the use of
a very simple aliasing model which assumes that there is precisely one
instance of every data type.  This greatly simplifies scaling the
analysis to very large programs, but also greatly reduces its
soundness.  RELAY\cite{Voung2007} built upon RacerX while attempting
to alleviate this limitation.  The key technique used was to summarise
the program's procedures\cite{Qadeer2004} using symbolic execution,
recording what locks each acquired and released and which structure
fields it accessed, allowing the tool to perform cross-function race
analysis without needing to consider the full body of each function
every time.  This provided useful improvements in both scalability and
soundness.

These techniques could be used to refine {\technique} in two main ways
of ways.  Most obviously, including a lockset table in the
\gls{programmodel} could potentially allow many of the false positive
\glspl{verificationcondition} to be eliminated far more easily,
simultaneously reducing both the cost of the analysis and the number
of bugs which must be checked at run time.  This would need to be done
with some care if the lockset table were derived dynamically (if the
end result is that {\technique} detects a bug only when Eraser does
then there would be little point in having both tools), but would be
relatively easy with the (more conservative) static tables built by
RacerX and RELAY.  Apart from that, there might also be some scope for
integrating RELAY-style procedure summaries into the {\technique}
analysis, both to automate the generation of library stubs
(\autoref{sect:derive:library_functions}) and, more interestingly, to
summarise frequently-used procedures within the program itself so as
to aid analysis of functions which call them.

\subsection{Happens-before}

Lockset analysis is most effective when the program's concurrency
protocol consists solely of a simple lock discipline, but, as
discussed above, most program's protocols are more complicated than
that.  There is a class of more powerful tools, such as
RaceTrack\cite{Yu2005} or FastTrack\cite{Flanagan2009}, which can
detect concurrency bugs whilst imposing far weaker requirements on the
structure of the program to be analysed.  At their core, these tools
consist of a mechanism to build a partial order of the program's
accesses to memory, determine which parts of that partial order might
affect the program's operation, and flag a potential error if the
program is dependent on some unexpected ordering.  A tool might, for
instance, declare that a program is allowed to depend on the order in
which threads are granted a lock when they contend for it, but that it
should not depend on the order of concurrent accesses to the same
memory location.  In principle, it is possible to do this by building
the entire happens-before graph\cite{Netzer1991}, but for performance
reasons most practical tools model only the most relevant part of it
using a variant of Lamport's vector clock algorithm\cite{Lamport1978}.

Schemes based on this idea can, in principle, be made sound, in the
sense that they can report every place in a particular program's
execution which depends on the order in which concurrent operations
are executed.  Practical implementations, however, compromise
soundness in order to reduce the false positive rate.  Consider, for
instance, two programs $P$ and $P'$ where $P'$ is the same as $P$
except for the introduction of the sequence ``release($x$);
acquire($x$);'' in some part of the program which holds lock $x$.  It
is clearly possible for this transformation to introduce additional
bugs, but the only edges introduced to the partial order will be
between lock operations.  A tool which reported all of the lock edges
would have a very high false positive rate for lock-based concurrent
software, but one which does not cannot distinguish $P$ and $P'$ and
so must have false negatives.

Ordering-based schemes can also be applied statically as in, for
instance, the Chord static race detector\cite{Naik2006}.  At a high
level, Chord works by first building a model of the program's existing
synchronisation structure, in what they call the lock analysis phase,
and then performing a second analysis to determine when two memory
accesses in different threads might alias, in what they call the
escaping pairs computation.  The structure constructed by the lock
analysis phase describes the safe edges of a happens-before partial
ordering and the escaping pairs computation describes the unsafe ones.
Any unsafe edges which are not prevented by safe ones are reported as
potential program bugs.  There would be some scope for combining their
model of the program's safe edges into {\technique}'s
\gls{programmodel}, reducing the number of concurrent interleavings
which would have to be considered in the initial analysis phase and
hence the number of \glspl{verificationcondition} requiring runtime
verification, although converting between their source-level analysis
and {\technique}'s machine code-level one might be challenging.

\subsection{Schedule perturbation}

One reasonable definition of a concurrency bug is a bug whose
behaviour depends on the precise relative timing of parts of a program
which run concurrently.  This suggests an alternative scheme for
finding such bugs: simply alter the program's timing and see what
happens.  This is the approach taken by
DataCollider\cite{Erickson2010}.  Rather than trying to find races
directly, it instead inserts delays into the program's execution so as
to make races more likely and detects them when they occur.  This
approach has a number of important advantages: it has no false
positives (any race reported will definitely have happened); it has
reasonably low overhead (so the program's behaviour during analysis is
likely to be at least broadly similar to that during normal
execution); and it requires relatively little in the way of supporting
machinery (so it can be used in constrained environments such as
kernel-mode drivers or embedded systems).  The parallels with
{\technique}'s \glspl{bugenforcer} are obvious.  The important
difference is that {\technique} makes use of an initial analysis phase
to discover the best places to insert delays, allowing it to reproduce
bugs far faster than DataCollider.

Chess\cite{Musuvathi2008} can be thought of as a more systematic
approach to the same idea.  Rather than inserting delays at randomly
selected points in order to perturb the schedule, Chess systematically
enumerates all possible program schedules and then flags schedules
which exhibit interesting behaviour, allowing it to reproduce a wide
variety of bugs quickly and easily.  Chess makes two major
approximations in order to get good results:
\begin{enumerate}
\item \emph{Bounded preemptions} Most concurrency bugs can be
  reproduced without requiring particularly complicated concurrent
  behaviour\cite{Musuvathi2007}.  Chess takes advantage of this by
  limiting the number of times they switch between threads in any
  given run of the program, vastly reducing the number of program
  schedules which must be considered at the expense of failing to
  detect bugs which depend on more complex interleavings.  A similar
  idea could be added to {\technique}'s symbolic execution engine
  without much difficulty, although, as discussed in
  \autoref{sect:eval:complex_hb}, {\technique} is already able to
  handle relatively complicated graphs with little difficulty, and so
  the potential for improving performance by doing so is limited.
\item \emph{Inductive racing} Chess's main analysis considers only a
  single thread at a time and switches between threads at defined
  preemption points.  For race-free programs, the only preemption
  points needed are at synchronisation-related library functions such
  as \texttt{WaitForSingleObject} or \texttt{ReleaseMutex}, and these
  are easily identified.  For other programs, it is also necessary to
  consider switching threads whenever the program experiences a data
  race, and these are much less obvious in a running program.  Chess
  identifies racing accesses by applying a standard data race detector
  to the first few schedules it considers and then simply assuming
  that those schedules contained all of the program's possible data
  races.  This means that Chess will sometimes miss data-dependent
  races, and hence potentially miss some real bugs, but dramatically
  reduces the computational cost of the analysis.

  {\Technique} makes a similar but weaker assumption as part of its
  dynamic alias analysis: Chess assumes that two accesses can race if
  they are observed to race, whereas {\technique} assumes that they
  can race if they are observed to access the same memory location
  without an intervening call to a memory retyping instruction such as
  \texttt{free}.  This implies that {\technique} is less likely to
  fail to analyse a bug due to an incorrect induction, but is also
  largely responsible for {\technique}'s far weaker scalability to
  bugs which depend on complicated memory access patterns.
\end{enumerate}
Despite these, Chess has been demonstrated to be remarkably effective
at reproducing interesting bugs in real-world programs and that,
combined with its good performance, makes it an attractive tool for
this kind of problem.

CTrigger\cite{Zhou} is another variant of a similar idea.  The
approach taken in that work is to perform an initial static analysis
on a program so as to discover some potential atomicity violations and
to then construct alternative schedules which attempt to trigger those
violations, in the hope that some of them correspond to a bug.  This
is, again, rather similar to {\technique}'s \gls{bugenforcer}
mechanism.  There are several important differences between the two
techniques, though: CTrigger operates on the program's source, whereas
{\technique} operates on machine code; CTrigger considers only simple
two-variable atomicity violations, whereas {\technique} considers a
much broader class of atomicity violations; CTrigger aims to reproduce
atomicity violations, whereas {\technique} attempts to reproduce
actual bugs; and CTrigger reproduces simple instruction interleavings,
whereas {\technique} can reproduce complex data-dependent schedules.

\subsection{Stereotyping}
\label{sect:rw:stereotyping}

All of the approaches discussed so far rely on some pre-defined notion
of what it means for a program to have a bug.  An alternative approach
is to simply define a bug to be anything which the program does
rarely.  Tools based on this idea start by building up a model of how
a stereotypical execution of the program behaves and then report any
deviation from the stereotype as a potential bug.  This is essentially
the same problem as is solved by anomaly detecting intrusion detection
systems\cite{Forrest1996a}, and such systems can be regarded as a kind
of bug detector.  In practice, though, systems designed for detecting
intrusions are not usually well-suited to detecting bugs, as they tend
to operate at the wrong level of abstraction, and I do not consider
them in detail here.

Daikon\cite{Ernst2007} is a particularly interesting approach to this
idea.  Their basic approach is to collect one or more traces of the
program while it is operating normally, recording the values of local
variables and function parameters at various interesting points in the
program's execution, and to then mine these traces to find
statistically well-supported correlations between values.  These
correlations are then converted into assertions and inserted into the
program; any execution in which an assertion fails is reported as a
potential bug.  The earlier DIDUCE\cite{Hangal2002} can be regarded as
a kind of dual of Daikon: rather than trying to find conditions which
are true for all known executions, it starts with a condition that
nothing at all is possible and then weakens it until it allows all of
the known behaviour.  This tends to lead to sharper inferred
invariants, in the sense of allowing less behaviour, and so DIDUCE
tends to find more bugs but with a higher false-positive rate.

The model-building parts of these tools could usefully be combined
with {\technique} so as to expand its \gls{programmodel}, potentially
giving useful improvements in both analysis performance and precision.
HeapMD\cite{Chilimbi2006}, which uses this kind of method to build up
a model of the heap, would be particularly interesting to investigate
in this respect.

These techniques can also be applied statically, as in, for example,
Engler's ``Bugs as deviant behaviour'' system\cite{Engler2001}.  The
idea here is to perform a kind of statistical static analysis to
identify common patterns in a program's source code and to then flag a
warning whenever any of these patterns are violated.  It might be, for
instance, that a call to \texttt{spin\_lock} is almost always followed
by a call to \texttt{spin\_unlock}, so that the remaining calls to
\texttt{spin\_lock} are likely to be bugs.  Systems based on this
observation are able to discover interesting violations of
program-specific invariants without ever having to be told what those
invariants are.  MUVI\cite{Lu2007}, which discovers rules related to
when variables are likely to be accessed together, is particularly
relevant in the context of concurrency bugs, as many atomicity
violation bugs will violate at least one of those rules.  Information
from such an analysis might be able to provide useful hints in
{\technique}'s symbolic execution phases, encouraging it to spend more
time on paths which are more likely to lead to interesting bugs and
less on those which are probably safe.

\subsection{Extended assertions}

All of the schemes discussed so far in this section are intended to
discover bugs automatically.  An alternative approach is to instead
make it easier for the programmer to find the errors themselves.  One
particularly attractive mechanism for doing so, originally proposed in
the \textit{metal} meta-compilation system\cite{Engler2000a}, is to
allow developers to extend the compiler with domain-specific semantic
knowledge, allowing the compiler to generate relevant domain-specific
warnings.  It might be, for instance, that the program's developer
knows that calls to \texttt{lock} must always be followed by calls to
\texttt{unlock} within the same function.  Semantic constraints of
this form are easily identified when implementing \texttt{lock} and
\texttt{unlock} but are easily forgotten when using them, and so
having the compiler check them automatically can detect a useful
number of bugs for relatively little cost.

The TESLA project\cite{Watson2013,Locielski2011}\editorial{still need
  a better cite} represents another approach to this idea.  In the
TESLA model, the programmer provides an approximation of the desired
state machine for some fragment of the program, expressed as a formula
in a linear-time temporal logic.  This is then compiled into a
co-program which runs alongside the program and checks that it
conforms to this state machine.  There are close parallels here with
{\technique}'s \glspl{bugenforcer}.  It would be interesting to
combine the two approaches by, for instance, using TESLA assertions as
input to the \gls{bugenforcer} building algorithm, rather than trying
to infer them directly from the binary; doing so would simultaneously
alleviate {\technique}'s greatest weakness, that building
\glspl{verificationcondition} is difficult for complex bugs, and
increase TESLA's ability to reproduce rare behaviour.

\subsection{Typestate systems}

Type state systems\cite{Strom1986a} are an older mechanism allowing
programmers to express complex program properties.  In this model, the
assertions are described by adding state to program types, with a
description of how certain operations can move instances of a type
from one state to another, and the programming language restricted to
only allow certain operations on objects which are in a particular
state.  These assertions are typically checked at run
time\cite{Wolff2011}, whether in an
ad-hoc\cite[pages~305--314]{Gamma1995} or systematic\cite{Aldrich2009}
manner, but can also in some cases be checked
statically\cite{Lam2005}.  Some systems, such as
Clara\cite{Bodden2010}, take an intermediate position between these
two extremes, checking as much as possible statically and deferring
the rest to run time.  This gives them a great deal of flexibility to
trade the incompleteness of dynamic analysis off against the high
computational cost of sound static analysis.  There is some scope for
combining this sort of technique with {\technique}'s enforcer
mechanism to evaluate some side-conditions statically, which could
potentially reduce the overhead which enforcers impose on running
programs.

2ndStrike\cite{Gao2011} is a typestate checking system which is
particularly relevant to {\technique}.  In that work, the authors
examined traces of a concurrent program's execution so as to find
places where it ``nearly'' violated a typestate-style correctness
specification, allowing them to derive alternative schedules which
were more likely to actually violate it.  At a high level, this is
rather similar to {\technique}'s approach of finding potential bugs
using symbolic execution and then trying to reproduce them by forcing
the program to follow a particular schedule.  There is even a useful
parallel between 2ndStrike's typestate protocols and {\technique}'s
side-condition checking logic.  The key advantage of {\technique} is
that it can infer the side-condition for itself, whereas 2ndStrike
relies on a programmer manually specifying the typestate protocol.
This does, however, allow 2ndStrike to investigate more complex bugs
than {\technique} can handle.

\subsection{Symbolic execution}

There is a very large body of existing literature which investigates
ways of automatically detecting various classes of non-concurrency
bugs using symbolic execution.  JPF, the Java
Pathfinder\cite{Havelund2000}, is a particularly important example of
such a system.  It has been used both as a research platform for new
approaches to the symbolic execution problem
itself\cite{D'Amorim2008,Gligoric2010} and to verify large-scale
systems in an industrial context\cite{PCZsCZreanu2008}.  As such, it
represents one of the most well-developed symbolic execution systems
in use today; it is certainly more so than the quite primitive
symbolic execution engine used by {\implementation}.  JPF cannot,
however, be applied as easily to binary programs, as it relies in many
ways on the far greater information available in Java
bytecode\cite{Lindholm2013}.

KLEE\cite{Cadar}, a symbolic execution engine for LLVM
bitcode\cite{Lattner2013}, is a more recent example.  The aim behind
KLEE is the automatic generation of test suites which exercise the
maximum amount of program functionality with the minimum amount of
testing.  This is conceptually very similar to {\technique}'s enforcer
approach to finding bugs: use static analysis to find possible bugs
and then build tests which show whether or not that bug is present.
The difference is that {\technique}'s tests are expressed in terms of
the concurrency schedules which are to be exercised, whereas KLEE's
are expressed in terms of the inputs to the program\footnote{KLEE
  itself can be parallelised, as in, for instance,
  Cloud9\cite{Ciortea2010}, but this is not the same as exploring
  parallel schedules in the program under test.}.  It would be
possible to combine the two techniques by, for instance, using KLEE to
find program inputs which allow {\technique} enforcer side-conditions
to be satisfied.  This would mitigate {\technique}'s most important
weakness, that most of the enforcers it generates require conditions
which the program can never actually reach, and increase KLEE's
ability to find interesting concurrency bugs.

SLAM\cite{Ball2011}, and the many systems based on it, such as
SLAyer\cite{Berdine2011} and Terminator\cite{Cook2006a}, is another
important example.  Unlike KLEE, it operates primarily at the level of
source code.  Most SLAM-based analyses are primarily thread-local,
considering only the sequential execution case; \cite{Cook2007} is one
important exception.  \todo{Say more.}

There have been many refinements proposed to the basic symbolic
execution method, such as counter-example guided abstraction
refinement\cite{Clarke2003} (CEGAR), lazy
abstraction\cite{Henzinger2002}, concollic execution\cite{Sen2005}, or
selective symbolic execution\cite{Chipounov2009}.  The main thrust of
this work has been to mitigate symbolic execution's high cost by
initially using some kind of approximate symbolic execution and then
switching to a more refined mechanism only where necessary to achieve
adequate coverage.  {\Technique}'s lazy aliasing resolution can be
regarded as a special case of an essentially similar idea, in that
\state{Load} operations initially return an abstraction representation
which ``contains'' every possible result of the load and {\technique}
only determines the actual loaded value once it reaches a point in the
{\StateMachine}'s execution where it actually matters.  Integrating
some of these existing refinements could potentially expand this to
cover the effects of states other than \state{Load}, which might give
a useful reduction in analysis times.

\section{Automatically characterising bugs}
\label{sect:rw:auto_characterise}

As part of its operation, {\technique} characterises bugs to form
\glspl{verificationcondition}.  The Delta Debugging\cite{Cleve2005}
project investigated the same problem.  In this approach, the tool
compares traces taken from a program when it was working to ones taken
while it was exhibiting a bug in order to find the parts of the traces
which most effectively predict whether the program will suffer the bug
being investigated, and hence to automatically locate the root cause
of the bug.  The approach was later extended to include actively
modifying a program's state as it runs and observing the
effects\cite{Jeffrey2009}.

Delta Debugging was original developed in the context of
single-threaded programs, but as subsequently extended to include
concurrent ones\cite{Choi2002}.  Their basic approach is to record a
program's action in a deterministic replay system and to then replay
it under slight variants of that schedule, allowing them to determine
which parts of the schedule are necessary for the bug to reproduce and
hence to produce a minimal bug-reproducing schedule.
Narayanasamy\cite{Narayanasamy2007} later proposed a similar algorithm
using a different replay framework.  The key difference between these
characterisations and the ones produced by {\technique} is one of
emphasis: Delta Debugging aims to produce a characterisation which is
useful to a human developer, whereas {\technique} aims to produce one
which is useful for automatically building \glspl{bugenforcer} and bug
fixes.  This influences which pieces of information are preserved and
which abstracted away and how the preserved information is presented.
The two techniques also impose slightly different restrictions on the
type of bug which is to be investigated: as discussed in
\autoref{sect:types_of_bugs}, {\technique} considers simple atomicity
violation crashes, whereas Delta Debugging considers concurrency bug
which can be reproduced under their deterministic replay system.

Program slicing is another approach to the bug characterisation
problem.  The starting point for this work is the observation that the
hardest part of understanding a bug is often determining which parts
of a large program are actually relevant to it, and so automating this
process would usefully simplify the bug-finding process.  There are
two basic approaches to program slicing: static\cite{Weiser1981} and
dynamic\cite{Agrawal1990a}.  Both of these rely on taking some
representation of the program and then filtering and transforming it
so as to remove aspects which are irrelevant to the bug under
investigation; the difference is that a static program slice starts
from the static program text, whereas a dynamic one starts from a
trace of the program's execution.  Program slices are conceptually
very similar to {\technique}'s {\StateMachines}, albeit derived in a
different way and for a different purpose.  The key difference between
the two representations is that a program slice is usually represented
in the same language as the original program, whereas {\StateMachines}
are expressed in an analysis language.  This makes them easier to
analyse, at the expense of also making them more difficult to derive
and more difficult to relate to the original program's behaviour.

\section{Automatically fixing bugs}

There have been many previous systems which aimed to automatically fix
bugs in programs, and I now give a brief overview of some of the more
important ones.

\subsection{Software rejuvenation and micro-reboots}

In practice, by far the most common approach to ``fixing'' software
bugs, once the software has been released, is simply to restart the
affected system and hope that the problem does not recur.  This is
essentially the idea between software rejuvenation\cite{Huang1995},
which attempted to ameliorate the effects of resource leaks by
periodically rebooting the affected systems.  Later refinements
included attempts to calculate the optimum reboot
schedule\cite{Garg1998,Li2002,Vaidyanathan2001}, and also some
attempts at reducing the cost of reboots
\cite{Candea2002,Patterson2002}.  While undeniably effective, this is
a rather inelegant approach to the problem, and carries very high
cost; most other work on automatic fault remediation can be regarded
as attempts to reduce the frequency with which operators must fall
back on these techniques.

\subsection{Failure obliviousness and related techniques}
More recently, Rinard et al\cite{Rinard2004} described failure
obliviousness, a technique for disguising certain classes of memory
faults in high-availability systems at the (possible) expense of
reduced integrity.  The core of this approach is, in essence, to
downgrade hardware exceptions from errors to warnings, allowing the
program to execute through them as far as possible in the hope that
the problem will self-cleanse rather than propagating further.  Some
faults are trivial to ignore (stores through bad pointers, for
instance, can be simply discarded).  Others require more
sophistication.  In particular, loads of bad pointers must somehow
synthesise a loaded value, and the choice of value can affect the
effectiveness of the technique in important ways.  The original paper
simply used a manually pre-defined sequence of plausible values; later
work expanded upon this by looking at the dynamic dataflow
context\cite{Nagarajan2009} or by using a lookaside table of recently
discarded stores\cite{Rinard2005a}.

The idea behind the reactive immune system\cite{Sidiroglou2005} is
similar, except that rather than trying to discard memory operations
they instead try to convert errors from unhandleable memory errors
into whatever sort of errors the program can handle.  The initial
implementation did this by forcing functions to return immediately
with an error value, obtained by type analysis on the source code;
this was refined in the ASSURE system\cite{Sidiroglou2009} to instead
take snapshots at places where it is convenient to inject errors and
then roll back when an error is detected.  Of course, error handling
is often rather buggy itself, and so recovery to error handling is not
always useful.  This issue was investigated in detail by
S\"{u}\ss{}kraut et al.\cite{Susskraut2006}, who also propose some
techniques for automatically improving its robustness.

One potentially interesting approach, proposed by Elkarablieh et
al.\cite{Elkarablieh2007} in a slightly different context, would be to
try to mine the program for information about the intended contents of
data structures.  This would then provide useful information when
deciding how to synthesise the results of wild reads so as to minimise
the potential for error propagation, or even, in a somewhat extreme
form, to proactively fix data structures which have suffered
corruption.  This potentially increases the effectiveness of error
hiding, but also potentially increases the potential for the program
to generate completely nonsensical results.  In the original paper,
these data structure invariants were obtained from
\verb|assert()|-like statements in the program source, combined with
some basic static analysis.  A later version, proposed by Malik et
al.\cite{Malik}, used Daikon-like detection of statistically justified
invariants during normal program operation, which allowed the
technique to be applied without source code.  ClearView\cite{Perkins}
refines this approach by combining it with an automated testing system
to try to reduce the risk of introducing new bugs.

DieHard\cite{Berger2006} is another application of the failure
oblivious concept to heap-related issues.  In this system, however, no
attempt is made to discover or to enforce data structure invariants;
instead, the heap is structured so as to minimise the probability of
certain common types of bugs causing user-visible errors.  The authors
use two main techniques to achieve this:
\begin{itemize}
\item First, the heap is expanded, such that there are likely to be
  large dead zones between any two allocations.  This makes buffer
  overflows much less dangerous.
\item Second, they avoid reusing heap locations quickly after they
  have been \texttt{free()}d, which reduces the risk of use-after-free
  bugs actually causing problems.
\end{itemize}
Neither of these techniques will eliminate bugs, but they can
dramatically reduce the probability of their causing user-visible
problems (at the expense of dramatically increasing memory
requirements and marginally increasing runtimes).
Exterminator\cite{Novark2007} further builds on this work by using
heuristics to try to identify probable bugs and only applying heap
expansion to allocations which are likely to benefit from it.
Assuming that all such allocations are detected, this retains all of
the bug-fixing benefits of DieHard while noticeably reducing its
overhead (at least in the common case where only a small number of
allocations actually need padding).

The AutoPaG system\cite{Lin2007} tackled a related problem, that of
overflows of stack-based buffers.  In this work, the authors assume
that a buffer overflow has already been identified by some mechanism
(a CCured\cite{Necula2005}-like safe compiler in the paper, but others
are possible), and then apply static analysis to find its root cause
at the source code level.  They then generate a source-level patch
which redirects any out-of-bounds accesses to the array back to a safe
location, in what is essentially a variant of failure obliviousness.
This allows them to mask the bug until a true fix can be obtained,
with very low run-time overhead in both time and space.
Unfortunately, their static analysis is not complete, and so they
must occasionally fall back to a dynamic scheme.

\subsection{Input rectification}

Rather than trying to fix bugs in a program, another strategy is to
sanitise the program's inputs so that it never sees anything which
might upset it.  RX\cite{Qin2007} is one example of such a system.  RX
protects a program reactively.  When it notices that something has
gone wrong, it rolls the program to an earlier checkpoint and then
replays it in a slightly different environment, with slightly
different inputs and a slightly different thread schedule, in the hope
that doing so will avoid the bug.  When it finds a strategy which
works it caches the details of the modifications it made, so that next
time it encounters a similar failure it can simply repeat those
modifications.  In this way it is able to protect the program from the
dangerous inputs without needing any knowledge of the program
structure, and very little knowledge of its interactions with the
environment.  First-Aid\cite{Gao2009} extended RX to handle certain
kinds of heap-related errors using a similar strategy of rolling the
program back and then trying it again with slightly different heap
behaviour; it can be thought of as the union of RX and DieHard.
Bouncer\cite{Costa2007} and Vigilante\cite{Costa2008} used similar
techniques to quickly protect network-facing services from
newly-released worms.

RX's main weakness is that it has no knowledge of the structure of a
program's inputs, and so when it establishes that a bug was triggered
by a particular input it has no choice but to discard it completely.
SOAP\cite{Long2012} tries to rectify this weakness by instead finding
safe approximations to dangerous inputs.  The core of SOAP is a
learning engine which augments a (manually specified) file format
description with a set of safety constraints generated by comparing
the results of a taint analysis to a set of known-safe inputs.  Future
inputs to the program are then rectified so that they satisfy these
constraints.  By providing this intermediate step between passing an
input to the program unchanged and dropping it completely input
rectification gives SOAP much more flexibility than RX when faced with
complex input-dependent bugs, and so gives SOAP-protected programs
better availability than RX-protected ones.  The main disadvantage of
the approach is that these manipulated inputs will usually be more
likely to trigger other undesirable program behaviour; whether this
trade-off is worthwhile will depend on the nature of the program to be
protected.

\subsection{Hardware-based fixes for data races}
All of the fault remediation systems discussed so far in this section
concentrated primarily on memory errors such as bad pointer
dereferences or buffer overflows.  There have also been many systems
which attempted to automatically fix concurrency errors.  One of the
earliest was ReEnact\cite{Prvulovic2003a}, which used modified
thread-level speculation hardware to capture precisely what happened
during a data race or atomicity violation, and then to control
instruction scheduling during subsequent re-executions so as to avoid
the bug in future.  This is similar to the intent of the fixes
generated by {\technique}, with a few exceptions:
\begin{itemize}
\item The ReEnact scheme requires unusual hardware support, whereas
  {\technique} is purely software-based.
\item ReEnact fixes are dynamic, in the sense that the program must be
  constantly monitored to ensure it does not follow a bad schedule,
  whereas the {\technique} fixes statically introduce required locking
  so that bad schedules become impossible.
\item ReEnact requires some (quite modest) amount of programmer
  involvement in order to identify which races are critical to a
  particular bug and hence to direct the fixing process, except in a
  few unusual special cases.  {\Technique}, by contrast, requires some
  minimal programmer involvement to identify some properties of the
  program, but, once that has been done, requires no further manual
  assistance to process each bug.
\end{itemize}
Despite these limitations, ReEnact was able to fix some bugs, and
shows reasonably low run-time overhead (mostly on the order of ten
percent, depending on the benchmark).

Atom-Aid\cite{Lucia2009} is another scheme which tries to use unusual
hardware features to protect against data race and atomicity violation
bugs, but in this case using hardware transactional
memory\cite{Herlihy1993} rather than thread-level speculation.  This
paper grew out of an earlier observation that, in some cases,
processor performance can be improved by bundling sequences of memory
accesses into transactions, and hence batching interconnect operations
and amortising their costs\cite{Ceze2007}.  This has the useful side
effect of eliminating a large number potential instruction
interleavings, and hence a large number of potential synchronisation
bugs.  Atom-Aid attempts to maximise this effect by carefully tweaking
transaction boundaries in response to the program's observed
behaviour, allowing them to hide most atomicity violations with very
low overhead.  Unfortunately, the necessary hardware changes are
unlikely to be widely deployed in the near future, and it is hard to
see how to adapt the system into a software-only implementation, which
limits the technique's applicability.

\subsection{Software-based fixes for data races}
It is also possible to fix data races using ordinary software rather
than exotic hardware.  ConTest\cite{Krena2007} provides one approach
to doing so.  The idea here is quite simple: the program is run under
a data race detection algorithm\footnote{The original paper used an
  ERASER\cite{Savage1997}-based algorithm, but others would work
  equally well.} and any detected races matches against a library of
manually-defined fix patterns which describe how to eliminate a
particular family of race bugs.  In principle, this could be used to
automatically eliminate every race bug in the program, if it can be
analysed for long enough with a sufficiently diverse workload and if
the fix pattern library is sufficiently complete.  In practice, it is
not clear that it is possible to build such a complete library using
the techniques presented in the paper\footnote{The paper only
  considers simple two-access atomicity violation bugs, with more
  complicated patterns deferred to future work.}, making the
technique's generality questionable.  Beyond this, ConTest also
suffers the more philosophical objection that races are not all
concurrency bugs and not all concurrency bugs are races, and so
eliminating races is in some sense solving the wrong
problem\editorial{That came out a little stronger than I'm entirely
  comfortable with.}.  Tallam et al.\cite{Tallam2008} suggested
essentially the same mechanism a year later, but restricted themselves
to uniprocessor execution (so the only parallelism is the
coarse-grained variant provided by the operating system's thread
abstraction); this allowed them to make some simplifications to their
implementation, but further reduced the useful scope of the technique.

ToleRace\cite{Kirovski2007}, which attempts to provide toleration for
asymmetric races, provides another useful point in the design space.
An asymmetric race is defined by the authors to be a situation where
some thread correctly follows a locking discipline (which must be
manually specified by the programmer), but another thread does not,
and thus causes the correct thread to fail.  This presents a challenge
when debugging, as most na\"{i}ve approaches to postmortem analysis
will blame the wrong thread for the crash.  ToleRace ameliorates this
class of problems by arranging that when a thread acquires a
particular lock, a local copy of all of the values protected by the
lock is taken, with any accesses to protected variables made while
holding the lock redirected to the copy.  This prevents the correct
thread from seeing the effects of incorrect threads while it is in the
critical section, and so the race is much less likely to cause serious
problems.  The scheme used by ToleRace did not, however, guarantee
that this copy was itself internally consistent in the presence of
asymmetric races, as the copying process was not atomic, and so
correct threads could still easily be undermined by races with
incorrect ones.  \textsc{Isolator}\cite{Ramalingam2009} fixes this
defect by introducing implicit per-page locks enforced using virtual
memory techniques.  However, it is still necessary for the programmer
to provide a manually-specified locking discipline, which makes these
techniques difficult to use in practise.

AVIO\cite{Lu} is another approach to automatically fixing
concurrency-related bugs.  It is essentially the application of
program stereotyping ideas (\autoref{sect:rw:stereotyping}) to shared
memory concurrency: the program's execution is observed for some
amount of time whilst AVIO builds up a model of how its memory
accesses interleave when it is behaving normally, and future
executions are then shepherded so that only those normal interleavings
are possible.  The intuition here is that bugs are unusual events, and
so preventing anything unusual from happening will prevent any bugs
from occurring.  The weakness, of course, is that sometimes something
unusual does happen (if, for instance, the program receives some input
which was not adequately covered by the training data), and AVIO will
be unable to provide protection in this case.  AVIO also has the
weakness that it requires unusual hardware support in order to achieve
good performance; while it can be implemented purely in software, the
software implementation causes a roughly twenty-five-fold slow-down,
making it impractical to use in production systems.

Kivati\cite{Chew2010} can be thought of as a refinement to AVIO which
reduces these weaknesses.  In Kivati, the access interleaving
invariants are discovered by means of a static analysis conducted
before the program starts running.  This set is usually far smaller
than the set which is discovered by AVIO.  That then allows Kivati's
second refinement, which is to enforce the invariants using the
processor's watchpoint registers\cite[Chapter 16.2: Debug
  Registers]{Intel2009}, obviating the need for custom hardware.  The
result is a similar level of protection to AVIO but with far less
overhead, usually on the order of a few tens of percent.  Kivati's
main weakness is that it can only protect against single-variable
races, due to limitations in the static analysis used.  Even if the
static analysis were extended, limitations on processor watchpoint
facilities would prevent it from considering large numbers of
variables at the same time.  {\Technique} does not share this
limitation, and the fixes it generates have noticeably lower overhead.
The downside, of course, is that {\technique}'s initial analysis phase
is far more expensive than Kivati's.

AFix\cite{Jin2011} is another example of a system for automatically
fixing concurrency bugs.  It works by patching additional lock
operations into LLVM bitcode so as to eliminate atomicity violation
bugs.  At a high level, the algorithm is quite similar to that used to
generate {\technique} fixes: convert a description of the atomicity
violation into critical sections, map those critical sections onto
contiguous fragments of the program's \gls{cfg}, and then introduce
additional synchronisation so as to make those \gls{cfg} fragments run
atomically with respect to each other.  There are, however, several
important differences.  Most obviously, the AFix algorithm considers
only simple two-access critical sections, whereas the {\technique} one
can enforce more complex $n$-access ones.  Even where there are
precisely two accesses to be protected, the set of instructions in the
critical section can differ slightly, because {\technique} will exit
the critical section if the thread leaves {\StateMachine}'s dynamic
\gls{cfg}, whereas AFix exits if the thread cannot reach another
protected instruction in the current function invocation.  This can be
either an advantage or a disadvantage, depending on why an instruction
is missing from the {\StateMachine} \gls{cfg}.  Some instructions will
be missing because they were cut off by the \gls{alpha} limit on the
\gls{analysiswindow}; releasing the lock for these instructions is
usually undesirable, as it re-introduces some of the concurrent
interleavings which the patch was supposed to eliminate.  Other
instructions will be missing because an earlier analysis phase has
shown that the program cannot suffer the bug if it follows that path;
releasing the lock here is safe, and can sometimes lead to better
parallelism and liveness behaviour.

AFix was later generalised to CFix\cite{Jin2012}, which adds support
for fixing certain ordering violations by patching in condition
variable operations.  Most other automated bug-fixing systems
(including {\technique}) largely ignore ordering violations.  Such
bugs account for roughly a third of real-world concurrency
errors\cite{Lu2008}, and so this is a large problem which is not
well-addressed by other work.  \todo{Say more}

ConAir\cite{Zhang2013} and ConMem\cite{Zhang2010} take a completely
different approach to fixing concurrency bugs.  Rather than trying to
prevent the bad interleavings from happening, they instead allow the
program to suffer the bug, and then roll the one buggy thread back and
retry it in isolation, in the hope that whatever it was that caused it
to go wrong will have resolved itself.  Until the failure is detected,
ConAir does not make any modifications to the program's behaviour.
This gives it very low overhead, but makes it problematic to roll
threads back after they have performed any non-idempotent
transformations of the program state, including most modifications to
shared memory.  The restriction to idempotent re-execution regions is
similar to {\technique}'s \gls{w-isolation} assumption: ConAir can
only re-execute regions which cannot influence another thread's
behaviour, and {\technique}, when the \gls{w-isolation} assumption is
enabled, can only analyse \glspl{crashingthread} which do not
influence the \gls{interferingthread}'s behaviour.  In fact, the
restriction on ConAir is somewhat stronger than the \gls{w-isolation}
assumption, as it cannot re-execute any code which \emph{might}
influence another thread, whereas \gls{w-isolation} is only violated
if every path which triggers the bug involves that kind of influence.

Aviso\cite{Lucia2013} presents another variant on this approach.  Like
ConAir, Aviso starts by allowing the program to suffer the bug at
least once and then modifies the schedule so that it does not suffer
it again.  Unlike ConAir, though, Aviso does not attempt to roll-back
any threads, but instead records that the schedule is bad.  They then
observe multiple runs of the program, potentially across multiple
machines, so as to statistically infer a causal relationship between
properties of the schedule and the reproduction of the bug.  These can
then be used to avoid the bug in future runs. \todo{Need something
  more here.}

\subsection{Deadlock bugs}
The final class of bugs considered here is deadlocks.  Techniques for
healing deadlocks in multithreaded applications have only been
investigated relatively recently\footnote{Deadlock avoidance has been
  studied in other contexts for much longer; see
  e.g. \cite{Dijkstra2004} or \cite{Viswanadham1990}.}.  One of the
earliest, proposed by Nir-Buchbinder et al.\cite{Nir-Buchbinder2008},
was to build the dynamic lock graph as the program runs, discover any
strongly-connected components (SCCs), and then reduce every SCC to a
single lock.  This eliminates the potential for any lock order
reversal (LOR) deadlock involving that cluster of locks, and would, if
a complete lock graph were available, completely eliminate all LOR
deadlocks in the program.  Unfortunately, dynamically collected lock
graphs are inherently potentially incomplete, and this means that the
healing is incomplete, and can in fact introduce new deadlocks in
certain situations.  Even when the lock order graph is complete, this
approach can sometimes require a very large number of locks to be
merged, leading to excessive loss of concurrency and a concomitant
high performance cost.

Gadara\cite{Wang2008} tackled both of these problems.  First, they
used static analysis to build a conservative approximation of the lock
graph (rather than the optimistic one produced by a dynamic analysis).
Second, they use discrete control theory to derive a ``controller''
co-program which inserts delays in the dynamic program execution in
some minimal set of places so as to avoid deadlocks, without
introducing unnecessary serialisation.  Of course, the use of a
conservative approximation means that they will occasionally detect a
deadlock where none is actually possible, and this will lead to
additional synchronisation operations; it is unclear from the paper
whether Gadara-protected systems are more or less serialised than
Nir-Buchbinder-protected ones.  At a high-level this controller is
conceptually similar to the message-passing machines used in
{\technique}'s crash enforcers, although the details and purpose of
the technique are significantly different.

It is also possible to make progress on these problems in a purely
dynamic system.  For instance, Dimmunix\cite{Jula2008} waits until the
program deadlocks, characterises the deadlock by means of a
``signature'', and then delays future lock acquire operations so as to
ensure that the signature cannot reoccur.  The hope is that preventing
the signature will also prevent the deadlock, and hence that the
program will, over time, become immune to whatever deadlocks might be
lurking in it.  Because it only fix deadlocks which have actually been
observed, serialisation is kept low and the need for complete locking
information is side-stepped, although at the cost of having to suffer
every deadlock at least once in order to fix it.

\subsection{Deterministic multi-threading}

Deterministic multi-threading systems, such as
Determinator\cite{Aviram2010} or dOS\cite{Bergan2010}, take a
different approach to concurrency bugs.  Rather than trying to detect
or fix such bugs, they instead design the runtime environment as to
make such bugs deterministic.  Concurrency bugs in a deterministically
multi-threaded system will either reproduce every time, in which case
they will be fixed quickly, or will never reproduce at all, in which
case they do not matter.

The most direct way of ensuring determinism, recommended by
Determinator, is to make the API presented to programmers
deterministic, so that there is simply no way for applications to do
anything which even appears to be non-deterministic.  In the case of
Determinator, this means that the main form of parallelism supported
is fork-join, with shared-memory parallelism implemented as a merge
operation on memory, analogous to the merge operation in a distributed
version control system\cite{Hamano2013}.  This is easy to understand
and has very respectable performance, and would arguably have been a
very good idea thirty years ago; unfortunately, deploying it today
would require that vast amounts of existing software be re-implemented
to use the new API, making it impractical for any but quite specialist
environments.

Rather than requiring that the API itself be deterministic, it is also
possible implement an existing API in a deterministic way, allowing
determinism to be retrofitted to existing operating systems without
discarding the existing investment in concurrent software.  This is
the approach advocated by dOS\cite{Bergan2010} and
\textsc{DThreads}\cite{Liu2011}.  The key observation behind these
systems is that most APIs are mostly deterministic, and so in practice
most parts of a program's execution are also inherently deterministic.
It is therefore only necessary to impose additional ordering on a
small number of operations.  \textsc{DThreads} and dOS achieve this by
dividing a program's execution into concurrent epochs, in which every
program thread advances but none are allowed to perform
ordering-dependent operations such as racing memory accesses, and
non-concurrent ones, in which only a single thread runs but that
thread is allowed to perform any operation.  Careful management of the
transition between epochs allows these systems to ensure that
executions are always completely deterministic, and hence that bugs
either reproduce every time or never reproduce at all.

\section{Decompilation and other analysis of machine code}

{\Technique}'s approach to generating {\StateMachines} from machine
code can be viewed as a form of decompilation, in the sense that it
takes a low-level representation of a program and converts it to a
higher-level one.  The most important difference is that decompilation
aims to preserve all of the behaviours of the program, whereas
{\technique} seeks only to preserve those behaviours which are most
relevant to the bug which is being investigated.  Cifuentes'
dissertation\cite{Cifuentes1994} provides a thorough, if now quite
outdated, overview of the field; Emmerik and
Waddington\cite{Emmerik2004} described some of the issues commonly
encountered when attempting to use these techniques in practice.

CodeSurfer\cite{Balakrishnan2005a,Balakrishnan2008}, also known as
WYSINWYX, is a more recent example of a decompilation platform.  The
intent here is to provide a human user with assistance in determining
what a binary-only program does, rather than supporting extensive
automated analyses.  It has only limited support for multi-threaded
programs, making it hard to compare directly to {\technique}.  On the
other hand, it does support an advanced memory aliasing analysis,
value-set analysis\cite{Balakrishnan2004}.  Aliasing analysis is
currently one of {\technique}'s major weaknesses, and so combining
these techniques might produce interesting results.

Decompilation is not the only kind of analysis which has been applied
to machine code.  BAP, the Binary Analysis Platform\cite{Brumley2011},
is one of the more recent examples.  This is a set of tools used to
convert machine code into an intermediate language suitable for other
forms of analysis.  As such, it is very similar to {\technique}'s
{\StateMachine} building process.  The chief difference is that BAP
does not consider multi-threaded programs at all, whereas that is the
primary purpose of {\technique}.  Along the same lines, the
BitBlaze\cite{Song2008} project designed a number of analyses on
machine code intended to uncover security problems given only a binary
program.  \todo{Not quite sure what that paragraph was trying to
  achieve.}

\section{Theorem proving and SAT solving techniques}

{\Technique} represents its \glspl{verificationcondition} and most
internal predicates as boolean BDDs whose variables are expressions in
the {\StateMachine} expression language (see
\autoref{sect:derive:state_machines}), augmented with some simple
arithmetic simplification and canonicalisation rules.  A
\gls{verificationcondition} is considered to be satisfiable if these
cannot reduce the BDD to \false.  This can be thought of as a very
simple Satisfiability Modulo Theory (SMT) solver\cite{Barrett2009},
with the BDD library implementing the satisfiability part and the
arithmetic rules providing the theory.  As such, it might be
interesting to investigate replacing these components with an existing
standard SMT solver such as Z3\cite{Moura2008} or
Yices\cite{Dutertre2006}.  This might eliminate some of the analysis
phase's false positives, and hence reduce the number of
\glspl{bugenforcer} which need to be generated and tested.

Some preliminary experiments suggested that the number of false
positives which could be eliminated in this way is actually quite
small: of a random sample of ten false positives generated from
mysqld, only one was caused by arithmetic incompleteness; the others
were caused by {\technique}'s weak models of the program's aliasing
and concurrency behaviour.  Also, in another experiment, I implemented
a much more powerful lazy DPLL-based satisfiability
checker\cite{Davis1962}, and this did not eliminate enough false
positives to justify its high computational cost.  On the other hand,
a more powerful SMT solver might allow some true negatives to be
eliminated more quickly, which might help to reduce the cost of the
main analysis phase.

\section{Discussion}
\todo{I'm pretty certain I need something to close out the chapter,
  but I'm not quite sure what.}
