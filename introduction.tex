\section{Motivation}

Commodity hardware is becoming increasingly concurrent, whether due to
more packages per machine, per cores per package, or more threads per
core, and software is adapting to make use of this greater
concurrency.  This promises greater performance, but at the same time
introduces a greater risk of serious concurrency bugs.  Even worse,
the nature of concurrency bugs means that they often reproduce only
intermittently, or only on particular classes of physical hardware,
and so they are more likely than non-concurrency bugs to survive
testing, and hence to cause problems for end users.  There is
therefore a need for tools to help discover and fix such bugs.  At the
same time, much software is ``abandonware'': no longer supported by
its original authors, or supported in only a derisory fashion.  It
would therefore be useful to have tools which can provide some help in
fixing such bugs without access to the source or help from the
original developers.  This dissertation presents one possible approach
to doing so: a set of techniques which can, first, slice a binary
program to find parts which are relevant to a specific bug; second,
analyse those slices to produce a dynamic analysis specifically
targeted at that specific bug; and, third, automatically generate a
fix for the bug.  The same analysis can also be used to find all
possible bugs of a specific class in the program.  The algorithms
involved have several modes of operation, most of which require
minimal programmer involvement; the rest require none at all, beyond
reproducing the bug which is to be fixed.

One the other hand, the class of bugs to be targeted is somewhat
limited: two threads interacting, with one modifying a shared
structure while a second reads it, causing the reading thread to crash
quickly in a recognisable way.  The precise definition of ``quickly''
depends on the mode of operation and the program to be analyses, but
will usually be dozens to hundreds of instructions.  This is a serious
limitation, but still allows some realistic bugs to be analysed.

\todo{I did have a reference saying that some reasonable proportion of
  real concurrency bugs falls into that category (like 30\% or so),
  but (a) I've lost the reference, and (b) having actually played with
  this a bit, I \emph{really} don't believe that any more.}

\todo{To be honest, I'm not really convinced by the abandonware story
  any more, which complicates things a bit.  A lot of the
  \emph{actual} motivation for this was having to reverse-engineer
  chunks of Windows while I was at Citrix, but I'm not sure that's
  something I really want to emphasise.}

\todo{I'm possibly quite unusual in having actually fixed concurrency
  bugs in real programs by hacking up the machine code?  ``A tool to
  help you do X'' isn't very useful if there only a couple of dozen
  people who would have even considered doing X in the first place.}

\section{Overview of approach}

\begin{figure}
\begin{tikzpicture}
  [block/.style = rectangle,draw,fill=blue!20,
    line/.style = draw, -latex']
  \node [block] (dynamic) {Dynamic analysis};
  \node [block, below right = of dynamic] (model) {Program model};
  \node [block, below left = of model] (static) {Static analysis};
  \node [block, right = of model] (candidates) {Candidate bugs};
  \node [block, right = of candidates] (repro) {Reproductions of bugs};
  \node [block, right = of repro] (fix) {Generated fixes};
  \path [line] (dynamic) -- (model);
  \path [line] (static) -- (model);
  \path [line] (model) -- (candidates);
  \path [line] (candidates) -- (repro);
  \path [line] (repro) -- (fix);
\end{tikzpicture}
\caption{Basic pipeline}
\label{fig:basic_pipeline}
\end{figure}

In its simplest mode, SLI uses a multi-stage pipeline to find and fix
bugs in arbitrary binary programs, as shown in
figure~\ref{fig:basic_pipeline}.  The pipeline starts by building up a
model of the program's behaviour using a combination of static
analysis, applied to the program's binary, and dynamic analysis,
applied while the program is operating normally.  A mixture of
symbolic execution and static analysis is then used to produce a set
of candidate bugs: places in the program which might have a bug of the
target class, if the program can be driven into a particular
configuration.  This set will be very large for most realistic
programs and will usually contain a large number of false positives,
and so is not, of itself, particularly useful.  The next stage of the
analysis is therefore to prune it back to just those bugs which can
definitely happen.  Most existing static analysis and model checking
systems will do so by layering on further layers of increasingly more
complex analysis algorithms.  I take a different approach: modifying
the program so as to make the bugs more likely to reproduce and then
using the program's existing test suite to drive it towards them.  In
effect, SLI turns its bug description into a new dynamic analysis
which specifically attempts to reproduce that bug.  Since SLI mostly
targets concurrency bugs, these modifications mostly consist of
inserting additional delays, and hence encouraging the program to
follow the desired schedules as far as possible.  The bugs which
survive this winnowing process are then definitely real bugs, and can
either be manually reviewed by a programmer or passed to the next
phase which produces a fix targeted at that specific bug, completely
automatically.  In addition to this basic mode of operation, SLI can
also take as input a core dump or the log from a deterministic replay
system and use that to produce a fix for a specific bug.

I give a detailed description of this analysis and the fixes generated
for a selection of bugs, both artificial ones and some from real
programs, and show that the analysis scales to realistically large
programs with acceptable computational cost.  This includes bugs which
were unknown to the author before writing the tool\editorial{Or, more
  precisely, one bug which was unknown to me before writing the tool
  but which was known to the program's original developers, and which
  is a trivial variation of a bug which I did know about.  But, you
  know, take your victories where you can get them.}.  I also show
that the fixes generated often have sufficiently low overhead to be
useful; usually a few percent in more realistic tests.  Finally, I
give the results of a small set of experiments intended to show that
my implementation of these techniques is itself correct.

\todo{I'm currently calling the static analysis pass whole-program
  static analysis, which is accurate in the sense that it looks at the
  whole program rather than at the bits relevant to one bug, but also
  kind of deceptive in that it (mostly) looks at it one function at a
  time, which is the opposite of the meaning of ``whole-program
  analysis'' as used in the compilers literature.}

The basic analysis technique used, in all of these modes, is to take
some small fragment of a binary program and approximate it using a
\StateMachine\editorial{Desperately need a better name for these.},
using a combination of decompilation, program slicing, and static
analysis techniques.  These \StateMachines contain all of the
information which is relevant to the bug being investigated but very
little irrelevant information, making them far easier to analyse than
the raw machine code.  They have a number of important properties:

\begin{itemize}
\item
  They can cross function boundaries, including between the program
  itself and library functions\editorial{But only in certain modes: I
    was a bit lazy in the bug-finding mode and restricted things to
    the main binary.  It's just an artifact of the implementation, and
    could be fixed without too much pain, but not in the time I have
    left.}.
\item
  They can contain information from multiple program threads, and so
  can accurately capture all of the threads relevant to a particular
  race, but are themselves completely deterministic, aiding simple
  analysis.  In particular, the \StateMachine for a particular bug can
  be used to build the happens-before graph necessary for that bug to
  reproduce (including when that happens-before graph is
  data-dependent).
\item
  \STateMachines can incorporate information obtained by the initial
  static and dynamic analysis passes in a reasonably straightforward
  way.
\item
  Control-flow within a \StateMachine is not necessarily the same as
  control flow within the original program, and memory accesses within
  a \StateMachine do not necessarily correspond to specific memory
  accesses in the original program, but can be related back when
  necessary.  This means that intermediate analysis steps have a great
  deal of flexibility to rewrite \StateMachines to remove unnecessary
  information without unduly complicating actually using the results
  of the analysis.
\item
  They can be interpreted, given a snapshot of the program's state, to
  make a prediction about whether the program might, starting from
  that state, suffer the bug which is being investigated.
  Alternatively, they can be symbolically executed to determine what
  initial states might lead to the bug.
\item
  Individual \StateMachines must complete in a finite, bounded, number
  of operations; equivalently, \StateMachines are acyclic and finite.
  This makes them far easier to analyse, but at the expense of
  somewhat limiting their expressive power.  In the particular case of
  SLI, we are only interested in bugs related to fairly small
  fragments of the program (those which should have been critical
  sections, but aren't) and so this is a tolerable limitation; it
  might be more of a concern in other applications.
  Section~\todo{...} briefly discusses some possible ways of removing
  this restriction.
\end{itemize}

\STateMachines are in many respects similar to executable program
slices of the original program, with the key difference that, unlike a
program slice, a \StateMachine is not expressed in the same language
as the original program.  This is to some extent a forced decision
(SLI operates on binaries, whereas most program slicing systems
operate on source code; programming languages are not usually
particularly convenient intermediate forms, but machine code is far
worse), but the extra flexibility can sometimes make this more
convenient than more conventional source-level program
slices\editorial{Should maybe have a forward ref here?}.

A somewhat closer analogy is with the abstract models commonly used in
formal verification systems such as Promela\needCite{}.  The
difference here is in the semantic structure of the program to be
modelled: SLI models machine-code programs, and hence has no knowledge
of higher-level constructs such as variables, arrays, or compound
structures, whereas a tool like Promela or SAL\needCite{} work with
source code and hence (mostly) assume that such information is
available.  While it would be possible in principle to extract such
information and hence build a SAL or Promela model, doing so would
itself be somewhat time-consuming.

Once a \StateMachine for a bug has been obtained, the analysis moves
on to attempting to reproduce it.  SLI does so by first examining the
\StateMachine to determine the happens-before graph necessary for the
target bug to reproduce, along with any appropriate side-conditions,
and then building a custom dynamic analysis for the original program
which makes that happens-before graph more likely to occur.  The
original program's original test suite is then used to exercise it,
thus confirming that the bug actually does (or does not) exist.
Several such happens-before enforcers can be run on each program at
any one time, which can significantly reduce the time taken for this
verification step.

Finally, the now-confirmed bug can be converted into a fix.  In this
mode, SLI again examines the happens-before graph implicit in the
\StateMachine and uses it to extract a set of critical sections of the
original program.  With these in hand, SLI can produce a modified
version of the original program which ensures that no critical
sections ever execute in parallel with each other, hence eliminating
the original bug.

\editorial{Cite Holzmann and Smith, 2001}.

\section{Contributions}

\begin{itemize}
\item
  Suggest a novel method of finding concurrency-related bugs given
  only a binary program and some way of running it.
\item
  Describe how the bug description produced when trying to find a bug
  can instead be used to automatically fix the same bug.
\item
  Propose a couple of ways of simplifying cross-function and
  cross-thread slices of a binary program.
\item
  Evaluate these techniques, showing that they can find and fix bugs
  in simple programs quickly, and that the analysis techniques
  \todo{(just about)} scale up to find real bugs in realistic
  programs.
\item
  I further give some evidence that my implementation of these
  techniques is itself correct, so that the other parts of the
  evaluation are likely to be correct.
\end{itemize}

\todo{Maybe include explicit comparisons to related work in here?}
