\todo{Need to think about names of things.  In particular, it'd be a
  good idea to have different names for the \emph{technique} and the
  \emph{implementation}; the current text conflates them a bit, and
  giving them different names might make that a bit more clear.  I've
  used \technique{} and \implementation{} in a few places as
  placeholders.}

\todo{The main thing missing here is a well-defined thesis.  Need to come
  up with one pretty damn quickly.}


\section{Motivation and overview}
\label{sect:intro:overview}

Commodity hardware is becoming increasingly concurrent, whether due to
more packages per machine, per cores per package, or more threads per
core, and software is adapting to make use of this greater
concurrency.  This promises greater performance, but at the same time
introduces a greater risk of serious concurrency bugs.  Concurrency
bugs are particularly difficult to fix, due to their inherent
non-determinism, and so it would be useful to have some tools to
assist in this.  This dissertation presents automated techniques to
discover, characterise, reproduce, and then fix a certain class of
concurrency bugs.

\begin{figure}
\begin{center}
  \begin{tikzpicture}
    [block/.style = rectangle,draw,fill=blue!20,
      line/.style = draw, -latex']
    \node [block,draw] (dynamic) {Running program};
    \node [block,draw, below = of dynamic] (model) {\introduction{Program model}};
    \node [block,draw, below = of model] (statemachines) {\introduction{\StateMachines}};
    \node [block,draw, below = of statemachines] (candidates) {\introduction{Candidate bugs}};
    \node [block,draw, below = of candidates] (repro) {Reproduction};
    \node [block,draw, below = of repro] (fix) {Fixes};
    \path [line,->] (dynamic) to node [right] {\introduction{Dynamic analysis}} (model);
    \path [line,->] (model) to node [right] {\introduction{Program abstraction}} (statemachines);
    \path [line,->] (statemachines.west) to node [left] {\introduction{{\StateMachine} simplification}} (statemachines.west);
    \path [line,->] (statemachines) to node [right] {\introduction{Symbolic execution}} (candidates);
    \path [line,->] (candidates) to node [right] {\introduction{Bug enforcers}} (repro);
    \path [line,->] (dynamic.west) to (repro.west);
    \path [line,->] (repro) to node [right] {\introduction{Fix generation}} (fix);
  \end{tikzpicture}
  \caption{Basic pipeline}
\end{center}
\label{fig:basic_pipeline}
\end{figure}

The basic approach is shown in Figure~\ref{fig:basic_pipeline}.  The
process starts by building a
\backref{model} of the program's behaviour using \backref{dynamic
  analysis} (Section~\ref{sect:dynamic_analysis}).  This
\backref{model} is then used to locate potentially relevant fragments
of the program and to build {\StateMachines} which model their
behaviour (Section~\ref{sect:derive}).  {\Technique} then uses a
variety of analysis passes to simplify the {\StateMachines} and to
remove any information which is not relevant to the bug under
investigation (Section~\ref{sect:simplify}).  These simplified
{\StateMachines} are then \backref{symbolically executed} to determine
whether they might exhibit the bug under investigation, and, if so,
under what circumstances; the results are summarised as a set of
candidate bugs (Section~\ref{sect:symbolic_execution}).  This set
usually contains a large number of false positives, and so the next
step is to prune it back down using \backref{bug enforcers}: special
schedulers which, when applied to the running program, make it far
more likely that the bug will reproduce quickly
(Section~\ref{sect:bug_enforcers}).  Any bugs which do reproduce can
then be passed to the final \backref{fix generation} phase which
binary patches the program to introduce synchronisation which
eliminates the bug (Section~\ref{sect:fix_generation}).

{\Technique} only considers only a subset of concurrency bugs: those
where one thread, referred to as the ``crashing thread'', is reading
from shared data structure while another thread, the ``interfering
thread'', simultaneously modifies it, and these concurrent updates
cause the crashing thread to crash quickly.  In a little more detail:

\begin{itemize}
\item The threads must be operating on a data structure located
  somewhere in shared memory.  The data structure does not need to be
  in contiguous memory, and does not need to correspond to any
  higher-level concept of a data structure such as a C++
  \texttt{class} or \texttt{struct}, but it does need to be in
  process-accessible memory.  Structures on the filesystem, for
  instance, are not considered.
\item The crashing thread must crash in a detectable way.  The
  simplest case is a hardware-detected fault such as referencing bad
  memory or dividing by zero, but more complex types of fault could
  also be supported, if a suitable detector can be implemented.
  {\Implementation} includes detectors for hardware-detected faults,
  assertion-failure type errors, and some types of double-free error.
  \todo{Should maybe have a ref here?}
\item The crash must be caused by the concurrent updates.  There must
  be some regions of the crashing and interfering threads such that
  running those regions in parallel can crash but running them
  atomically, in either order, will not.
\item The crashing thread must crash quickly.  {\Technique} uses a
  finite \introduction{analysis window} \introduction{$\alpha$} and
  will only consider reordering concurrent operations which occur at
  most \backref{$\alpha$} instructions before the crash.  Bugs which
  require knowledge of the program behaviour beyond that window cannot
  be analysed.  Equivalently, {\technique} only considers bugs which
  can be fixed by small critical sections containing fewer than
  $\alpha$ dynamic instructions.  \backref{$\alpha$} can, in
  principle, be arbitrarily large, but computational constraints mean
  that in practice it will be limited to a few dozen to a few hundred
  instructions, depending on the program to be analysed and how much
  information about the bug is available before analysis starts.
\end{itemize}

This clearly does not include every possible type of concurrent bug
(it does not, for instance, include any but the most trivial deadlock
bugs, and complicated memory corruption bugs are difficult to handle),
but it does include some interesting bugs.
Section~\ref{sect:future_work:generalising} considers some possible
ways of relaxing some of these restrictions.

One important decision which must be made when designing this kind of
tool is how much higher-level semantic information to use, and in
particular whether to operate at the level of machine code or source
code.  Working with machine code gives a tool the most precise
description of the program's behaviour, as concurrency bugs often
depend on the precise details of compiler optimisations, and is
inherently language-independent; on the other hand, source code
provides far more useful information, and so is usually far easier to
analyse.  {\Technique} takes the extreme position of operating on
machine code as far as possible, only relying on access to source code
when absolutely necessary.  For some non-trivial programs, including
Thunderbird and pbzip2, the technique can produce useful results
without any access to source code at all, and for most others very
little information is needed (MySQL, for instance, required two
functions related to memory allocation to be manually annotated).

\section{Contributions}

This dissertation makes several contributions:

\begin{itemize}
\item
  Suggest a novel method of finding concurrency-related bugs given
  only a binary program and some way of running it.
\item
  Describe how the bug description produced when trying to find a bug
  can be used to automatically fix the same bug or to make the bug
  more easily reproducible.
\item
  Evaluate these techniques, showing that they can find and fix bugs
  in simple programs quickly, and that the analysis techniques scale
  up to find real bugs in realistic programs.
\end{itemize}

I give a detailed description of {\technique} and some results
obtained using \implementation, my implementation of it.  These
include details of the fixes generated for a selection of bugs, both
artificial ones and some from real programs (including one which was
unknown to the author before writing the tool), and a demonstration
that the analysis scales to realistically large programs with
acceptable computational cost.  I also show that the fixes generated
often have sufficiently low overhead to be useful; usually a few
percent in more realistic tests.  Finally, I give the results of a
small set of experiments intended to show that \implementation{} is a
correct implementation of \technique{}, so that the other results are
likely to reflect true properties of {\technique} and not simply bugs
in {\implementation}.

\section{Memory model}

{\Technique} assumes that the processor implements a strongly-ordered
memory model, so that accesses issued by a single are never reordered.
It therefore cannot precisely model the behaviour of any processor in
widespread use today.  On the other hand, this is a reasonable
approximation for the behaviour of the widely-used AMD64
architecture\needCite{}, where memory reordering is a rare and highly
constrained event.  This limitation is not, therefore, completely
crippling.

{\Technique} also assumes that the program does not make use of any
unaligned memory accesses.  For many architectures this would be a
sound assumption, as most processors do not support such accesses;
even where they are supported, they are generally very slow, and so
most programs will avoid them wherever possible, and so this is not a
major source of unsoundness.

\todo{I should maybe mention somewhere that I'm ignoring signal
  handlers?}

\todo{Also assumes a simple accessible/not accessible model of memory
  protection, rather than considering readable/writable/executable
  separately.}

\todo{And I assume that I know about all of the things which might
  update a given memory location i.e. no \texttt{MAP\_SHARED} etc.}

\subsection{Program slicing}

Program slicing\editorial{Cite Weiser 1984} is a family of techniques
for extracting the parts of a program which are relevant to some
particular behaviour.  A slice might, for instance, include all
statements which might be involved in computing the value of some
variable, or all of those which modify some data structure.  The core
technique used is a form of dependency-chasing: some initial set of
program statements are marked as necessary, then everything which
influences one of the necessary statements is marked as necessary, and
the process repeats until the set of necessary statements reaches a
fixed point.  The slice then consists of all of the statements in the
necessary set, combined so that they form a valid program.  There are
many variants of this basic algorithm, using different definitions of
``influence'' and different approaches for recombining the statements,
but the intent in all cases is to form a simplified version of the
program which can be used to more easily investigate some aspect of
its behaviour.

Program slices are conceptually very similar to {\StateMachines},
which also approximate a program so as to allow some aspect to be more
easily explored.  The key difference is that a classical program slice
will be expressed in the same language as the original program,
whereas as a {\StateMachine} translates the program's machine code
into an analysis language.  This makes them much easier to analyse,
but at the expense of making them more difficult to derive.

\todo{This makes no sense.} The nature of the aspects to be explored
also differs.  Most program slicing techniques slice programs
according to simple single-threaded data flow properties, and hence
are primarily useful for exploring single-threaded behaviour.
{\Technique} {\StateMachines}, by contrast, are primarily useful for
investigating cross-thread behaviour.

\subsection{The happens-before graph}

\todo{I define an HB graph to be a DAG whose nodes are program events
  and where there's an edge from A to B if A happens before B.  I
  thought that was the standard definition, but Steve has a different
  and more complicated one.  I should chase that to make sure I'm
  using the term correctly.}
