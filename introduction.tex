\todo{Need to think about names of things.  In particular, it'd be a
  good idea to have different names for the \emph{technique} and the
  \emph{implementation}; the current text conflates them a bit, and
  giving them different names might make that a bit more clear.  I've
  used \technique{} and \implementation{} in a few places as
  placeholders.}

\section{Motivation}

Commodity hardware is becoming increasingly concurrent, whether due to
more packages per machine, per cores per package, or more threads per
core, and software is adapting to make use of this greater
concurrency.  This promises greater performance, but at the same time
introduces a greater risk of serious concurrency bugs.  Even worse,
the nature of concurrency bugs means that they often reproduce only
intermittently, or only on particular classes of physical hardware,
and so they are more likely than non-concurrency bugs to survive
testing, and hence to cause problems for end users.  There is
therefore a need for tools to help discover and fix such bugs.  At the
same time, much software is ``abandonware'': no longer supported by
its original authors, or supported in only a derisory fashion.  It
would therefore be useful to have tools which can provide some help in
fixing such bugs without access to the source or help from the
original developers.  This dissertation presents one possible approach
to doing so: a set of techniques which can, first, slice a binary
program to find parts which are relevant to a specific bug; second,
analyse those slices to produce a dynamic analysis specifically
targeted at that specific bug; and, third, automatically generate a
fix for the bug.  The same analysis can also be used to find all
possible bugs of a specific class in the program.  The algorithms
involved have several modes of operation, most of which require
minimal programmer involvement; the rest require none at all, beyond
reproducing the bug which is to be fixed.

One the other hand, the class of bugs to be targeted is somewhat
limited: two threads interacting, with one modifying a shared
structure while a second reads it, causing the reading thread to crash
quickly in a recognisable way.  The precise definition of ``quickly''
depends on the mode of operation and the program to be analyses, but
will usually be dozens to hundreds of instructions.  This is a serious
limitation, but still allows some realistic bugs to be analysed.

\todo{I did have a reference saying that some reasonable proportion of
  real concurrency bugs falls into that category (like 30\% or so),
  but (a) I've lost the reference, and (b) having actually played with
  this a bit, I \emph{really} don't believe that any more.}

\todo{To be honest, I'm not really convinced by the abandonware story
  any more, which complicates things a bit.  A lot of the
  \emph{actual} motivation for this was having to reverse-engineer
  chunks of Windows while I was at Citrix, but I'm not sure that's
  something I really want to emphasise.}

\todo{I'm possibly quite unusual in having actually fixed concurrency
  bugs in real programs by hacking up the machine code?  ``A tool to
  help you do X'' isn't very useful if there only a couple of dozen
  people who would have even considered doing X in the first place.}

\section{Overview of approach}
\label{sect:intro:overview}

\begin{figure}
\begin{tikzpicture}
  [block/.style = rectangle,draw,fill=blue!20,
    line/.style = draw, -latex']
  \node [block] (dynamic) {Dynamic analysis};
  \node [block, below right = of dynamic] (model) {Program model};
  \node [block, below left = of model] (static) {Static analysis};
  \node [block, right = of model] (candidates) {Candidate bugs};
  \node [block, right = of candidates] (repro) {Reproductions of bugs};
  \node [block, right = of repro] (fix) {Generated fixes};
  \path [line] (dynamic) -- (model);
  \path [line] (static) -- (model);
  \path [line] (model) -- (candidates);
  \path [line] (candidates) -- (repro);
  \path [line] (repro) -- (fix);
\end{tikzpicture}
\caption{Basic pipeline}
\label{fig:basic_pipeline}
\end{figure}

In its simplest mode, \technique{} uses a multi-stage pipeline to find
and fix bugs in arbitrary binary programs, as shown in
figure~\ref{fig:basic_pipeline}.  The pipeline starts by building up a
model of the program's behaviour using a combination of static
analysis, applied to the program's binary, and dynamic analysis,
applied while the program is operating normally.  A mixture of
symbolic execution and static analysis is then used to produce a set
of candidate bugs: places in the program which might have a bug of the
target class, if the program can be driven into a particular
configuration.  This set will be very large for most realistic
programs and will usually contain a large number of false positives,
and so is not, of itself, particularly useful.  The next stage of the
analysis is therefore to prune it back to just those bugs which can
definitely happen.  Most existing static analysis and model checking
systems will do so by layering on further layers of increasingly more
complex analysis algorithms.  I take a different approach: modifying
the program so as to make the bugs more likely to reproduce and then
using the program's existing test suite to drive it towards them.  In
effect, \technique{} turns its bug description into a new dynamic
analysis which specifically attempts to reproduce that bug.  Since
\technique{} mostly targets concurrency bugs, these modifications mostly
consist of inserting additional delays, and hence encouraging the
program to follow the desired schedules as far as possible.  The bugs
which survive this winnowing process are then definitely real bugs,
and can either be manually reviewed by a programmer or passed to the
next phase which produces a fix targeted at that specific bug,
completely automatically.  In addition to this basic mode of
operation, \technique{} can also take as input a core dump or the log
from a deterministic replay system and use that to produce a fix for a
specific bug.

I give a detailed description of \technique{} and some results obtained
using \implementation, my implementation of it.  These include details
of the fixes generated for a selection of bugs, both artificial ones
and some from real programs, and a demonstration that the analysis
scales to realistically large programs with acceptable computational
cost.  This includes bugs which were unknown to the author before
writing the tool\editorial{Or, more precisely, one bug which was
  unknown to me before writing the tool but which was known to the
  program's original developers, and which is a trivial variation of a
  bug which I did know about.  But, you know, take your victories
  where you can get them.}.  I also show that the fixes generated
often have sufficiently low overhead to be useful; usually a few
percent in more realistic tests.  Finally, I give the results of a
small set of experiments intended to show that \implementation{} is a
correct implementation of \technique{}.

\todo{I'm currently calling the static analysis pass whole-program
  static analysis, which is accurate in the sense that it looks at the
  whole program rather than at the bits relevant to one bug, but also
  kind of deceptive in that it (mostly) looks at it one function at a
  time, which is the opposite of the meaning of ``whole-program
  analysis'' as used in the compilers literature.}

The basic analysis technique used, in all of these modes, is to take
some small fragment of a binary program and approximate it using a
\StateMachine\editorial{Desperately need a better name for these.},
using a combination of decompilation, program slicing, and static
analysis techniques.  These \StateMachines contain all of the
information which is relevant to the bug being investigated but very
little irrelevant information, making them far easier to analyse than
the raw machine code.  They have a number of important properties:

\begin{itemize}
\item
  They can cross function boundaries, including between the program
  itself and library functions\editorial{But only in certain modes: I
    was a bit lazy in the bug-finding mode and restricted things to
    the main binary.  It's just an artifact of the implementation, and
    could be fixed without too much pain, but not in the time I have
    left.}.
\item
  They can contain information from multiple program threads, and so
  can accurately capture all of the threads relevant to a particular
  race, but are themselves completely deterministic, aiding simple
  analysis.  In particular, the \StateMachine for a particular bug can
  be used to build the happens-before graph necessary for that bug to
  reproduce (including when that happens-before graph is
  data-dependent).
\item
  \STateMachines can incorporate information obtained by the initial
  static and dynamic analysis passes in a reasonably straightforward
  way.
\item
  Control-flow within a \StateMachine is not necessarily the same as
  control flow within the original program, and memory accesses within
  a \StateMachine do not necessarily correspond to specific memory
  accesses in the original program, but can be related back when
  necessary.  This means that intermediate analysis steps have a great
  deal of flexibility to rewrite \StateMachines to remove unnecessary
  information without unduly complicating actually using the results
  of the analysis.
\item
  They can be interpreted, given a snapshot of the program's state,
  its future happens-before graph, and some information about its
  control flow, to make a prediction about whether the program might,
  starting from that state, suffer the bug which is being
  investigated.  Alternatively, they can be symbolically executed to
  determine what initial states might lead to the bug.

  \todo{The information about the control flow is kind of subtle: it's
    not to do with which branches the program takes, but to do with
    how the CFG gets unrolled while building the machine.  Probably
    don't want to try to describe that just yet.}
\item
  Individual \StateMachines must complete in a finite, bounded, number
  of operations; equivalently, \StateMachines are acyclic and finite.
  This makes them far easier to analyse, but at the expense of
  somewhat limiting their expressive power.  In the particular case of
  \technique{}, we are only interested in bugs related to fairly small
  fragments of the program (those which should have been critical
  sections, but aren't) and so this is a tolerable limitation; it
  might be more of a concern in other applications.
  Section~\todo{...} briefly discusses some possible ways of removing
  this restriction.
\end{itemize}

\STateMachines are in many respects similar to executable program
slices of the original program, with the key difference that, unlike a
program slice, a \StateMachine is not expressed in the same language
as the original program.  This is to some extent a forced decision
(SLI operates on binaries, whereas most program slicing systems
operate on source code; programming languages are not usually
particularly convenient intermediate forms, but machine code is far
worse), but the extra flexibility can sometimes make this more
convenient than more conventional source-level program
slices\editorial{Should maybe have a forward ref here?}.

A somewhat closer analogy is with the abstract models commonly used in
formal verification systems such as Promela\needCite{}.  The
difference here is in the semantic structure of the program to be
modelled: \technique{} models machine-code programs, and hence has no
knowledge of higher-level constructs such as variables, arrays, or
compound structures, whereas a tool like Promela or SAL\needCite{}
work with source code and hence (mostly) assume that such information
is available.  While it would be possible in principle to extract such
information and hence build a SAL or Promela model, doing so would
itself be somewhat time-consuming.

Once a \StateMachine for a bug has been obtained, the analysis moves
on to attempting to reproduce it.  \technique{} does so by first
examining the \StateMachine to determine the happens-before graph
necessary for the target bug to reproduce, along with any appropriate
side-conditions, and then building a custom dynamic analysis for the
original program which makes that happens-before graph more likely to
occur.  The original program's original test suite is then used to
exercise it, thus confirming that the bug actually does (or does not)
exist.  Several such happens-before enforcers can be run on each
program at any one time, which can significantly reduce the time taken
for this verification step.

Finally, the now-confirmed bug can be converted into a fix.  In this
mode, \technique{} again examines the happens-before graph implicit in
the \StateMachine and uses it to extract a set of critical sections of
the original program.  With these in hand, \technique{} can produce a
modified version of the original program which ensures that no
critical sections ever execute in parallel with each other, hence
eliminating the original bug.

\editorial{Cite Holzmann and Smith, 2001}.

\section{Contributions}

\begin{itemize}
\item
  Suggest a novel method of finding concurrency-related bugs given
  only a binary program and some way of running it.
\item
  Describe how the bug description produced when trying to find a bug
  can instead be used to automatically fix the same bug.
\item
  Propose a couple of ways of simplifying cross-function and
  cross-thread slices of a binary program.
\item
  Evaluate these techniques, showing that they can find and fix bugs
  in simple programs quickly, and that the analysis techniques
  \todo{(just about)} scale up to find real bugs in realistic
  programs.
\item
  I further give some evidence that my implementation of these
  techniques is itself correct, so that the other parts of the
  evaluation are likely to be correct.
\end{itemize}

\todo{Maybe include explicit comparisons to related work in here?}

\section{Structure of this dissertation}

\begin{itemize}
\item Description of \StateMachines.  How to derive them and a couple
  of ways of manipulating them.
\item Uses of \StateMachines: how to use them to fix bugs, and to make
  bugs easier to reproduce.
\item Evaluation: demonstration that it works well for small bugs,
  discussion of some slightly more realistic ones, and demonstration
  that the analysis scales to more realistic programs will tolerable
  cost.  I also explore the effectiveness of some different
  \StateMachine simplification strategies.  Finally, I give some
  evidence that my implementation is correct.
\item Related work: I give an overview of existing work in the field
  and highlight the differences and similarities between SLI and
  previous approaches.
\end{itemize}

\section{Type of bug considered}

SLI considers only a restricted class of all possible bugs: those
where one thread is reading a structure while another thread is
modifying it, and this concurrency causes the reading thread to crash
quickly.  In slightly more detail:

\begin{itemize}
\item The \emph{structure} is defined quite loosely: it is a (usually
  non-contiguous) collection of locations in memory which are accessed
  by one or both of the threads.  There is no requirement that it
  match up with any language- or programmer- level definition of
  structure such as \verb|struct| in C or a \verb|class| in C++ (and
  in fact such higher-level constructs do not exist in the binaries
  which SLI analyses).
\item Only \emph{concurrency} bugs are considered.  This means that
  there must be some critical sections in the read and write threads
  such that running those sections atomically with respect to each
  other is guaranteed to avoid the crash but interleaving them might
  not\footnote{In fact, SLI makes the slightly stronger assumption
    that running all of the instructions represented in the read or
    write thread \StateMachines atomically avoids the bug; see
    section~\ref{sect:mandatory_concurrency} for a discussion of why
    this might be unsound.}.  \todo{I want to say something about
    still being able to enforce arbitrary HB-graphs, rather than the
    very simple ones you get with critical sections, but can't quite
    get the phrasing right.}
\item The only communication allowed is from the \emph{write} thread
  to the \emph{read} one.  The analysis assumes that the write
  thread's behaviour will never depend on the actions of the read
  thread, which in practice means that the write thread will never
  read memory locations written to by the read thread.  Note that this
  does not imply that the read thread cannot write to any memory
  locations: the read thread can see writes issued by either thread,
  even though the write thread can only see its own writes.
  Similarly, it is assumed that no other threads can interfere with
  the two threads being examined.
\item The read thread must crash \emph{quickly}: within the
  instructions represented by its \StateMachine.  Depending on how the
  program and the way in which the \StateMachine has been derived,
  this might be from a few dozen to a few hundred instructions.  For
  the purposes of \implementation, a crash means either dereferencing
  a bad pointer, and so generating a segmentation fault, or calling
  one of a number of pre-defined crashing functions such as
  \verb|abort| or \verb|__assert_fail|.
\end{itemize}

This is obviously a somewhat restricted class of bugs, but still
contains some non-trivial ones, and restricting the class of bugs like
this helps to make the analysis more tractable.

