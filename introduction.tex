\todo{Need to think about names of things.  In particular, it'd be a
  good idea to have different names for the \emph{technique} and the
  \emph{implementation}; the current text conflates them a bit, and
  giving them different names might make that a bit more clear.  I've
  used \technique{} and \implementation{} in a few places as
  placeholders.}

\todo{The main thing missing here is a well-defined thesis.  Need to come
  up with one pretty damn quickly.}

\smh{Probably want to explain a bit about (a) Happens-Before
  (e.g. Boehm) and (b) program slicing before using the terms freely.}


\section{Motivation and overview}

Commodity hardware is becoming increasingly concurrent, whether due to
more packages per machine, per cores per package, or more threads per
core, and software is adapting to make use of this greater
concurrency.  This promises greater performance, but at the same time
introduces a greater risk of serious concurrency bugs.  Even worse,
concurrency bugs often depend on details of the program which are only
apparent at the machine code level, rather than at source level.
There is therefore a need for tools to help discover and fix
concurrency bugs by directly analysing program binaries.  This
dissertation presents one possible approach to doing so: a set of
techniques which can, first, slice a binary program to find parts
which are relevant to a specific bug; second, analyse those slices to
determine whether the bug might actually happen in real executions;
and, third, automatically generate a fix for the bug.  \smh{Very
  strong} The same analysis can also be used to find all possible bugs
of a specific class in the program.  The approach used requires
minimal programmer involvement; in some interesting cases it is
completely automated.

This is a demanding goal.  To make it feasible, {\technique} considers
only a restricted class of concurrency bug: two threads interacting,
with one modifying some shared structures while a second reads it,
causing the reading thread to crash quickly in a recognisable
way.\todo{Need a bit more here.}

\section{Overview of approach}
\label{sect:intro:overview}

\begin{figure}
\begin{center}
  \begin{tikzpicture}
    [block/.style = rectangle,draw,fill=blue!20,
      line/.style = draw, -latex']
    \node [block,draw] (dynamic) {Running program};
    \node [block,draw, below right = of dynamic] (model) {Program model};
    \node [block,draw, above right = of model] (static) {Program binary};
    \node [block,draw, below = of model] (candidates) {Candidate bugs};
    \node [block,draw, below = of candidates] (repro) {Reproduction};
    \node [block,draw, below = of repro] (fix) {Fixes};
    \path [line,->] (dynamic) to node [left] {Dynamic analysis} (model);
    \path [line,->] (static) to node [right] {Static analysis} (model);
    \path [line,->] (model) to node [right] {Bug generation} (candidates);
    \path [line,->] (candidates) to node [right] {Enforcement} (repro);
    \path [line,->] (repro) to node [right] {Fix generation} (fix);
  \end{tikzpicture}
  \caption{Basic pipeline}
\end{center}
\label{fig:basic_pipeline}
\end{figure}

In its simplest mode, \technique{} uses a multi-stage pipeline to find
and fix concurrency bugs in arbitrary binary programs, as shown in
Figure~\ref{fig:basic_pipeline}.  The pipeline starts by building up a
model of the program's behaviour using a combination of static
analysis, applied to the program's binary, and dynamic analysis,
applied while the program is operating normally.  This model can then
be used, via a mixture of symbolic execution and further static
analysis, to generate a set of candidate bugs.  These represent all of
the places in the program which might possibly suffer from a bug of
the type being investigated, if the program ever reaches a particular
configuration.  This set is usually quite large for realistic
programs, and often contains a very high proportion of false
positives, and so the next stage is to trim it back to bugs which
might actually occur.  The approach used here is somewhat unusual:
rather than applying a succession of more powerful analysis,
{\technique} instead modifies the program so as to make the bug
reproduce more easily in a process called enforcement\editorial{Ugly
  phrasing.} and then runs the program through its existing test
suite.  This step eliminates all false positives from the set of
candidate bugs.  Finally, the remaining confirmed bugs are passed to
the fix generation phase, which produces a modified version of the
original program containing additional synchronisation which is
guaranteed to eliminate the bug.

\smh{c/f RX?}

In addition to this basic mode of operation, \technique{} can also
take as input a core dump or the log from a deterministic replay
system and use that to produce a fix for a specific bug.

I give a detailed description of \technique{} and some results obtained
using \implementation, my implementation of it.  These include details
of the fixes generated for a selection of bugs, both artificial ones
and some from real programs, and a demonstration that the analysis
scales to realistically large programs with acceptable computational
cost.  This includes bugs which were unknown to the author before
writing the tool\editorial{Or, more precisely, one bug which was
  unknown to me before writing the tool but which was known to the
  program's original developers, and which is a trivial variation of a
  bug which I did know about.  But, you know, take your victories
  where you can get them.}.  I also show that the fixes generated
often have sufficiently low overhead to be useful; usually a few
percent in more realistic tests.  Finally, I give the results of a
small set of experiments intended to show that \implementation{} is a
correct implementation of \technique{}.

The basic analysis technique used, in all of these modes, is to take
some small fragment of a binary program and approximate it using a
\StateMachine\editorial{Desperately need a better name for
  these.}\smh{``sketch''? (What's in it?  What does it look like?)}: a
simplified version of part of the program which contains all of the
information which is relevant to the bug being investigated but very
little irrelevant information.  This makes them far easier to analyse
than the raw machine code.  They have a number of important
properties:

\begin{itemize}
\item
  They can cross function boundaries, and so can be used to model
  cross-function properties of the program.
\item
  {\STateMachines} are themselves completely deterministic, aiding
  simple analysis, but can contain information from multiple program
  threads, and so can accurately capture all of the threads relevant
  to a particular race, but are themselves completely deterministic,
  aiding simple analysis.  In particular, the \StateMachine for a
  particular bug can be used to build the happens-before graph
  necessary for that bug to reproduce (including when that
  happens-before graph is data-dependent).
\item
  \STateMachines can incorporate information obtained by the initial
  static and dynamic analysis passes in a reasonably straightforward
  way.
\item
  Control-flow within a \StateMachine is not necessarily the same as
  control flow within the original program, and memory accesses within
  a \StateMachine do not necessarily correspond to specific memory
  accesses in the original program.  This means that intermediate
  analysis steps have a great deal of flexibility to rewrite
  \StateMachines and hence to remove unnecessary information.  On the
  other hand, it also means that translating the results of the
  analysis back from \StateMachines to the original program requires a
  little bit of care.  This is discussed in more detail in later
  sections.
\item
  They can be interpreted, given a snapshot of the program's state,
  its future happens-before graph, and some information about its
  control flow, to make a prediction about whether the program might,
  starting from that state, suffer the bug which is being
  investigated.  Alternatively, they can be symbolically executed to
  determine what initial states might lead to the bug.

  \todo{The information about the control flow is kind of subtle: it's
    not to do with which branches the program takes, but to do with
    how the CFG gets unrolled while building the machine.  Probably
    don't want to try to describe that just yet.}
\item
  Individual \StateMachines must complete in a finite, bounded, number
  of operations; equivalently, \StateMachines are acyclic and finite.
  This makes them far easier to analyse, but at the expense of
  somewhat limiting their expressive power.  In the particular case of
  \technique{}, we are only interested in bugs related to fairly small
  fragments of the program (those which should have been critical
  sections, but aren't) and so this is a tolerable limitation; it
  might be more of a concern in other applications.
  Section~\todo{...} briefly discusses some possible ways of removing
  this restriction.
\end{itemize}

\STateMachines are in many respects similar to executable program
slices of the original program, with the key difference that, unlike a
program slice, a \StateMachine is not expressed in the same language
as the original program.  This is to some extent a forced decision
({\technique} operates on binaries, whereas most program slicing
systems operate on source code; programming languages are not usually
particularly convenient intermediate forms, but machine code is far
worse), but the extra flexibility can sometimes make this more
convenient than more conventional source-level program
slices\editorial{Should maybe have a forward ref here?}.

A somewhat closer analogy is with the abstract models commonly used in
formal verification systems such as Promela\needCite{}.  The
difference here is in the semantic structure of the program to be
modelled: \technique{} models machine-code programs, and hence has no
knowledge of higher-level constructs such as variables, arrays, or
compound structures, whereas tools like Promela or SAL\needCite{} work
with source code and hence (mostly) assume that such information is
available.

Once a {\StateMachine} for a bug has been obtained, it is converted
into a verification condition.  This is a predicate which is true
precisely when the bug being investigated reproduces, expressed in
terms of the program's state (its memory contents, registers, etc.),
its happens-before graph (the order in which memory accesses are
interleaved), and its control flow (which exit is taken from branch
instructions).  These could be passed to existing model checking tools
such as \needCite{} or \needCite{} \editorial{Probably; I haven't
  really thought about the details.} to check whether the bug might
actually exist, or a programmer could simply manually expect them.
More interestingly, {\technique} can use them to generate ``bug
enforcers'': modified versions of the program with additional delays
and synchronisation which make the bug more likely to reproduce.  The
original program's original test suite is then used to exercise it,
thus confirming that the bug actually does (or does not) exist.

Finally, the now-confirmed bug can be converted into a fix.  In this
mode, {\technique} examines the happens-before graph in the
verification condition and uses it to extract a set of critical
sections of the original program.  With these in hand, {\technique}
can produce a modified version of the original program which ensures
that no critical sections ever execute in parallel with each other,
hence eliminating the original bug.

\todo{Cite Holzmann and Smith, 2001.}

\section{Contributions}

\begin{itemize}
\item
  Suggest a novel method of finding concurrency-related bugs given
  only a binary program and some way of running it.
\item
  Describe how the bug description produced when trying to find a bug
  can be used to automatically fix the same bug.
\item
  Propose several techniques for simplifying cross-function and
  cross-thread slices of binary programs.
\item
  Evaluate these techniques, showing that they can find and fix bugs
  in simple programs quickly, and that the analysis techniques
  \todo{(just about)} scale up to find real bugs in realistic
  programs.
\item
  I further give some evidence that my implementation of these
  techniques is itself correct, so that the other parts of the
  evaluation are likely to be correct.
\end{itemize}

\todo{Maybe include explicit comparisons to related work in
  here?}\smh{Maybe in intro, but not right here.}

\section{Structure of this dissertation}

\begin{description}
\item[Chapter~\ref{chapter:derive_manip}] Description of
  \StateMachines: how to derive and manipulate them.
\item[Chapter~\ref{chapter:using_machines}] Uses of \StateMachines:
  how to use them to derive the verification condition, build bug
  enforcers, and generate bug fixes.
\item[Chapter~\ref{chapter:eval}] Evaluation: demonstration that it
  works well for small bugs, discussion of some slightly more
  realistic ones, and demonstration that the analysis scales to more
  realistic programs will tolerable cost.  I also explore the
  effectiveness of the {\StateMachine} simplification strategies given
  in Chapter~\ref{chapter:derive_manip}.  Finally, I give some
  evidence that {\implementation} is a correct implementation of
  {\technique}.
\item[Chapter~\ref{chapter:related_work}] Related work: I give an
  overview of existing work in the field and highlight the differences
  and similarities between {\technique} and previous approaches.
\end{description}

\section{Type of bug considered}

{\Technique} considers only a restricted class of all possible bugs:
those where two threads are accessing the same structure, with one
reading and one writing, and this concurrency causes the reading
thread to crash quickly and recognisably.  In slightly more detail:

\begin{itemize}
\item The bug must be reproducible with only \emph{two} threads
  interacting.  Bugs which require three or more threads are not
  considered.  There might, of course, be additional threads in the
  program, and this is acceptable provided that those other threads
  are not needed to reproduce the bug.
\item One thread must be \emph{reading} from the structure while
  another is \emph{writing} to it.  Bugs in which both threads are
  simultaneously updating the same structure are not considered\smh{Is
    this a big restriction?  Can we not frame many bugs into this
    shape?}.
\item The \emph{structure} is defined quite loosely: it is a (usually
  non-contiguous) collection of locations in memory which are accessed
  by both threads.  There is no requirement that it match up with any
  language- or programmer- level definition of structure such as
  \verb|struct| in C or a \verb|class| in C++ (and in fact such
  higher-level constructs do not exist in the binaries which
  {\technique} analyses).
\item Only \emph{concurrency} bugs are considered.  This means that
  there must be some critical sections in the reading and writing
  threads such that running those sections atomically with respect to
  each other is guaranteed not to crash but interleaving them might.
\item The reading threads must crash \emph{quickly}.  {\Technique}
  uses a finite analysis window $\alpha$ and will only consider
  reordering concurrent operations which occur at most $\alpha$
  instructions before the crash.  Bugs which require knowledge of the
  program behaviour beyond that window cannot be analysed.  Another
  way of thinking about this is to say that {\technique} only
  considers bugs which can be fixed by small critical sections
  containing fewer than $\alpha$ dynamic instructions.  $\alpha$ can,
  in principle, be arbitrarily large, but computational constraints
  mean that in practice it will be limited to a few dozen to a few
  hundred instructions, depending on the program to be analysed and
  how much information about the bug is available before analysis
  starts.
\item The tool\editorial{What tool?} must be able to \emph{recognise}
  that the program has crashed.  For the purposes of my prototype
  {\implementation}, this means that it must suffer either a fatal
  page fault or an assertion failure.  This could be extended to more
  general classes of crash using techniques such as TESLA\needCite{}
  or invariant inference\needCite{}.

  \todo{It occurs to me that it'd actually be fairly easy to add at
    least one test which uses a programmer-provided invariant, which'd
    make this a little bit more convincing.  The invariant language
    would have to be fairly weak, so it wouldn't be particularly
    *useful*, but it'd be rhetorically handy.}
\end{itemize}

\smh{Why is this important (or not)?  i.e. can we reduce other bugs to
  this or extend the technique?}

\todo{I did have a reference saying that some reasonable proportion of
  real concurrency bugs falls into that category (like 30\% or so),
  but (a) I've lost the reference, and (b) having actually played with
  this a bit, I \emph{really} don't believe that any more.}\smh{hmm}

This is clearly only a subset of possible concurrency bugs.
Nevertheless, it does include some interesting bugs in real programs,
and the restrictions imposed significantly reduce the cost of
performing the analysis.  \editorial{I don't actually show that
  restricting to two threads helps reduce cost, and doing so would be
  a pain in the backside.  It's not even clear what it means to say
  that requiring a recognisable crash reduces cost, since the thing
  wouldn't even work if you didn't have that.} \todo{Need more here.}

\smh{Ok -- generally decent intro missing some structure, and still
  missing the high level story in a para -- maybe fix up fig 2.1 with
  annotations?}
