\chapter{Gaining control of a running program}
\label{sect:enforce:gain_control}

\todo{This is maybe a bit short to have its own chapter?}

The discussion of building crash enforcers in
\autoref{sect:reproducing_bugs} assumes that it can gain control of
the program at any point.  This section describes one possible way of
doing so.  The basic idea is quite simple: to replace some
instructions of the original program with branch instructions which
transfer control to the entry point of the plan interpreter.  This is
efficient and avoids unnecessarily modifying the program's state.
There is, however, a risk that the branch instruction will be larger
than the instruction at which the interpreter needs to gain control,
in which case the branch will corrupt the following instruction.  The
patching mechanism must ensure that the program never executes one of
these corrupted instructions\footnote{Instructions will only be
  corrupted like this on architectures which have variable-sized
  instructions, such as AMD64, but there is an analogous problem on
  fixed-size instruction architectures such as ARM or Alpha.  These
  architectures generally lack a single instruction capable of
  branching to any location in their address space, and so the patch
  might need to use several instructions to implement the branch,
  which has the same effect as just using a single very large branch
  instruction.}.

\begin{figure}[tp]
  \begin{displaymath}
    \textsc{PatchStrategy} = \left\{\begin{array}{rl}
    \mathit{Patch}: & \{\textsc{Instruction}\} \\
    \mathit{Cont}: & \{\textsc{Instruction}\} \\
    \mathit{MustInterpret}: & \{\textsc{Instruction}\}
    \end{array}\right\}
  \end{displaymath}
  \caption{The \textsc{PatchStrategy} type}
  \label{fig:patch_strategy_type}
\end{figure}

{\Implementation} represents solutions and partial solutions to the
patch problem using the \textsc{PatchStrategy} type, illustrated in
\autoref{fig:patch_strategy_type}:

\begin{itemize}
\item $\mathit{Patch}$ is the set of instructions in the original
  program which will be replaced with branch instructions.
\item $\mathit{Cont}$ is a set of instructions which are not patched
  themselves but which will be run in the interpreter anyway.
\item $\mathit{MustInterpret}$ is a set of instructions where the
  enforcement plan requires us to gain control, but where the patches
  described in this strategy would be insufficient to do so.
\end{itemize}

There are various constraints on the validity of a
\textsc{PatchStrategy} which are best explained inductively.  The
empty \textsc{PatchStrategy}, which has all three sets empty, is a
valid strategy, and corresponds to the case where the program is
completely unmodified.  There are three rules for generating a new
valid \textsc{PatchStrategy} from an existing one:

\begin{itemize}
\item
  \textbf{PatchDirect} This rule transforms a \textsc{PatchStrategy}
  by removing an instruction $i$ from the $\mathit{MustInterpret}$ set
  and adding it to the $\mathit{Patch}$ one.  The enforcer will
  therefore gain control at $i$ by replacing $i$ with a branch to the
  interpreter.  This could potentially corrupt the instructions
  following $i$; if so, \textsc{BuildPatchStrategy} adds those
  instructions to $\mathit{MustInterpret}$.  This rule is only valid
  if the branch at instruction $i$ would not itself corrupt or be
  corrupted by one of the other instructions in the $\mathit{Patch}$
  set.
\item
  \textbf{Prefix} This rule also removes an instruction $i$ from
  $\mathit{MustInterpret}$, but does not add it to $\mathit{Patch}$
  and hence will not replace the instruction with a branch.  The rule
  instead adds $i$ to $\mathit{Cont}$ and all of $i$'s predecessors to
  $\mathit{MustInterpret}$, so that the enforcer gains control before
  $i$ starts and then maintains control when the program branches to
  $i$.  This rule is only valid if {\technique} can find all of the
  predecessors of $i$.
\item
  $\textbf{Extend}(i)$ This rule extends the \textsc{PatchStrategy} by
  adding a new instruction $i$ to $\mathit{MustInterpret}$.
\end{itemize}

{\Technique} must find a valid \textsc{PatchStrategy} in which
$\mathit{MustInterpret} = \varnothing$ and $\mathit{Cont} \cup
\mathit{Patch}$ includes all of the instructions at which the enforcer
must gain control.  The algorithm for doing so is shown in
\autoref{fig:patch_search_algorithm}.  This algorithm starts with an
empty \textsc{PatchStrategy} (line 2).  It considers each instruction
at which it must gain control in turn (line 3).  For each one, it adds
the instruction to the $\mathit{MustInterpret}$ set (line 4) and then
explores from there using the first two strategy generating rules
(lines 5 to 13) until it finds a strategy with an empty
$\mathit{MustInterpret}$ state (lines 7 to 9).  The algorithm then
loops again adding another instruction from $\mathit{gainControl}$ to
$\mathit{MustInterpret}$, and repeats until every instruction has been
added.  The resulting strategy is then guaranteed to gain control of
the program at every instruction in $\mathit{gainControl}$ and to
ensure that the program never executes one of the corrupted
instructions.

\begin{figure}
  \begin{algorithmic}[1]
    \Procedure{BuildPatchStrategy}{$\mathit{gainControl}$}
    \State {$\mathit{currentSoln} \gets \textsc{PatchStrategy}(\mathit{Patch} = \{\}, \mathit{Cont} = \{\}, \mathit{MustInterpret} = \{\})$}
    \For {$i \in \mathit{gainControl}$}
      \State {$q \gets \queue{\textbf{Extend}(i)(\mathit{currentSoln})}$}
      \While {\true}
        \State {$\mathit{s} \gets \mathit{pop}(q)$}
        \If {$s.\mathit{MustInterpret} = \{\}$}
          \State {$\mathit{currentSoln} \gets s$}
          \State \textbf{break}
        \Else
          \State {$q \gets q + \mathbf{PatchDirect}(s) + \mathbf{Prefix}(s)$}
        \EndIf
      \EndWhile
    \EndFor
    \State \Return $\mathit{currentSoln}$
    \EndProcedure
  \end{algorithmic}
  \caption{Patch search algorithm.  $\mathit{gainControl}$ is the set
    of instructions at which the enforcer must gain control of the
    program.  Not shown: {\implementation}'s implementation records
    all of the stratgies which it has visited so far so as to avoid
    re-visiting them.}
  \label{fig:patch_search_algorithm}
\end{figure}

This algorithm, as stated, leaves the order in which
\textsc{PatchStrategy}s are removed from the queue ambiguous.  This
can sometimes have a quite large effect on the number of instructions
which must be executed in the interpreter, and hence on the
performance overheads of the patch.  It is hard to predict precisely
how large an impact a given strategy will have on performance without
a detailed model of the program's behaviour, but it can reasonably be
approximated to be proportional to the number of static instructions
affected, $|\mathit{Cont} \cup \mathit{Patch}|$.  {\Implementation}
will therefore always choose to expand the strategy where that
quantity is smallest, which usually causes it to find the strategy
which minimises the cost of patch\footnote{The result is only usually
  minimal, rather than guaranteed to be minimal, because the
  $\mathit{gainControl}$ set is processed incrementally, with no
  backtracking from one instruction to an earlier one, and so it might
  be that the first instruction processed produces a strategy which is
  incompatible with the optimal strategy for the second instruction.
  There is an alternative non-incremental version of the algorithm
  which starts by setting $\mathit{MustInterpret}$ to
  $\mathit{gainControl}$, rather than adding one instruction at a
  time, and that alternative version would be guaranteed to find the
  optimal solution.  On the other hand, the search process itself
  would be far more expensive, as it would attempt to explore from
  every $\mathit{gainControl}$ instruction simultaneously.  This would
  raise the cost from $O(nk)$ to $O(n^k)$, where $k =
  |\mathit{gainControl}|$ and $n/k$ is the cost of the current
  algorithm.  In practice, the algorithm given here rarely needs to
  add more than one or two instructions to the $\mathit{Cont}$ set
  anyway (see \autoref{sect:eval:genfix}), and so this would not be a
  good trade-off.}.

Calculating the set of predecessor instructions, necessary to apply
the \textbf{Prefix} rule, is itself marginally complicated.  The
crashing \gls{cfg} building algorithm, described in
\autoref{sect:derive:build_crashing_cfg}, needs to solve the same
problem, and {\technique} uses a similar solution here.  There is one
important difference, however: if the \gls{cfg}-building algorithm
misses a predecessor then the analysis will be incomplete, which is
irritating but tolerable, whereas if the \textsc{PatchStrategy}
builder misses one then the program will potentially crash, which is
more of a problem.  This could happen if the strategy corrupts an
instruction $i$ and there are control-flow edges to $i$ which are
possible in the program but not in the \gls{programmodel}.  The most
common reason for an edge to be missing from the \gls{programmodel} is
if it is an indirect call which did not occur during the dynamic
analysis phase.  {\Implementation} avoids that particular problem by
simply disabling the \textbf{Prefix} strategy for the first
instruction in any function, which ensures that such instructions will
never be corrupted in the final strategy.

This can sometimes lead to the patch problem being unsolvable if the
entire function is smaller than a single branch instruction, as in
that case it will not be possible to patch the function without
corrupting the first instruction of the next function in the binary.
In that case, {\implementation} simply gives up and reports an error.
This is rarely a problem in practice, as very few functions are that
small without very aggressive compiler optimisations, and most
compilers, including gcc\cite[Section~3.10]{Stallman2010} and
LLVM\needCite{}, will at high optimisation levels pad functions to a
multiple of 16 bytes for performance reasons.

An alternative approach would be to take control of the program using
debug breakpoints rather than jump instructions.  These are either a
single byte (for the \verb|int3| instruction) or no bytes at all (for
debug registers), and so avoid the instruction clobbering problem.
This would work, but would have a couple of important disadvantages:

\begin{itemize}
\item
  Debug breakpoints are far slower than branches.  This might be
  important if the critical section is to be inserted on a
  particularly hot code path and has a side-condition which usually
  fails.
\item
  Using debug breakpoints in this way would interfere with any other
  debugger which the developer might want to use.  With a branch-style
  patch, standard debuggers work without modification for any part of
  the program which has not been patched, whereas a breakpoint-style
  patch requires extensive coordination between the debugger and the
  patch mechanism for either to work at all.
\item
  Breakpoint registers are of strictly limited number on most
  architectures (four, on x86).  This means that they can never
  provide a complete solution by themselves.
\end{itemize}

{\Implementation} therefore generates exclusively branch-style patches.
