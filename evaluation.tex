\newcommand{\biggraph}[1]{\input{#1}}
%\newcommand{\biggraph}[1]{}
%\draftonly{\renewcommand{\biggraph}[1]{}}

\chapter{Evaluation}
\label{chapter:eval}

Experiments still to run:

\begin{itemize}
\item Run the mysql enforcers on ise, count the reproes.
\item Measure the effectiveness of the complex\_hb enforcers on ise.
\item Re-run the fix overhead experiments on ise
\item Finish running the various config knob experiments.
\item Need to re-do the cost of building fixes experiments.
\end{itemize}

\begin{sanefig}
  \begin{tabular}{lp{12.7cm}}
    $x \pm^n_p y$ & The mean, $x$, and sample standard deviation, $y$, of $n$ samples of some distribution with appropriately low skew and kurtosis.\\
    & \\
    $x \pm^n_\mu y$ & The mean, $x$, of some distribution and the standard deviation of the mean, $y$, calculated by applying the central limit theorem to $n$ samples of the distribution.\\
    & \\
    $x \pm_\mu y$ & The mean, $x$, of some distribution and the standard deviation of the mean, $y$, calculated from distributions derived elsewhere rather than directly from sampled data.\\
    & \\
    $[x,y]^n_b$ & $[x,y]$ form a 90\% confidence interval for some statistic of a distribution, derived by a bootstrap with $b$ replicates over $n$ samples. \\
    & \\
    $z \in [x,y]^n_\infty$ & $z$ is a maximum likelihood estimator of some statistic of a distribution and $[x,y]$ form a 90\% confidence interval for it, calculated by performing a bootstrap over $n$ samples of the distribution and taking the limit as the number of replicates goes to infinity.\\
    & \\
    $0/n$ & A Bernoulli process was sampled $n$ times and did not succeed. \\
    &\\
    $n/n$ & A Bernoulli process was sampled $n$ times and succeeded every time. \\
  \end{tabular}
  \caption{Summary of statistical notation used in this chapter.}
\end{sanefig}

Previous chapters have described {\technique} and how it can, under
appropriate circumstances, automate every stage of the debugging
process, from discovering bugs through characterising and reproducing
them to ultimately generating fixes.  This chapter provides an
experimental evaluation of the effectiveness and performance of my
implementation, {\implementation}.  This evaluation will consist of
four parts:
\begin{itemize}
\item \autoref{sect:eval:does_it_work} investigates whether
  {\technique} works at all, looking at the time taken to produce
  \glspl{verificationcondition}, \glspl{bugenforcer}, and fixes; the
  effects of \glspl{bugenforcer} and fixes on the frequency with which
  bugs reproduce; and the effects of the fixes on the program's
  behaviour.
\item \autoref{sect:eval:how_does_it_work} then explores some aspects
  of {\technique}'s performance in more detail, showing how the
  analysis time breaks down across the various phases.
\item Next, \autoref{sect:eval:why_does_it_work} examines the reasons
  for the properties observed in the previous sections and relates
  them back to the design features of {\technique}.
\item Finally, \autoref{sect:eval:does_it_scale} investigates
  {\technique}'s scalability with respect to bug complexity, using a
  variety of metrics, so as to determine when it is likely to fail.
\end{itemize}
Unless otherwise stated, all experiments were run on a four-core Intel
Q6600 2.40GHz with 8GiB of memory running Ubuntu Lucid Lynx.  The
\gls{w-isolation} assumption was enabled, \gls{alpha} was set to 20,
both analysis timeouts were set to five minutes, and the timeout used
by \glspl{bugenforcer} was randomly uniformly distributed between 100
and 200ms.  The system compiler, used to build the \glspl{bugenforcer}
and fixes, as well as {\implementation} itself, was gcc version 4.4.3.

\section{Does it work?}
\label{sect:eval:does_it_work}

This part of the evaluation aims to determine whether {\technique}
works at all.  In other words, is it able to reproduce and fix
concurrency bugs?  I investigate this using both small artificial
bugs, in \autoref{sect:eval:artificial_bugs}, and some real bugs taken
from large existing pieces of software, in
\autoref{sect:eval:does:real}.

\subsection{Artificial bugs}
\label{sect:eval:artificial_bugs}

\begin{sanefig}
  \begin{tabular}{p{8cm}p{6.5cm}}
    \multicolumn{2}{c}{\texttt{\#define NR\_PTRS 100}}\\
    \subfigure[][\RaggedRight {\rm \bugname{toctou}\!} crashing thread]{
      \begin{minipage}{7.2cm}
        \begin{literalC}
          while (1) \clbrace
            idx = random() \% NR\_PTRS;\\
            analysis\_window() \clbrace
              if (global\_ptrs[idx] != NULL) \clbrace
                *(global\_ptrs[idx]) = 5;
              \crbrace
            \crbrace
          \crbrace
        \end{literalC}
      \end{minipage}
      \label{fig:eval:artificial_bugs:programs:toctou:crashing}
    }
    &
    \subfigure[][{\rm \bugname{toctou}\!} interfering thread]{
      \begin{minipage}{6.2cm}
        \begin{literalC}
          while (1) \clbrace
            idx = random() \% NR\_PTRS; \\
            analysis\_window \clbrace
              global\_ptrs[idx] = NULL;
            \crbrace \\
            global\_ptrs[idx] = \&t;
          \crbrace
          \\
        \end{literalC}
      \end{minipage}
      \label{fig:eval:artificial_bugs:programs:toctou:interfering}
    } \\
    \subfigure[][{\rm \bugname{multi\_variable}\!} crashing thread]{
      \begin{minipage}{7.2cm}
        \begin{literalC}
          while (1) \clbrace
            analysis\_window \clbrace
              v1 = global1;\\
              v2 = global2;\\
              assert(v1 == v2);
            \crbrace \\
            sleep(500$\mu$s);
          \crbrace
          \\
        \end{literalC}
      \end{minipage}
      \label{fig:eval:artificial_bugs:programs:multi_variable:crashing}
    }
    &
    \subfigure[][\RaggedRight {\rm \bugname{multi\_variable}\!} interfering thread]{
      \begin{minipage}{6.2cm}
        \begin{literalC}
          while (1) \clbrace
            global1 = 5;\\
            global2 = 5;\\
            sleep(500$\mu$s);\\
            analysis\_window \clbrace
              global1 = 7;\\
              global2 = 7;
            \crbrace
          \crbrace
        \end{literalC}
      \end{minipage}
      \label{fig:eval:artificial_bugs:programs:multi_variable:interfering}
    } \\
    \subfigure[][{\rm \bugname{double\_free}\!} active threads]{
      \begin{minipage}{7.2cm}
        \begin{literalC}
          while (1) \clbrace
            analysis\_window \clbrace
              t = global\_ptr; \\
              if (t != NULL) \clbrace
                free(t);
              \crbrace \\
              global\_ptr = NULL;
            \crbrace \\
            sleep(1ms);
          \crbrace
        \end{literalC}
      \end{minipage}
      \label{fig:eval:artificial_bugs:programs:double_free:active}
    }
    &
    \subfigure[][{\rm \bugname{double\_free}\!} environmental thread]{
      \begin{minipage}{6.2cm}
        \begin{literalC}
          \\
          \\
          while (1) \clbrace
            if (global\_ptr == NULL) \clbrace
              global\_ptr = malloc(64);
            \crbrace
          \crbrace
          \\
          \\
          \\
        \end{literalC}
      \end{minipage}
      \label{fig:eval:artificial_bugs:programs:double_free:environmental}
    }
  \end{tabular}
  \caption{Artificial test programs.  {\tt analysis\_window}\hspace{-1pt} shows
    the extent of the \gls{analysiswindow}, which was specified
    manually for these tests.  The various delays were chosen so that
    the bug reproduced in a reasonable time when the program was run
    with neither an enforcer nor a fix applied.}
  \label{fig:eval:artificial_bugs:programs}
\end{sanefig}

\noindent
I first consider {\technique}'s behaviour when applied to bugs in
three artificial test programs, shown in
\autoref{fig:eval:artificial_bugs:programs}.  These programs
illustrate several important features of {\technique}:
\begin{itemize}
  \item The \bugname{toctou} test,
    figures~\ref{fig:eval:artificial_bugs:programs:toctou:crashing}
    and~\ref{fig:eval:artificial_bugs:programs:toctou:interfering},
    investigates {\technique}'s ability to reproduce data-dependent
    bad pointer dereferencing bugs, and in particular the importance
    of the side condition checking mechanism.
  \item The \bugname{multi\_variable} test,
    figures~\ref{fig:eval:artificial_bugs:programs:multi_variable:crashing}
    and~\ref{fig:eval:artificial_bugs:programs:multi_variable:interfering},
    shows a multi-variable atomicity violation.  Some previous
    approaches, such as Kivati\cite{Chew2010}, were not able to handle
    this kind of bug.
  \item The final test, \bugname{double\_free}, demonstrates
    {\technique}'s ability to handle double free-type bugs.  It
    consists of three threads: two ``active'' threads, shown in
    \autoref{fig:eval:artificial_bugs:programs:double_free:active},
    and one ``environmental'' one, shown in
    \autoref{fig:eval:artificial_bugs:programs:double_free:environmental}.
    It is possible for both active threads to release the same memory
    allocation, causing a double-free bug.  Note that the crashing and
    interfering {\StateMachines} will both represent the active thread
    and the environmental thread will not be represented by a
    {\StateMachine} at all.
\end{itemize}
These experiments clearly do not cover every possible form of program
behaviour, or even a particularly representative subset of possible
behaviours, but they suffice to demonstrate {\technique}'s basic
functionality.

\subsubsection{Computational costs of building \glsentrytext{verificationcondition}s, \glsentrytext{bugenforcer}s, and fixes}

\autoref{tab:eval:artificial_bugs:analysis_time} shows the time taken
to analyse these bugs and build either \glspl{bugenforcer} or fixes
for them.  As might be expected, these very simple bugs are processed
very quickly, at every stage of the process.  These figures provide a
reasonable lower bound on the time which {\technique} might take to
analyse a bug; realistic ones would, of course, take much longer.

\begin{sanetab}
  \begin{tabbular}{|p{2.4cm}|p{2.83cm}|p{2.83cm}|p{2.83cm}|p{2.83cm}|}
    \hline
    Test program              & \Gls{programmodel}      & \Gls{verificationcondition} & \Gls{bugenforcer} & Fix \\
    \hline
    \bugname{toctou}          & $0.541 \pm^{10}_p 0.056$ & $0.527 \pm^{10}_p 0.008$ & $0.206 \pm^{10}_p 0.008$ & $0.142 \pm^{10}_p 0.004$\\
    \bugname{multi\_variable} & $0.662 \pm^{10}_p 0.067$ & $0.370 \pm^{10}_p 0.007$ & $0.207 \pm^{10}_p 0.006$ & $0.135 \pm^{10}_p 0.004$\\
    \bugname{double\_free}    & $0.434 \pm^{10}_p 0.055$ & $0.342 \pm^{10}_p 0.009$ & $0.199 \pm^{10}_p 0.009$ & $0.135 \pm^{10}_p 0.003$\\
    \hline
  \end{tabbular}
  \caption{Time taken, in seconds, to build the \gls{programmodel},
    \gls{verificationcondition}, \gls{bugenforcer}, and fix for the
    artificial bugs.  Each configuration was run eleven times and the
    results of the first run discarded. \todo{Should be after the
      figure which defines the tests.}}
  \label{tab:eval:artificial_bugs:analysis_time}
\end{sanetab}

\subsubsection{Reproducing the bugs}

\begin{sanefig}
  \biggraph{eval/artificial_bugs/cdf1.tex}
  \caption{CDF of time taken to reproduce the bugs in the artificial
    test programs, with and without \glspl{bugenforcer}, and some
    summary statistics.  All configurations tested 110 times, in
    random order, with the first ten results discarded.  Note log
    scale.  All times in seconds.  Means calculated ignoring timeouts.
    Grey region gives a 90\% confidence interval, computed using the
    Dvoretsky-Kiefer-Wolfowitz-Massart (DKWM)
    inequality\cite{Massart1990}.  Note that DKWM confidence intervals
    are curve-wise rather than point-wise i.e. there is a 90\%
    confidence that the entire curve is within the shaded region,
    rather than that any given point is.}
  \label{fig:eval:artificial_bugs:cdf1}
\end{sanefig}

\noindent
\autoref{fig:eval:artificial_bugs:cdf1} shows how effective the
\glspl{bugenforcer} generated from these bugs are, giving cumulative
distribution functions (CDFs) of the reproduction times and some
summary statistics.  This figure shows that the enforcers are able to
reduce the mean time taken to reproduce these bugs, often by a large
amount.  They are particularly effective at eliminating large outliers
in which the bug takes a very long time to reproduce.  This is a
useful property: with fewer outliers, the behaviour of a bug will be,
qualitatively, more predictable, which is likely to make it easier for
a programmer to understand the bug, even without a reduction in
reproduction time.

\subsubsection{Fixing the bugs}

\todo{I'm undecided as to how much this actually adds.}

\begin{sanetab}
  \begin{tabbular}{|p{5cm}|p{3cm}|p{3cm}|p{3cm}|}
    \hline
                           & \multicolumn{3}{c|}{Time to run main loop, microseconds} \\
    \cline{2-4}
    Test program           & Unfixed & Fixed & Increase \\
    \hline
    \bugname{toctou}       & & &\\
    \hspace{1em}Crashing thread         & $0.62 \pm_{\mu}^{10} 0.03$   & $0.69 \pm_{\mu}^{10} 0.07$ & $0.07 \pm_\mu 0.08$ \\
    \hspace{1em}Interfering thread      & $0.64 \pm_{\mu}^{10} 0.06$   & $0.84 \pm_{\mu}^{10} 0.06$ & $0.20 \pm_\mu 0.08$ \\
    \hline
    \bugname{multi\_variable} & & &\\
    \hspace{1em}Crashing thread         & $561 \pm_{\mu}^{10} 5$       & $556.7 \pm_\mu^{10} 0.3$ & $-4 \pm_\mu 5$\\
    \hspace{1em}Interfering thread      & $561 \pm_{\mu}^{10} 5$       & $556.8 \pm_\mu^{10} 0.3$ & $-4 \pm_\mu 5$\\
    \hline
    \bugname{double\_free}    & & &\\
    \hspace{1em}Active threads          & $1086 \pm_{\mu}^{10} 1$      & $1063.8 \pm_\mu^{10} 0.6$ & $-22 \pm_\mu 1$\\
    \hspace{1em}Environmental thread    & $0.0878 \pm_{\mu}^{10} 0.0008$ & $0.0861 \pm_\mu^{10} 0.0007$ & $0.002 \pm_\mu 0.001$\\
    \hline
  \end{tabbular}
  \caption{Time taken to run a single iteration of the main loop of
    each test, with and without a fix applied.  This experiment was
    structured as eleven batches, with each configuration tested once
    in each batch in random order and the results of the first batch
    discarded.  A configuration was tested by running it for ten
    seconds, restarting whenever the test program crashed, and
    counting the number of times the loop ran during that time.  I
    then calculated the time per iteration as
    $\frac{10\mathrm{s}}{n}$, where $n$ is the number of iterations,
    and present summary statistics for that distribution.}
  \label{tab:eval:artificial_bugs:fixes}
\end{sanetab}

\noindent
{\Technique} is able to generate fixes for all three of these
artificial bugs, and these fixes correctly eliminate the bugs and
prevent the programs from crashing.
\autoref{tab:eval:artificial_bugs:fixes} shows the effect these fixes
have on the program's performance, expressed in terms of time taken to
complete the two loops.  These results are difficult to interpret, as
all of the loops contain calls to either \texttt{sleep}, which leads
to obvious distortions in the data, or complex library functions such
as \texttt{random} or \texttt{malloc}, which interact with the
additional synchronisation in unintuitive ways.  Nevertheless, they
suggest that the cost of a {\technique} critical section is small even
on the scale of microseconds, and hence that {\technique} will be able
to fix bugs in code which runs millions of times per second without
the program as a whole suffering crippling performance degradation.  I
cover this theme in more detail in
\autoref{sect:eval:why:fix_overhead}.

\subsection{Bugs in real programs}
\label{sect:eval:does:real}

The previous section showed that {\technique} can be used to reproduce
and fix bugs in some simple artificial test programs.  This section
repeats the experiments using two bugs taken from real programs:
\begin{itemize}
\item The first, \bugname{thunderbird}, is Mozilla bug number
  391259\cite{Mery2007}, a time-of-check, time-of-use race in the IMAP
  client component of Thunderbird, a popular open-source e-mail
  client.  The relevant parts of the program are shown in
  figures~\ref{fig:eval:real_bugs:programs:thunderbird:crashing}
  and~\ref{fig:eval:real_bugs:programs:thunderbird:interfering}.  If
  \verb|m_transport| is set to \verb|NULL| by the
  \gls{interferingthread} in between the two accesses in the crashing
  one then the program will crash.
\item The second, \bugname{mysql}, is MySQL bug number
  56324\cite{Correia2010}.  A simplified version of the buggy code is
  shown in figures~\ref{fig:eval:real_bugs:programs:mysql:crashing}
  and~\ref{fig:eval:real_bugs:programs:mysql:interfering}.  The
  program will crash if the interfering thread sets
  \texttt{PSI\_server} to \texttt{NULL} in between the two accesses to
  that variable in the crashing thread.
\end{itemize}
{\Technique} is able to reproduce and fix both of these bugs.  For
these tests, unless otherwise noted, I assumed that the crashing
instruction had already been identified, rather than attempting to
discover it automatically using {\technique}.

\begin{sanefig}
  \begin{tabular}{p{8.9cm}p{5.8cm}}
    \subfigure[][{\rm \bugname{thunderbird\hspace{-1pt}}} crashing thread]{
      \begin{minipage}{8cm}
        \begin{literalC}
          if (this->m\_transport) \clbrace
            this->m\_transport->SetTimeout();
          \crbrace
        \end{literalC}
      \end{minipage}
      \label{fig:eval:real_bugs:programs:thunderbird:crashing}
    }
    &
    \subfigure[][{\rm \bugname{thunderbird\hspace{-1pt}}} interfering thread]{
      \begin{minipage}{5.5cm}
        \begin{literalC}
          \\
          this->m\_transport = NULL;\\
        \end{literalC}
      \end{minipage}
      \label{fig:eval:real_bugs:programs:thunderbird:interfering}
    }\\
    \subfigure[][{\rm \bugname{mysql\hspace{-1pt}}} crashing thread]{
      \begin{minipage}{8cm}
        \begin{literalC}
          if (PSI\_server) \clbrace
          PSI\_server->delete\_current\_thread();
          \crbrace
        \end{literalC}
      \end{minipage}
      \label{fig:eval:real_bugs:programs:mysql:crashing}
    }
    &
    \subfigure[][{\rm \bugname{mysql\hspace{-1pt}}} interfering thread]{
      \begin{minipage}{5.5cm}
        \begin{literalC}
          \\
          PSI\_server = NULL;\\
        \end{literalC}
      \end{minipage}
      \label{fig:eval:real_bugs:programs:mysql:interfering}
    }
  \end{tabular}
  \caption{Test bugs in real programs.}
  \label{fig:eval:real_bugs:programs}
\end{sanefig}

\subsubsection{Characterising the bugs}

\autoref{tab:eval:real_bugs:analysis_time} shows how long it takes to
build the \gls{programmodel} and \glspl{verificationcondition} for
these bugs.  Note that the time to build the \gls{programmodel} is
dramatically larger for real programs than it was for the artificial
ones considered earlier, but the time to generate the
\glspl{verificationcondition} is largely unchanged.  This is because
      {\technique} must examine the entire program in order to build
      the \gls{programmodel}, but only needs to examine the
      \gls{analysiswindow} to build the \glspl{verificationcondition}.
      The high cost of building the model is somewhat mitigated by the
      fact that it is built for the program rather than for any
      particular bug, and so the cost could be amortised if there were
      several bugs in the same program.

\begin{sanetab}
  \begin{tabbular}{|p{2.72cm}|p{5.8cm}|p{5.8cm}|}
    \hline
    Test bug                  & \Gls{programmodel}  & \Glspl{verificationcondition} \\
    \hline
    \bugname{thunderbird}     & $1240 \pm^{10}_p 10$s & $0.39 \pm^{10}_p 0.01$s \\
    \bugname{mysql}           & $1088 \pm^{10}_p 7$s  & $1.13 \pm^{10}_p 0.02$s\\
    \hline
  \end{tabbular}
  \caption{Time taken to build the \gls{programmodel} and
    \glspl{verificationcondition} for the bugs taken from real
    programs.  All tests were run eleven times with the result of the
    first run discarded.}
  \label{tab:eval:real_bugs:analysis_time}
\end{sanetab}

{\Technique} generated one false positive \gls{verificationcondition}
for each bug, in addition to the desired true positive, both of which
were caused by incompleteness in the {\technique}'s model of the
program's behaviour.  In the case of \bugname{thunderbird}, the
problem was the lack of knowledge of the program's existing
synchronisation structure: {\technique} located another place in the
program which set \texttt{m\_transport} to \texttt{NULL}, and
correctly identified that interleaving that store with the
\gls{crashingthread} might lead to a crash, but failed to notice that
an existing lock prevented the interleaving from happening.  The
\bugname{mysql} false positive, by contrast, was caused by an
incomplete model of the program's data structure\editorial{Looks like
  a typo; isn't; is actually an important distinction.  Think harder
  about how to make that clear.}.  {\Technique} located another
instruction which could set \texttt{PSI\_server} and which could
potentially race with the \gls{crashingthread}, but in that case the
value stored was always a valid pointer and so the interleaving could
not lead to a crash.

\subsubsection{Reproducing the bugs}

\begin{sanetab}
  \begin{tabbular}{|p{2.72cm}|l|l|l|}
    \hline
    Bug                   & True positive enforcer & False positive enforcer & Combined enforcer \\
    \hline
    \bugname{thunderbird} & $0.640 \pm^{10}_p 0.010$s     & $0.640 \pm^{10}_p 0.010$s     & $0.710 \pm^{10}_p 0.020$s\\
    \bugname{mysql}       & $0.566 \pm^{10}_p 0.011$s     & $0.553 \pm^{10}_p 0.010$s     & $0.678 \pm^{10}_p 0.010$s\\
    \hline    
  \end{tabbular}
  \caption{Time taken building the various \glspl{bugenforcer}}
  \label{tab:eval:real_bugs:build_enforcer_times}
\end{sanetab}

\begin{sanetab}
  \begin{tabbular}{|l|p{2.46cm}|p{2.46cm}|p{2.46cm}|p{2.46cm}|}
    \hline
                              & \multicolumn{4}{c|}{Enforcer} \\
    \cline{2-5}
    Bug                       & None & True positive & False positive & Combined \\
    \hline
    \bugname{thunderbird}     & 0/10 &    &   &    \\
    \hspace{1em}100--200ms timeout &   & 0/10  & 0/10 & 0/10  \\
    \hspace{1em}5s timeout    &   & 10/10 & 0/10 & 10/10 \\
    \bugname{mysql}           &   &    &   &    \\
    \hline
  \end{tabbular}
  \caption{Reproduction counts for the different bugs and
    configurations.  \todo{Need more data.}}
  \label{tab:eval:real_bugs:repro_effectiveness}
\end{sanetab}

\noindent
All four \glspl{verificationcondition} can be converted to
\glspl{bugenforcer}.
\autoref{tab:eval:real_bugs:build_enforcer_times} shows how long it
took to do so; as can be seen, this step was very fast.

I then attempted to evaluate the efficacy of the generated enforcers.
The results are shown in
\autoref{tab:eval:real_bugs:repro_effectiveness}.  For the
\bugname{mysql} bug, I used the \texttt{rpl\_change\_master} test out
of the MySQL test suite, as it runs quickly without manual
intervention and exercises the buggy code, and ran it one hundred
times in each configuration.  As can be seen, the true positive and
combined enforcers were effective at reproducing this bug, and it did
not reproduce at all without an enforcer or with the false positive
enforcer.

For the \bugname{thunderbird} bug, no convenient automated test was
available, and so I exercised the buggy code via manual interaction
with the Thunderbird GUI by clicking on an IMAP folder and then
quickly clicking the close button.  I repeated this ten times in each
configuration, restarting Thunderbird between each attempt.  The IMAP
folder was the only folder in an account on a local Dovecot 1.2.9 IMAP
server which had no other users, and no other IMAP accounts were
configured in Thunderbird.  The IMAP folder itself was empty.  None of
the {\technique} \glspl{bugenforcer} were able to reproduce this bug
using their default 100--200ms timeout, but increasing the timeout to
five seconds caused the bug to reproduce easily.  The program was
still quite usable even with this long delay, as the bug is in code
which executes infrequently, and only in a background thread.

This illustrates an important weakness of the {\technique} approach:
the timeout must be tailored to the application being tested, and in
some cases the bug as well.  Too small a timeout will prevent the
threads from properly rendezvousing, preventing the bug from
reproducing at all, while too long a timeout will cause a large probe
effect, also reducing the likelihood of reproduction.  Very roughly,
the timeout must be of the same general scale as the process which
triggers the bug.  In this case, that process involves user
interaction, and so the timeout must be broadly the same scale as
those interactions; five seconds is on that scale, whereas 200ms is
not.

\subsubsection{Fixing the bugs}

\begin{sanetab}
  \begin{tabbular}{|p{3.4cm}|p{11.25cm}|}
    \hline
    Bug                  & Time building fix \\
    \hline
    \bugname{mysql}      & $287 \pm_p^{10} 6$ms \\
    \bugname{thunderbird} & $373 \pm_p^{10} 6$ms \\
    \hline
  \end{tabbular}
  \caption{Time taken to convert \glspl{verificationcondition} to fixes.}
  \label{tab:eval:real_bugs:time_building_fixes}
\end{sanetab}

\noindent
These \glspl{verificationcondition} can also be converted to fixes;
the time taken to do so is shown in
\autoref{tab:eval:real_bugs:time_building_fixes}.  The fixes generated
are similar for both bugs: one critical section covering the two loads
in the \gls{crashingthread}, and another covering the store in the
\gls{interferingthread}\editorial{Diagram, maybe?}.  It is hard to
validate experimentally that these fixes are correct, as the bugs
reproduce quite rarely even without the fix\footnote{Due to
  implementation limitations, it is not possible to load an
  {\technique} fix and an {\technique} \gls{bugenforcer} into the same
  program.}\!\!, but manual inspection suggested that they had correctly
eliminated the dangerous interleaving.  It is also hard to
experimentally evaluate the performance impact of these fixes, as, in
the case of \bugname{thunderbird}, there is no convenient metric of
performance, beyond noting that performance was qualitatively
unaffected, and, in the case of \bugname{mysql}, the fix is to code
which executes sufficiently rarely that the system-level overhead was
immeasurably small.

These are not the fixes which a human programmer would make.  In
particular, the call to \texttt{delete\_current\_thread}, in
\bugname{mysql}, and \texttt{SetTimeout}, in \bugname{thunderbird},
are not protected in any way.  This means that the
\gls{crashingthread} might continue to execute a method in
\texttt{m\_transport} or \texttt{PSI\_server} after those variables
have been cleared.  In this case, the implementations of those methods
means that this is safe, but doing so does not concord with common
programming practice, and changes in the implementation could render
it unsafe without being visible to {\technique}.  This might cause
{\technique} to generate a fix which is qualitatively incomplete,
despite correctly eliminating all of the identified dangerous
interleavings.

The problem here lies in {\technique}'s definition of a ``bug'': an
atomicity violation which might lead to a crash on a particular
instruction.  Once {\technique} has ensured that that specific
instruction cannot crash, it considers the bug to be fixed; if the
program then crashes five instructions later, {\technique} defines
that to be a different bug, requiring a different fix.  This will not
necessarily agree closely with a programmer's or user's idea of what
it means to fix a bug.

\subsubsection{Finding unknown bugs}
\label{sect:how:finding_unknown}

\todo{Change in test machine here, but that's not as apparent as it
  should be from the text.}

\begin{sanetab}
  \begin{tabbular}{|l|p{4.35cm}|p{4.35cm}|}
    \hline
    Phase & Time taken & Cores used \\
    \hline
    Building \gls{programmodel} & $571 \pm_{\mu}^{10} 1$s & 1\\
    Deriving \glspl{verificationcondition} & $8500 \pm_{\mu}^{10} 100$s & 10 \\
    Converting to \glspl{bugenforcer} & $204 \pm_{\mu}^{10} 3$s & 10 \\
    \hdashline
    Total & $9300 \pm_{\mu} 100$s & NA \\
    \hline
  \end{tabbular}
  \caption{Time taken to generate a full suite of \glspl{bugenforcer}
    for MySQL on an AMD Opteron 6168 with 16GiB of memory.  The
    complete analysis was run eleven times and the results of the
    first run discarded; the results here are the average of the
    remaining ten runs.  Operating system disk caches were discarded
    in between each run.  The last two phases were parallelised; the
    first was not.}
  \label{tab:eval:does:building_all_enforcers_times}
\end{sanetab}

\noindent
MySQL has an extensive automated test suite, and so {\technique} can
be used to look for previously unknown bugs by generating every
possible \gls{bugenforcer} and running the test suite under each of
them.  {\Implementation} took two and a half hours to generate the
10173 \glspl{bugenforcer} for MySQL (see
\autoref{tab:eval:does:building_all_enforcers_times}).  To test the
effectiveness of these enforcers, I ran the
\texttt{rpl\_change\_master} test repeatedly with each\footnote{This
  experiment was structured as a series of eleven rounds, with each
  enforcer used once in each round.  Apart from stragglers at the end
  of each round, I tested ten enforcers in parallel.  The order of
  \glspl{bugenforcer}, and hence which \glspl{bugenforcer} ran in
  parallel with which other \glspl{bugenforcer}, was chosen randomly
  in each round.  The system used for this test was the same Opteron
  6168 as was used to generate the \glspl{bugenforcer}.  I discarded
  the results of the first round of testing; the results here are for
  the remaining ten rounds.  The results for the no-enforcer case were
  produced by running the test 10,000 times without an enforcer, again
  running ten instances of the test in parallel.}\!\!\!.  The results are
shown in \autoref{tab:eval:does:finding_unknown}.  Three of the
enforcers were able to reproduce the bugs for which they were
designed.  The first, hereafter referred to as enforcer A, reproduced
the \bugname{mysql} bug, as desired.  The other two, enforcers B and
C, reproduced essentially similar races elsewhere in MySQL.  I was
unaware of these bugs before running this experiment.  All three bugs
were very rare without an enforcer, or with the wrong enforcer, but
reproduced very easily when an appropriate enforcer was used.

It is perhaps surprising that the reproduction rates are lower with an
inappropriate enforcer than they are with no enforcer at all.  This
reflects the fact that randomly adding delays to a program's execution
is not an effective way of reproducing bugs: delaying a thread reduces
the program's effective concurrency, and unless the delays are
carefully positioned this will outweigh the benefits of encouraging it
to explore less-common schedules.

\begin{sanetab}
\begin{tabbular}{|l|l|l|l|}
\hline
         & \multicolumn{3}{c|}{Reproduction rate} \\\cline{2-4}
Enforcer\, & Bug A                         & Bug B                                    & Bug C \\
\hline
None     & 0/10000                       & $0.03 \in [0.02,0.06]^{10000}_{\infty}\%$     & $0.29 \in [0.21,0.38]^{10000}_{\infty}\%$\\
\hdashline
A        & $90 \in [80,100]^{10}_{\infty}\%$ & 0/10                                     & 0/10 \\
B        & 0/10                          & 10/10                                    & 0/10 \\
C        & 0/10                          & 0/10                                     & 10/10 \\
\hdashline
Other    & 0/101700                      & $0.014 \in [0.009,0.020]^{101700}_{\infty}\%$ & $0.10 \in [0.08,0.11]^{101700}_{\infty}\%$ \\
\hline
\end{tabbular}
\caption{Effectiveness of {\technique} at finding unknown bugs.}
\label{tab:eval:does:finding_unknown}
\end{sanetab}

\section{How does it work?}
\label{sect:eval:how_does_it_work}

The previous section demonstrated that {\technique} works, at a basic
level, for at least some real and artificial bugs.  This section aims
to expand upon this by giving more details of the way in which it
works, by breaking the time and memory usage down into the different
phases of the analysis and determining which phases represent the most
important bottlenecks.  For these experiments, I selected ten thousand
memory-accessing instructions at random from MySQL and produced
\glspl{bugenforcer} and fixes for each in turn, recording the time
spent in each of the various steps of the analysis.

The analysis of a single potentially crashing instruction can be
roughly divided into four phases:
\begin{itemize}
\item Per-\gls{crashingthread} analysis work.  {\Technique} starts
  analysing a potentially-crashing instruction by constructing the
  crashing {\StateMachine}, and from that it builds the interfering
  \glspl{cfg}.  This work is done once for each potentially-crashing
  instruction.
\item Per-\gls{interferingthread} analysis work.  Each crashing
  {\StateMachine} will generate zero or more
  \glspl{interferingthread}, each of which is analysed independently.
\item Building the \gls{bugenforcer}.  Each \gls{interferingthread} in
  turn generates zero or one \glspl{verificationcondition}.  Each
  \gls{verificationcondition} is processed in isolation to produce a
  single \gls{bugenforcer}.
\item Building the fixes.  The \glspl{verificationcondition} can
  instead be converted into fixes.  Again, each
  \gls{verificationcondition} is processed in isolation to produce a
  single fix.
\end{itemize}
I consider each phase in turn.

\subsection{Per-\gls{crashingthread} analysis}

\begin{sanefig}
  \biggraph{eval/phase_breakdown/per_crashing.tex}
  \caption{Distributions of time taken by the per-crashing instruction
    steps of the analysis.}
  \label{fig:eval:how:per_crashing_times}
\end{sanefig}

\noindent
The initial part of the analysis is performed once for each
potentially-crashing instruction.  For each instruction, {\technique}
derives the crashing \gls{cfg}
(\autoref{sect:derive:build_crashing_cfg}), decompiles it to a
{\StateMachine} (\autoref{sect:derive:compile_cfg}), simplifies it
(\autoref{sect:derive:simplify_sm}), builds the interfering
\glspl{cfg} (\autoref{sect:derive:write_side}), and then derives
C-atomic (\autoref{sect:derive:inferred_assumption} and
\autoref{sect:derive:w_isolation}).
\autoref{fig:eval:how:per_crashing_times} shows how much time is spent
in each of these steps.  This figure shows several useful pieces of
information:
\begin{itemize}
\item The main part of the figure shows the probability density
  function of the time spent in each part of the analysis.  Note that
  this is shown on a log scale, and that the density is with respect
  to log time.  The kernel used in estimating the probability density
  function is shown below the PDF itself; this is the contribution
  which a single sample makes to the PDF\footnote{For these charts, I
    used a rectangular kernel of width $2.75Rn^{-0.2}$, where $R$ is
    the log inter-quartile range and $n$ the number of samples.  This
    bandwidth was chosen as it is reasonably robust to outliers and
    minimises the expected mean square error for log-Gaussian
    data.}\!\!.
\item The median of the distribution is shown as a horizontal line
  across the PDF and its arithmetic mean as a small cross.
\item 90\% confidence intervals for the PDF and median are given by
  grey areas and for the mean by the vertical bars.  All confidence
  intervals were calculated using a 1,000 replicate bootstrap.
\item The ``Total'' PDF gives the distribution of the total time taken
  for each potentially-crashing instruction, measured from the start
  of processing to the end.  The ``Defect'' PDF, to its left, shows
  the difference between the total time taken and the sum of all of
  the measured steps.  As can be seen, it is small relative to the
  other quantities measured, which is necessary for the other
  measurements to be meaningful.
\item The boxes above the PDFs give the number of potentially-crashing
  instructions which failed to complete each part of the analysis,
  sized such that a constant area represents a constant number of
  instructions across the figure.  The reasons for these failures are
  given in \autoref{tab:eval:how:failures_per_crashing}.
  \begin{sanetab}
    \begin{tabbular}{|p{5.3cm}|p{2.9cm}|p{2.9cm}|p{2.9cm}|}
      \hline
      Step & Instructions starting step                 & Out of time & Out of memory \\
      \hline
      \RaggedRight Compile crashing {\StateMachine}     & 8031 & 1 & 0 \\
      \RaggedRight Simplifying crashing {\StateMachine} & 8030 & 2 & 0 \\
      \RaggedRight Derive C-atomic                      & 3678 & 1 & 2 \\
      \RaggedRight Process interfering \glspl{cfg}      & 3675 & 0 & 1 \\
      \hline
    \end{tabbular}
    \caption{Causes of failures during per-crashing instruction
      processing.  Note that the timeout runs from the start of the
      per-crashing instruction phase, rather than being restarted for
      each step. \todo{Error bars? Maybe express as ratios?}}
    \label{tab:eval:how:failures_per_crashing}
  \end{sanetab}
\item The boxes below the PDFs give the number of potentially-crashing
  instructions which were not processed in each part of the analysis.
  Some of these skips are caused by failures in other parts of the
  analysis, but the majority are caused by one of the early analysis
  phases being sufficient to prove that a particular instruction
  cannot possibly crash due to an atomicity violation bug, allowing
  {\implementation} to skip the remaining phases.  These are discussed
  in more detail below.
\end{itemize}
The most important observation to draw from this figure, aside from
the gross summary of how long each step takes, is that most of the
distributions are dominated by their tails, in the sense that the mean
is often more than an order of magnitude greater than the median.
This reflects the fact that many of the algorithms have worst-case
running time far worse than their common case.  Instructions which
happen to hit one of the slow cases take a very long time to complete,
while those which avoid the slow cases complete very quickly.  The
time spent deriving C-atomic, for instance, has a median of 1.3ms and
a mean of 170ms, while the total time taken has a median of 11ms and a
mean of eight seconds.

Aside from those gross features, the distributions also exhibit some
multi-modal behaviour, visible on the chart as a number of ``bulbs''
in the PDFs.  These are accounted for by various special cases within
{\implementation}:
\begin{itemize}
\item The first phase, ``Build crashing \gls{cfg}'', has a small mode
  at around 20$\mu$s.  The potentially-crashing instructions in this
  bulb are all part of the program's ELF PLT stubs.  {\Implementation}
  assumes that these will never crash, allowing it to skip further
  processing with very little work.
\item The same phase also has a mode at about 2ms, which consists of
  instructions which access either the stack or a statically constant
  addresses.  There is no possibility of these instructions crashing
  due to a race, so {\implementation} skips most of the analysis when
  it detects one.
\item The next phase, ``Compile crashing {\StateMachine}'', has a mode
  at about 4ms.  This dereferences of pointers which the static
  analysis component of the \gls{programmodel} can show to be valid,
  either because they are fixed offsets from the stack pointer or
  because they must have been dereferenced in the same thread before
  reaching this instruction.  The {\StateMachine} is replaced with the
  single state {\stSurvive}.
\item Finally, the fourth phase, ``Derive interfering \glspl{cfg}'',
  has a very large mode at about 2ms.  This consists of instructions
  where none of the memory-accessing instructions remaining after
  simplification could possibly race with another thread according to
  the dynamic component of the \gls{programmodel}.  Such instructions
  will never generate any interfering \glspl{cfg}, allowing
  {\technique} to skip the rest of the analysis.
\end{itemize}
The overall effect of these special cases is that most
potentially-crashing program instructions are able to skip most steps
of the analysis.  This is a useful property when analysing a large
number of instructions speculatively.

\subsection{Per-\gls{interferingthread} analysis}
\label{sect:eval:how:per_interfering}

The per-crashing instruction analysis generates a large number of
pairs of crashing {\StateMachine} and interfering \gls{cfg} which are
analysed in the per-\gls{interferingthread} analysis phase.  The time
taken to do so is illustrated in
\autoref{fig:eval:how:per_interfering}, in the same style as
\autoref{fig:eval:how:per_crashing_times}.  Failures encountered
during this phase are detailed in
\autoref{tab:eval:how:failures_per_interfering}.

\begin{sanefig}
  \biggraph{eval/phase_breakdown/per_interfering}
  \caption{Time taken by per-\gls{interferingthread} analysis steps,
    as distributions over the 27535 interfering \glspl{cfg} generated
    by the per-crashing instruction phase.  In this figure, the
    {\StateMachine}-building steps include {\StateMachine}
    simplification.  The second step, ``Rederive crashing
    {\StateMachine}'', performs various additional simplifications to
    the crashing {\StateMachine} which become possible once
    {\technique} has identified the interfering {\StateMachine}.}
  \label{fig:eval:how:per_interfering}
\end{sanefig}

\begin{sanetab}
  \begin{tabbular}{|p{5.3cm}|p{2.9cm}|p{2.9cm}|p{2.9cm}|}
    \hline
    Step                                & \Glspl{cfg} starting step & Out of time & Out of memory \\
    \hline
    Build interfering {\StateMachine}   & 27535                     & 21          & 1 \\
    Rederive crashing {\StateMachine}   & 23513                     & 44          & 0 \\
    Run \gls{ic-atomic} {\StateMachine} & 13055                     & 47          & 35 \\
    Build cross-product {\StateMachine} & 12935                     & 1           & 0 \\
    Run cross-product {\StateMachine}   & 12934                     & 47          & 0 \\
    \hdashline
    Total                               & 27535                     & 160         & 36 \\
    \hline
  \end{tabbular}
  \caption{Causes of failures during per-\gls{interferingthread}
    processing.  Note that the timeout runs from the start of the
    per-\gls{interferingthread} phase, rather than being restarted for
    each step. \todo{Maybe re-express as ratios so that I can add some
      error bars?}}
  \label{tab:eval:how:failures_per_interfering}
\end{sanetab}
As with \autoref{fig:eval:how:per_crashing_times}, this figure shows
that most of the distributions involved are dominated by their tails,
indicating that most of the analysis time is spent processing a small
minority of unusually difficult \glspl{cfg}.  The two symbolic
execution phases are particularly prone to these outliers, because
they must consider every path through the relevant {\StateMachine} and
the number of such paths rises exponentially with the size of the
{\StateMachine}.  The ``Derive C-atomic'' per-\gls{crashingthread}
analysis step likewise shows a particularly long tail in which it is
particularly expensive.

More surprisingly, symbolically executing the \gls{ic-atomic}
{\StateMachine} is more expensive than executing the cross-product
{\StateMachine}, despite having to consider far fewer instruction
orderings.  This is because it has less information about the
configurations in which the {\StateMachines} might start: the
cross-product execution assumes that the \gls{ic-atomic} constraint
holds when the {\StateMachines} start, often eliminating a large
number of possible initial states, whereas the \gls{ic-atomic}
execution can only assume the weaker C-atomic constraint.

\begin{sanefig}
  \biggraph{eval/phase_breakdown/per_interfering_no_w_atomic}
  \caption{Time taken by per-\gls{interferingthread} analysis steps,
    with the \gls{ic-atomic} steps disabled.}
  \label{fig:eval:how:per_interfering:no_ic_atomic}
\end{sanefig}

This is further illustrated in
\autoref{fig:eval:how:per_interfering:no_ic_atomic}, which shows how
long the various steps take when {\technique} assumes \gls{ic-atomic}
is the constant \true, rather than attempting to derive it.  This
eliminates the steps involved in deriving \gls{ic-atomic}, which take
500ms, but increases the cost of the later steps so that the total
time taken was unchanged\footnote{In fact, the average time taken
  actually \emph{increased} slightly, from $0.52 \in [0.46,
    0.59]_{1000}^{27338}$ to $0.59 \in [0.51, 0.67]_{1000}^{27432}$,
  but that was not statistically significant, and was in any case
  partly influenced by changes in the behaviour of failing runs.}.
Disabling \gls{ic-atomic} processing also increased the number of
\glspl{verificationcondition} generated, from 3870 to 6613.  These
extra conditions are all, by construction, false positives, and all
would require run-time verification.  \todo{Not sure how much that
  added, really.}

\subsection{Costs of building \gls{bugenforcer}}

\begin{sanefig}
  \biggraph{eval/phase_breakdown/build_enforcer}
  \caption{Time taken to convert the 3870
    \glspl{verificationcondition} generated by the experiments in
    \autoref{sect:eval:how:per_interfering} into \glspl{bugenforcer}.
    All of the failures were caused by running out of memory; there
    were no timeouts during this experiment.}
  \label{fig:eval:how:build_enforcer}
\end{sanefig}

\begin{sanetab}
  \begin{tabbular}{|p{5.6cm}|p{2.8cm}|p{5.6cm}|}
    \hline
    Step & \Glspl{verificationcondition} starting step & Out of memory \\
    \hline
    Extract happens-before graph & 3870 & 27 \\
    Place side conditions        & 3843 & 3 \\
    Compile                      & 3834 & 2 \\
    \hline
  \end{tabbular}
  \caption{Causes of failures converting \glspl{verificationcondition}
    to \glspl{bugenforcer}.  There were no timeouts in this test.}
  \label{fig:eval:how:build_enforcer_failures}
\end{sanetab}

\noindent
\autoref{fig:eval:how:build_enforcer} shows how long it takes to
convert \glspl{verificationcondition} into \glspl{bugenforcer}.  The
figure divides the time taken into five steps:
\begin{itemize}
\item Extracting the happens-before graph, as discussed in
  \autoref{sect:enforce:slice_hb_graph}.  This step is generally
  reasonably quick, with a median time of 20ms, but has a long tail of
  slow and memory-hungry operations.  This reflects the nature of the
  algorithm used: BDD reordering has a good common-case cost but a
  very poor worst-case one.  The \glspl{verificationcondition} which
  avoid the worst-case performance complete very quickly and those
  which do not form the long tail.
\item Determining when the verification condition's input expressions
  become available, as discussed in \autoref{sect:enforce:place_vcs}.
  This is, unsurprisingly, a very quick step, with relatively few
  outliers, as the rules governing when inputs become available are
  simple and easily applied.
\item Deciding how to evaluate the non-happens before component of the
  \gls{verificationcondition} by placing side conditions on the
  happens-before and control flow graphs.  Like the first step, this
  one is implemented using BDD reordering operations, and so is
  generally fast with a long tail of slow operations.  The small bulb
  of \glspl{verificationcondition} which complete in around 20$\mu$s
  consists of the \glspl{verificationcondition} which depend only on
  inputs which are available at the start of the \gls{crashingthread},
  for which the placement problem is trivial.
\item Building the patch strategy, expressed as the $\mathit{Cont}$
  and $\mathit{Patch}$ sets, as discussed in
  \autoref{sect:enforce:gain_control}.  The secondary mode at around
  2ms consists of \glspl{bugenforcer} which only need to patch
  instructions which are large enough to accommodate a branch
  instruction.  Patching these will never corrupt any other
  instructions, and so building the patch strategy is trivial.
\item Compiling the resulting enforcer into an ELF shared object.
  {\Implementation} performs this step by generating a C source file
  and passing it off to the system compiler and linker, with the bulk
  of the time spent in those external programs.  This makes it
  difficult to provide any useful analysis on why this step takes as
  long as it does.
\end{itemize}
Somewhat surprisingly, {\technique} was able to eliminate six
\glspl{verificationcondition} whilst placing side conditions.  This
was due to the incompleteness of {\technique}'s SMT solver.  The
solver makes use of a number of heuristics based on the BDD structure
of the \gls{verificationcondition} and these heuristics produce
slightly different results as the side condition algorithm manipulates
that structure.  In those six \glspl{verificationcondition}, the
solver was unable to show that the original condition was
unsatisfiable, but was able to show that one of the rearranged forms
was, and hence that the bug could never be reproduced.  There was
therefore no need to generate \glspl{bugenforcer} for any of them and
{\technique} skipped the remaining steps involved in building one.

Ignoring those six unsatisfiable \glspl{verificationcondition}, this
phase suffered a total of thirty-two failures, giving a failure rate
of 0.8\%.  The per-\gls{crashingthread} and
per-\gls{interferingthread} both suffered failure rates of 0.7\%;
collectively, these suggest that {\technique}, with these settings,
will be unable to generate \glspl{bugenforcer} for roughly 2.2\% of
potential bugs of the targeted form.  While obviously worse than a 0\%
failure rate, a 2.2\% one is still reasonably low, and is unlikely to
be a crippling limitation.

\subsection{Costs of building fixes}

\todo{RERUN}

\Glspl{verificationcondition} can also be converted into fixes.
\autoref{tab:eval:gen_fix_perf} shows how long that takes, using the
same one thousand \glspl{verificationcondition} as used in the
previous experiment.  As can be seen, the time taken is completely
dominated by the system compiler.  This makes it difficult to explain
why the process takes as long as it does in any meaningful way.
Nevertheless, these results confirm that building fixes from
\glspl{verificationcondition} is itself a very fast operation,
compared to building the \glspl{verificationcondition} themselves, and
so this step is unlikely to be the most important barrier to practical
use of {\technique}.

\begin{sanetab}
  \begin{tabbular}{|l|p{2.5cm}|p{2.5cm}|p{2.5cm}|p{2.5cm}|}
    \hline
          &      & \multicolumn{3}{c|}{Percentiles} \\
    \cline{3-5}
    Phase & Mean & $5^{th}$\% & $50^{th}$\% & $95^{th}$\%  \\
    \hline
    Find critical sections & $0.84 \pm^{4355}_\mu 0.05$ & $[0.116,0.121]$ & $[0.308,0.323]$ & $[2.10,2.44]$ \\
    Build patch strategy   & $7.8 \pm^{4355}_\mu 0.3$ & $[0.373,0.403]$ & $[0.940,0.962]$ & $[38.7,43.8]$ \\
    Graph expansion        & $2.2 \pm^{4355}_\mu 0.1$ & $[0.232,0.242]$ & $[0.554,0.576]$ & $[10,13]$ \\
    System compiler        & $120.8 \pm^{4355}_\mu 0.4$ & $[88.0,88.9]$ & $[120,122]$ & $[146,148]$ \\
    \hdashline
    Total & $131.6 \pm^{4355}_\mu 0.5$ & $[95.8,97.4]$ & $[130.0,131.2]$ & $[168.3,174.1]$  \\
    \hline
  \end{tabbular}
  \caption{Time taken to convert 1000 \glspl{verificationcondition}
    generated from MySQL to fixes.  All times in milliseconds.
    Distribution percentiles are given as 90\% confidence intervals,
    derived using a bootstrap with 1000 replicates.}
  \label{tab:eval:gen_fix_perf}
\end{sanetab}

\subsection{Dynamic aliasing analysis}

{\Technique} relies on an initial dynamic analysis
(\autoref{sect:program_model}) to build a model of the program's
aliasing behaviour, and if this is incomplete then it will not be able
to find all bugs in the program.
Figures~\ref{fig:eval:dyn_convergence:mysqld},
\ref{fig:eval:dyn_convergence:thunderbird},
and~\ref{fig:eval:dyn_convergence:pbzip2} show the number of edges in
the aliasing table, expressed as a proportion of the edges in the
final table, as a function of time, for a variety of test programs and
workloads.  These figures show that the aliasing table had in all
cases effectively converged on its final value within a few minutes,
suggesting that, for these workloads, it would only be necessary to
run the program to be analysed under the dynamic analysis for a few
minutes to achieve adequate coverage.  This is not an unreasonable
burden to place on the user.

\begin{sanefig}
  \begin{tabular}{cc}
    \subfigure[][rpl\_change\_master]{
      \biggraph{eval/dyn_convergence/rpl_change_master.tex}
    } &
    \subfigure[][innodb\_multi\_update]{
      \biggraph{eval/dyn_convergence/innodb_multi_update.tex}
    } \\
    \subfigure[][binlog\_stm\_drop\_tbl]{
      \biggraph{eval/dyn_convergence/binlog_stm_drop_tbl.tex}
    } &
    \subfigure[][timestamp\_basic]{
      \biggraph{eval/dyn_convergence/timestamp_basic.tex}
    }
  \end{tabular}
  \vspace{-12pt}
  \caption{Dynamic aliasing coverage against time for MySQL, using
    some tests out of the test suite.  Dashed vertical lines show where the
    program was restarted.}
  \label{fig:eval:dyn_convergence:mysqld}
\end{sanefig}

\begin{sanefig}
  \biggraph{eval/dyn_convergence/thunderbird}
  \vspace{-24pt}
  \caption{Dynamic aliasing coverage against time for Thunderbird
    during normal usage.  Dashed vertical lines show where the program was
    restarted.}
  \label{fig:eval:dyn_convergence:thunderbird}
\end{sanefig}

\begin{sanefig}
  \biggraph{eval/dyn_convergence/pbzip2}
  \vspace{-24pt}
  \caption{Dynamic aliasing coverage against time for pbzip2 version
    1.1.6 while compressing three randomly-generated 10MiB files.
    Dashed vertical lines show where the program was restarted.}
  \label{fig:eval:dyn_convergence:pbzip2}
\end{sanefig}

I also briefly investigated the performance of the analysis tool
itself, using pbzip2 as a test program.  For these experiments, I
compressed ten randomly-generated 100MiB files with and without the
dynamic analysis.  Without the dynamic analysis, compressing one file
took $7.8 \pm_\mu^{10} 0.1$ seconds; with the dynamic analysis, this
increased to $274 \pm_\mu^{10} 2$ seconds, a factor of roughly
thirty-five.  This is a rather large overhead, and would be infeasible
in a production environment, but is tolerable for something which
needs to run for a few tens of minutes in a development one.  For
comparison, a null Valgrind skin completed this test in $226.6
\pm_\mu^{10} 0.5$ seconds, an overhead of a factor of twenty-nine,
suggesting that most of the overhead of the dynamic analysis tool
comes simply from the fact that it is implemented as a Valgrind skin.
Re-implementing it in a faster analysis framework, such as
PIN\cite{Luk2005}, might therefore provide a useful speed-up.

\section{Why does it work?}
\label{sect:eval:why_does_it_work}

Previous sections have established that {\technique} works at a basic
level and given some details of its operation.  This section aims to
expand on that by providing some explanations for the properties
observed and showing how they follow from the {\technique} design.

\subsection{Importance of side-condition checking}

The most distinctive feature of {\technique}'s \gls{bugenforcer}
mechanism, compared to previous work such as Kivati\cite{Chew2010} or
MUVI\cite{Lu2007}, is side-condition checking, which enables it to
avoid spending time enforcing a particular concurrent ordering if some
aspect of the program's state means that doing so would be
unproductive.  \autoref{fig:eval:indexed_toctou:no_scs} shows the
reproduction time for the \bugname{toctou} test with a full enforcer
and with one which does not perform any side-condition checking.  This
clearly shows not only that reproduction performance without side
condition checking is far worse than with a full enforcer, but also
that it is worse than not using an enforcer at all.  Without
side-condition checking, the enforcer enforces the happens-before
graph every time the buggy code runs, causing the program to run far
more slowly, so the buggy code runs far less frequently.  In this
case, the happens-before graph is quite simple but the side-condition
has a low probability of succeeding, and increasing the likelihood of
reproducing the happens-before graph is insufficient to outweigh the
reduced number of chances to satisfy the
side-condition.

\begin{sanefig}
  \biggraph{eval/artificial_bugs/special/indexed_toctou_no_scs.tex}
  \caption{Effect of side-condition checking on the time taken to
    reproduce the indexed\_toctou bug.  Each configuration was run 110 times
    and the first 10 results discarded; the chart shows a CDF of the time taken
    to reproduce in the remaining 100 runs.  The grey region gives a 90\%
    DKWM confidence interval.}
  \label{fig:eval:indexed_toctou:no_scs}
\end{sanefig}

The importance of side-condition checking depends on the probability
of satisfying the condition, and hence, for the \bugname{toctou} test,
on \texttt{NR\_PTRS}.  \autoref{fig:eval:indexed_toctou:nr_ptrs} shows
this dependency.  Reproduction times rise as \texttt{NR\_PTRS},
whether an enforcer is used or not, but do so far more rapidly without
one, indicating that {\technique} enforcers become relatively more
effective as the probability of a side condition passing falls.  It is
also worth noting that the behaviour with an enforcer is qualitatively
simpler, with smaller inter-quartile ranges, means generally near to
the medians, and a generally smoother shape (the dips at
\texttt{NR\_PTRS} = 400 and \texttt{NR\_PTRS} = 200, for instance, are
much less pronounced when using an enforcer).  It seems likely that a
programmer tasked with fixing this bug would find the behaviour
illustrated in the second chart easier to understand than that in the
first.

\begin{sanefig}
  \subfigure[][Without enforcer]{ \biggraph{eval/artificial_bugs/special/indexed_toctou_vary_nr_ptrs_no_enforcer.tex} }
  \subfigure[][With enforcer]{ \biggraph{eval/artificial_bugs/special/indexed_toctou_vary_nr_ptrs_enforcer.tex} }
  \caption{Reproduction times with and without an enforcer loaded, for
    varying values of \texttt{NR\_PTRS}.  Note the log scales.  Each
    abscissa was sampled 110 times, discarding the first ten results
    and with the order of tests randomised.  Boxes show interquartile
    range and median with 90\% confidence interval for quantiles in
    grey.  Cross and bars give arithmetic mean and 90\% confidence
    interval for mean.  Confidence intervals computed by a bootstrap
    with 1000 replicates.}
  \label{fig:eval:indexed_toctou:nr_ptrs}
\end{sanefig}

\subsection{Interaction with the program's existing synchronisation}

\todo{Not convinced this belongs here.}

\begin{sanefig}
  \subfigure[][\RaggedRight Crashing thread with {\technique}-visible\\synchronisation]{
    \begin{minipage}{5.1cm}
      \begin{literalC}
        while (1) \clbrace
          analysis\_window \clbrace
            lock(); \\
            if (ptr != 0) \clbrace
              *ptr = 5;
            \crbrace \\
            unlock();
          \crbrace
        \crbrace
      \end{literalC}
    \end{minipage}
    \label{fig:eval:existing_sync:visible}
  }
  \subfigure[][\RaggedRight Crashing thread with {\technique}-invisible\\synchronisation]{
    \begin{minipage}{5.1cm}
      \begin{literalC}
        while (1) \clbrace
          lock();\\
          analysis\_window \clbrace
            if (ptr != 0) \clbrace
              *ptr = 5;
            \crbrace
          \crbrace \\
          unlock();
        \crbrace
      \end{literalC}
    \end{minipage}
    \label{fig:eval:existing_sync:invisible}
  }
  \subfigure[][Interfering thread]{
    \begin{minipage}{3cm}
      \begin{literalC}
        while (1) \clbrace
          ptr = \&t;\\
          analysis\_window \clbrace
            lock();\\
            ptr = 0;\\
            unlock();
          \crbrace
        \crbrace
        \\
      \end{literalC}
    \end{minipage}
    \label{fig:eval:existing_sync:interfering}
  }
  \vspace{-12pt}
  \caption{A correctly synchronised program.  \texttt{lock()} and
    \texttt{unlock()} acquire and release a global lock,
    respectively.}
  \label{fig:eval:existing_sync}
\end{sanefig}

\noindent
This section briefly explores the effects of any existing
synchronisation on {\technique}'s behaviour, using the test program
shown in \autoref{fig:eval:existing_sync}.  In this (correctly
synchronised) program, the interfering thread modifies a global
variable while the two crashing threads simultaneously make use of it.
The crashing threads differ only in the placement of the
synchronisation operations: the first, in
\autoref{fig:eval:existing_sync:visible}, places the synchronisation
within the \gls{analysiswindow}, making it visible to the {\technique}
analysis, whereas the second, in
\autoref{fig:eval:existing_sync:invisible}, moves it outside of the
window, so {\technique} will be unaware of it.

As expected, {\technique} produces a \gls{verificationcondition}, and
hence a \gls{bugenforcer}, for the second thread but not for the
first.  When loaded into the program, this enforcer attempts to
enforce a happens-before graph which contradicts the program's
existing synchronisation and therefore deadlocks.  This causes the
enforcer's message operations to time out, and so the enforcer exits
and allows the program to run normally (beyond suffering reduced
performance).

The \gls{verificationcondition} can also be converted to a ``fix''.
This fix does not fix any actual bugs, as there are none, but does not
otherwise harm the program's execution, beyond a slight loss of
performance.

\subsection{Effect of {\StateMachine} simplification}

{\Technique} applies various simplifications to {\StateMachines}
before attempting to symbolically execute them, and, as previously
indicated, these simplifications often account for a significant
proportion of the total analysis time.  {\Technique} is nevertheless
faster because of them, as the cost of the simplification is
outweighed by the reduction in the cost of the symbolic execution
steps.  To quantify this, I re-ran the experiments of
\autoref{sect:eval:how_does_it_work} with {\StateMachine}
simplification disabled; the results are shown in
\autoref{tab:eval:why:effects_of_simplification}.  As expected, the
simplifiers reduce the total time taken by the analysis and the number
of failures experienced.  Perhaps surprisingly, they also increased
the number of \glspl{verificationcondition} generated.  This is due to
a survival effect: disabling the simplifiers excludes the most complex
{\StateMachines}, as those tend to fail without simplification, and
those are generally the most likely to generate
\glspl{verificationcondition}.  All of the additional
\glspl{verificationcondition} observed with simplification enabled
corresponded to cases which simply failed with simplification
disabled.

\begin{sanetab}
  \begin{tabbular}{|l|l|l|}
    \hline
    & \multicolumn{2}{c|}{{\STateMachine} simplification} \\
    \cline{2-3}
    & Enabled & Disabled \\
    \hline
    Mean time to process crashing instruction                            & $[5.5, 10]_{1000}^{10000}$     & $[26, 38]_{1000}^{1000}$\\
    {\ldots} excluding per-\gls{interferingthread} work*                 & $[0.83, 1.02]_{1000}^{9993}$   & $[2.4, 2.9]_{1000}^{9963}$\\
    \Glspl{verificationcondition} per crashing instruction*              & $[0.38, 0.40]_{1000}^{9993}$   & $[0.25, 0.28]_{1000}^{9963}$\\
    Interfering \glspl{cfg} per crashing instruction                     & $[2.75, 2.76]_{1000}^{9993}$   & $[5.25, 5.27]_{1000}^{9963}$\\
    Failures per crashing instruction (\%)                               & $[0.04, 0.12]_{\infty}^{10000}$ & $[0.28, 0.47]_{\infty}^{10000}$\\
    Mean time to process interfering \gls{cfg}$\dagger$                  & $[0.46, 0.60]_{1000}^{27339}$  & $[1.80, 1.99]_{1000}^{51694}$\\
    \Glspl{verificationcondition} per interfering \gls{cfg}(\%)$\dagger$ & $[13.8, 14.5]_{\infty}^{27339}$ & $[4.96,5.28]_{\infty}^{51694}$\\
    Failures per interfering \gls{cfg} (\%) *                            & $[0.63, 0.79]_{\infty}^{27535}$ & $[1.3,1.5]_{\infty}^{52422}$\\
    \hline
  \end{tabbular}
  \caption{Effect of {\StateMachine} simplification on analysis
    effectiveness. All times in seconds. *: Excluding failures in the
    per-crashing instruction phase. $\dagger$: Excluding failures in
    either phase.  Note that the data for the simplification-enabled
    case was taken from the experiments reported in
    \autoref{sect:eval:how_does_it_work}, rather than being
    re-collected for this table. }
  \label{tab:eval:why:effects_of_simplification}
\end{sanetab}

\subsection{Effect of the \glsentrytext{w-isolation} assumption}
\label{sect:eval:w_isolation}

{\Technique} can optionally make use of the \gls{w-isolation}
assumption to constrain the aliasing problem, which can sometimes
usefully improve analysis performance at the expense of discovering a
smaller class of bugs.  I evaluated the impact of this assumption by
repeating the experiments of \autoref{sect:eval:how_does_it_work} with
\gls{w-isolation} disabled.  The results are shown in
\autoref{tab:eval:why:w_isolation}.  These are broadly as expected:
the \gls{w-isolation} assumption causes the analysis to complete
slightly more quickly, with a slight reduction in the number of
failures, and causes {\technique} to generate a slightly smaller set
of \glspl{verificationcondition}.  In this instance, all of the
eliminated \glspl{verificationcondition} were false
positives\footnote{To confirm this, I converted them all into
  \glspl{bugenforcer} and applied them all to the
  \texttt{rpl\_change\_master} test, in the style of
  \autoref{sect:how:finding_unknown}; none were able to reproduce the
  hypothesised bugs.}\!\!, and so this is a very reasonable trade-off.

\begin{sanetab}
  \begin{tabbular}{|l|l|l|}
    \hline
    & \multicolumn{2}{c|}{\Gls{w-isolation} assumption} \\
    \cline{2-3}
    & Enabled & Disabled \\
    \hline
    Mean time to process crashing instruction                            & $[5.5, 10]_{1000}^{10000}$      & $[9.2, 15]_{1000}^{10000}$ \\
    {\ldots} excluding per-\gls{interferingthread} work*                 & $[0.83, 1.02]_{1000}^{9993}$    & $[1.1, 1.4]_{1000}^{9994}$\\
    \Glspl{verificationcondition} per crashing instruction*              & $[0.38, 0.40]_{1000}^{9993}$    & $[0.40, 0.42]_{1000}^{9994}$\\
    Interfering \glspl{cfg} per crashing instruction                     & $[2.75, 2.76]_{1000}^{9993}$  & $[3.26,3.26]_{1000}^{9994}$ \\
    Failures per crashing instruction (\%)                               & $[0.04, 0.12]_{\infty}^{10000}$  & $[0.03, 0.10]_{\infty}^{1000}$\\
    Mean time to process interfering \gls{cfg}$\dagger$                  & $[0.46, 0.60]_{1000}^{27339}$   & $[0.76, 0.91]_{1000}^{32275}$\\
    \Glspl{verificationcondition} per interfering \gls{cfg}(\%)$\dagger$ & $[13.8, 14.5]_{\infty}^{27339}$  & $[12.3,12.9]_{\infty}^{32275}$\\
    Failures per interfering \gls{cfg} (\%) *                            & $[0.63, 0.79]_{\infty}^{27535}$  & $[0.82,0.99]_{\infty}^{32569}$\\
    \hline
  \end{tabbular}
  \caption{Effect the \gls{w-isolation} assumption on analysis
    effectiveness. All times in seconds.  *: Excluding failures in the
    per-crashing instruction phase. $\dagger$: Excluding failures in
    either phase.}
  \label{tab:eval:why:w_isolation}
\end{sanetab}

\subsection{Effect of the \glsentrytext{programmodel}}

{\Technique} uses an \gls{programmodel} to capture certain interesting
parts of the program's behaviour beyond the \gls{analysiswindow}, and
this information is used in a number of places throughout the
analysis.  Some of these uses, such as the use of the dynamic aliasing
model to derive $\beta$ and $c2i$ when building the interfering
\glspl{cfg}, are essential to the approach, and without them no
progress can be made at all; others, such as the use of hints from the
aliasing model during symbolic execution, are optional, and can be
disabled to produce an analysis which is less effective but still
produces some results.  To quantify these effects, I re-analysed the
instructions chosen in \autoref{sect:eval:how_does_it_work} with
{\implementation} configured to make minimal use of either the static
or dynamic parts of the \gls{programmodel}.  The results are shown in
\autoref{tab:eval:why:program_model}.

\begin{sanetab}
  \newcommand{\HangingRaggedRight}{\RaggedRight \leftskip 2em \parindent -2.2em }
  \begin{tabbular}{|>{\HangingRaggedRight} p{6.2cm}| >{\RaggedRight \hspace{-1mm}}p{2.55cm}| >{\RaggedRight}p{2.6cm} | >{\RaggedRight}p{2.6cm}|}
    \hline
    & Full model & Dynamic disabled & Static disabled \\
    \hline
    Mean time to process crashing instruction                            & $[5.5, 10]_{1000}^{10000}$     & & \\
    {\ldots} excluding per-\gls{interferingthread} work*                 & $[0.83, 1.02]_{1000}^{9993}$   & & \\
    \Glspl{verificationcondition} per crashing instruction*              & $[0.38, 0.40]_{1000}^{9993}$   & & \\
    Mean interfering \glspl{cfg} per crashing instruction                & $[2.75, 2.76]_{1000}^{9993}$   & & \\
    Failures per crashing instruction(\%)                                & $[0.04, 0.12]_{\infty}^{10000}$ & & \\
    Mean time to process interfering \gls{cfg}$\dagger$                  & $[0.46, 0.60]_{1000}^{27339}$  & & \\
    \Glspl{verificationcondition} per interfering \gls{cfg}(\%)$\dagger$ & $[13.8, 14.5]_{\infty}^{27339}$ & & \\
    Failures per interfering \gls{cfg} (\%)*                             & $[0.63, 0.79]_{\infty}^{27535}$ & & \\
    \hline
  \end{tabbular}
  \caption{Effect the \gls{programmodel} assumption on analysis
    effectiveness. For the dynamic disabled column, {\implementation}
    was configured to only use information from the dynamic alias
    analysis when deriving $\beta$ and $i2c$; for the static disabled
    one, it was configured to only use information from the static
    analysis when deriving the static crashing \gls{cfg}.  *:
    Excluding failures in the per-crashing instruction
    phase. $\dagger$: Excluding failures in either phase.  \todo{Need
      data}}
  \label{tab:eval:why:program_model}
\end{sanetab}

These results suggest that the hints from the static analysis are
useful but not critical, giving modest reductions in the analysis
time, in the failure rate, and in the number of
\glspl{verificationcondition} generated.  {\Technique} remains useful,
albeit slower and less effective, when the non-essential information
collected by the static analysis is ignored.

The results when disabling hints from the dynamic analysis are far
more dramatic.  The analysis time and failure rate rise to the point
where {\technique} is effectively useless.  The number of
\glspl{verificationcondition} generated falls, though, due to a
survivor effect: only the very simplest {\StateMachines} can be
symbolically executed without aliasing information from the dynamic
analysis, and these are generally the least likely to generate
\glspl{verificationcondition}.  All of the additional
\glspl{verificationcondition} generated when the dynamic analysis is
enabled correspond to cases where the analysis simply fails when it is
disabled.

\subsection{Sources of fix overhead}
\label{sect:eval:why:fix_overhead}

\todo{Ugly writing.} As previously discussed, {\technique}-generated
fixes generally have low overheads, usually on the order of a few
microseconds per critical section.  This section gives a more detailed
break-down of the sources of that overhead by applying a variety of
fixes and partial fixes to a simple test program and comparing their
performance.  The test program, \bugname{nobug}, is shown in
\autoref{fig:eval:why:nobug}.  {\Technique} correctly identifies that
the program might suffer an atomicity violation crash if
\texttt{global} is ever 2, but, lacking a global model of the
program's structure, is unable to show that that is impossible, and so
generates a \gls{verificationcondition} and ``fix'' for this program.
Since this bug is a false positive, the fix has no effect on the
program's behaviour, beyond introducing a modest amount of additional
overhead.  

\begin{sanefig}
  {\hfill}
  \subfigure[][\Gls{crashingthread}]{
    \begin{minipage}{1cm}
      \begin{literalC}
        while (1) \clbrace
          analysis\_window \clbrace
            x$_0$ = global;\\
            x$_1$ = global;\\
            assert(x$_0$ + x$_1$ != 3);
          \crbrace
        \crbrace
      \end{literalC}
    \end{minipage}
  }
  {\hfill}
  \subfigure[][\Gls{interferingthread}]{
    \begin{minipage}{1cm}
      \begin{literalC}
        \\
        while (1) \clbrace
          analysis\_window \clbrace
            global = 1;
          \crbrace
        \crbrace
        \\
      \end{literalC}
    \end{minipage}
  }
  {\hfill}
  \caption{The {\!\rm \bugname{nobug}\!} test program.}
  \label{fig:eval:why:nobug}
\end{sanefig}

\begin{sanetab}
  \begin{tabbular}{|l|l|l|l|l|}
    \hline
                                       & \multicolumn{2}{c|}{Thread iteration time} & \multicolumn{2}{c|}{Thread overhead} \\
    \cline{2-5}
    Type of fix                        & Crashing & Interfering & Crashing & Interfering \\
    \hline
    \textit{None}                      & & & & \\
    \textit{Gain control only}         & & & & \\
    \textit{No synchronisation}        & & & & \\
    \textit{Synchronise only crashing} & & & & \\
    \textit{Normal}                    & & & & \\
    \hdashline
    \textit{Debug registers}           & & & & \\
    \hline
  \end{tabbular}
  \caption{Number of loop iterations completed by {\!\rm
      \bugname{nobug}\!} per second with a selection of different
    partial fixes applied.  See text for descriptions of the type of
    fix. \todo{Need data} }
  \label{tab:eval:why:nobugperf}
\end{sanetab}

\autoref{tab:eval:why:nobugperf} evaluates these overheads, for
several variants of the fix:
\begin{itemize}
\item \textit{None} --- No fix is applied at all.
\item \textit{Gain control only} --- The fix is generated by the usual
  algorithm, except that the $\mathit{newNode}$ function in
  \autoref{fig:fix:graph_grammar} is replaced with the constant
  $\varnothing$.  The resulting fix will gain control of the program
  in the usual way but will return control as soon as the program
  leaves the $\mathit{Cont}$ set.  This configuration measures the
  overheads introduced by simply gaining control of the program at the
  necessary points.
\item \textit{No synchronisation} --- The fix is generated by the
  usual algorithm, except that the ``Acquire lock'' and ``Release
  lock'' sequences in \autoref{fig:fix:graph_grammar} are replaced
  with no-ops.  The resulting patch will gain control of the program
  in the usual way, and will retain control for as long as a full
  patch will, but will never perform any synchronisation operations.
  This configuration measures the overheads introduced by duplicating
  and rearranging the program code in the critical sections.
\item \textit{Synchronise only crashing} --- This fix omits the
  \gls{interferingthread} synchronisation operations from the patch
  but retains the \gls{crashingthread} ones, and so makes it possible
  to evaluate the overhead of synchronisation operations in the
  absence of any contention.
\item \textit{Normal} --- A complete fix is generated, using the
  complete algorithms from \autoref{sect:enforce:gain_control} and
  \autoref{fig:fix:graph_grammar}.
\item \textit{Debug registers} --- A complete fix is generated, except
  that rather than gaining control using the patch strategy algorithm
  in \autoref{sect:enforce:gain_control}, it gains control using the
  processor's debug registers.
\end{itemize}
\todo{Need more once I have data.} These results show that the
synchronisation operations themselves are the most expensive part of
the generated fixes.  This is reassuring, and suggests that the
patching mechanism used by {\technique} is close to the optimal way of
introducing these synchronisation operations into this program.  As
expected, the fix which used debug registers was far slower than the
one which used the patch strategy mechanism.

\section{When does it work?}
\label{sect:eval:does_it_scale}

Previous sections have investigated whether {\technique} works, how it
works, and why it works.  This section builds upon these by looking at
how {\technique}'s behaviour depends on the complexity of the bug to
be investigated, quantifying its scalability, and hence places some
constraints on the situations in which {\technique} is likely to
behave well.

\subsection{Scalability to complex happens-before graphs}
\label{sect:eval:complex_hb}

\begin{sanefig}
  {\hfill}
  \subfigure[][Crashing thread]{
    \texttt{
      \begin{tabular}{lll}
        \multicolumn{3}{l}{while (1) \{} \\
        & \multicolumn{2}{l}{analysis\_window \{} \\
        & & $\texttt{x}_1$ = global;\\
        & & $\texttt{x}_2$ = global;\\
        & & $\vdots$ \\
        & & $\texttt{x}_N$ = global;\\
        & & \hspace{-2mm}\begin{tabular}{ll}
          assert(!(&\hspace{-2.5mm}$\texttt{x}_1$ == 1 \&\& \\
          &\hspace{-2.5mm}$\texttt{x}_2$ == 2 \&\& \\
          &$\vdots$ \\
          &\hspace{-2.5mm}$\texttt{x}_N$ == N)); \\
        \end{tabular}\\
        & \multicolumn{2}{l}{\}} \\
        \multicolumn{3}{l}{\}} \\
      \end{tabular}
    }
  }
  {\hfill}
  \subfigure[][Interfering thread]{
    \texttt{
      \begin{tabular}{lll}
        \\
        \\
        \multicolumn{3}{l}{while (1) \{} \\
        & \multicolumn{2}{l}{analysis\_window \{} \\
        & & global = 1;\\
        & & global = 2;\\
        & & $\vdots$ \\
        & & global = N;\\
        & \multicolumn{2}{l}{\}} \\
        \multicolumn{3}{l}{\}} \\
        \\
        \\
      \end{tabular}
    }
  }
  {\hfill}
  \caption{The \bugname{complex\_hb}$_{N}$ test.  This bug will only
    be triggered if $2N-1$ happens-before edges are all correctly
    enforced.}
  \label{fig:eval:why:complex_hb}
\end{sanefig}

\noindent
This section explores {\technique}'s behaviour as the complexity of
the happens-before graph increases, using the test program used is
shown in \autoref{fig:eval:why:complex_hb}.  The two threads each
consist of a series of $N$ memory accesses arranged such that the
program crashes if it alternates accesses between the two threads.
The happens-before graph for this bug therefore contains $2N$ edges.

\begin{sanefig}
  \todo{Regenerate with more replicates.}
  \biggraph{eval/complex_hb/complex_hb_build_summaries}
  \caption{Time taken to analyse the \bugname{complex\_hb}$_N$ test,
    for varying values of $N$.  Note log scale.  Each abscissae was
    sampled eleven times, discarding the first, in random order.
    Crosses and bars give the mean and 90\% confidence interval of the
    mean, calculated using the central limit theorem.  The solid line
    shows a regression onto ${\alpha}e^{{\beta}N} + \gamma$ over $7
    \leq N \leq 20$ extrapolated to the full range of $N$; the dashed
    one shows a quartic regression over the same data.  Grey regions
    give 90\% confidence intervals for the regression lines, computed
    using a 1,000 replicate bootstrap.  Note that the regressions
    minimise the sum of squares loss, but are plotted on a logarithmic
    scale.}
  \label{fig:eval:complex_hb:analysis_time}
\end{sanefig}

\autoref{fig:eval:complex_hb:analysis_time} shows how the time taken
when generating \glspl{verificationcondition} varies with
$N$\footnote{Memory consumption on this test was 4MiB on the smallest
  test and 8MiB on the largest one, but these numbers are more
  functions of implementation details of {\implementation} than
  meaningful properties of {\technique}.}\!\!\!.  ~The time taken clearly
increases rapidly with $N$, and this will limit the complexity of bugs
which can be analysed with {\technique}.  This is not, however, likely
to be the most important limitation to {\technique}'s scalability:
most bugs in real programs require only two or three edges to be
enforced\cite{Musuvathi2008}, and {\technique} was able to analyse a
79-edge one in under ten minutes.

\todo{Not sure this adds all that much.} It is perhaps interesting to
note that, although very rapid, the rate of increase is less than
exponential.  The solid line in the figure shows the least-squares
exponential regression on the data for $7 \leq N \leq 20$\footnote{The
  results reported appear to be robust to small changes in the
  boundaries of this region.}, extrapolated over the complete range of
$N$.  It significantly over-estimates the rate at which the time taken
increases.  A quartic regression over the same data, shown as a dotted
line in the figure, gives a much closer fit in the extrapolated
region.  This is because, in this particular test, the {\StateMachine}
simplification step is able to make quite dramatic simplifications to
the structure of the {\StateMachines}, and so there is no need to ever
consider all $2^N$ interleavings of the memory accesses.

\todo{Also put in some numbers on how effective the enforcers are.
  The answer is that they're very effective, and how effective they
  are is basically independent of $N$, but I should probably say that.}

\subsection{Scalability with respect to memory access complexity}

\begin{sanefig}
  {\hfill} \subfigure[][Crashing thread]{ \texttt{
    \begin{tabular}{ll}
      \multicolumn{2}{l}{$\texttt{s}_1$ = random() \% NR\_PTRS;}\\
      \multicolumn{2}{l}{$\texttt{s}_2$ = random() \% NR\_PTRS;}\\
      \multicolumn{2}{l}{\vdots}\\
      \multicolumn{2}{l}{$\texttt{s}_S$ = random() \% NR\_PTRS;}\\
      \multicolumn{2}{l}{$\texttt{l}_1$ = random() \% NR\_PTRS;}\\
      \multicolumn{2}{l}{$\texttt{l}_2$ = random() \% NR\_PTRS;}\\
      \multicolumn{2}{l}{\vdots}\\
      \multicolumn{2}{l}{$\texttt{l}_L$ = random() \% NR\_PTRS;}\\
      \multicolumn{2}{l}{analysis\_window \{}\\
      &$\texttt{slots}[\texttt{s}_1]$ = 1;\\
      &$\texttt{slots}[\texttt{s}_2]$ = 2;\\
      &\vdots\\
      &$\texttt{slots}[\texttt{s}_S]$ = $S$;\\
      &\hspace{-2.3mm}\begin{tabular}{lll}
         assert(~(&\hspace{-2.5mm}$\texttt{slots}[\texttt{l}_1]$ &\hspace{-3mm} + \\
         &\hspace{-2.5mm}$\texttt{slots}[\texttt{l}_2]$ &\hspace{-3mm} + \\
         & \vdots \\
         &\hspace{-2.5mm}$\texttt{slots}[\texttt{l}_L]$ &\hspace{-4.5mm} ) \\
         &\multicolumn{2}{l}{\hspace{1em}!= $L.(S+1) + 1$);}\\
       \end{tabular}\\
      \multicolumn{2}{l}{\}}
    \end{tabular}
    }
  }
  {\hfill}
  \raisebox{-6pt}{
  \subfigure[][Interfering thread]{
    \texttt{
      \begin{tabular}{ll}
        \\
        \\
        \\
        \\
        \\
        \\
        \\
        \multicolumn{2}{l}{idx = random() \% NR\_PTRS;}\\
        \multicolumn{2}{l}{analysis\_window \{} \\
        & slots[idx] = S+1; \\
        \multicolumn{2}{l}{\}}\\
        \\
        \\
        \\
        \\
        \\
        \\
        \\
        \\
      \end{tabular}
    }
  }
  }
  {\hfill}
  \caption{The \bugname{complex\_alias}$_{L,S}$ test.
    \texttt{NR\_PTRS} is the constant 100.}
  \label{fig:eval:why:complex_aliasing}
\end{sanefig}

\begin{sanefig}
  \biggraph{eval/complex_alias/hard}
  \caption{Memory and time used to analyse the
    \bugname{complex\_alias}$_{L,S}$ test.  Each configuration was run
    eleven times, in random order, with the first, highest, and lowest
    values discarded.  Lines show contours of the average of the
    remaining eight values; grey regions show the range.
    Configurations which timed out are shown with a cross; those which
    ran out of memory are shown with a circle.  Configurations which
    timed out on some repeats and ran out of memory on others are
    shown with both.  For the purposes of drawing the contours,
    experiments which failed were treated as if they had completed
    precisely at the timeout and used precisely the maximum memory;
    cells in which I made that assumption are shown in red.  Note that
    the {\implementation} was configured to only run if the heap size
    exceeded 2GB.}
  \label{fig:eval:why:complex_aliasing:result1}
\end{sanefig}

\noindent
The previous section showed that {\technique} scales well to
complicated happens-before graphs; this one investigates how well it
scales to complicated memory access patterns.  This first test program
used is shown in \autoref{fig:eval:why:complex_aliasing}.  The
\gls{crashingthread} \gls{analysiswindow} consists of $S$ stores and
$L$ loads, with all of the addresses unpredictable, followed by a
final test on the sum of the loaded values.  This test always fails,
and so the program never crashes, but {\technique} is unable to prove
that without considering every possible way of evaluating the
condition.

\autoref{fig:eval:why:complex_aliasing:result1} shows the cost of
analysing this program, in terms of time taken and memory consumed, as
functions of $L$ and $S$.  Both functions clearly increase rapidly
with both $L$ and $S$, with a much stronger response to $L$ than to
$S$.  This reflects the fact that {\technique} effectively solves this
aliasing problem by brute force, considering each combination of $S+1$
values of the $L$ loads for a total of $(S+1)^L$ aliasing patterns.
This is a rapidly growing function of both $L$ and $S$, and, for the
relevant values of its inputs, grows more rapidly with $L$ than $S$,
conveniently explaining the graph's most obvious qualitative
features\footnote{This model is, however, a poor quantitative fit for
  the data, as the cost of analysing each aliasing pattern is also a
  function of $L$ and $S$.}\!\!.

\begin{sanefig}
  {\hfill}
  \subfigure[][Crashing thread]{
    \texttt{
    \begin{tabular}{ll}
      \multicolumn{2}{l}{$\texttt{s}_1$ = random() \% NR\_PTRS;}\\
      \multicolumn{2}{l}{$\texttt{s}_2$ = random() \% NR\_PTRS;}\\
      \multicolumn{2}{l}{\vdots}\\
      \multicolumn{2}{l}{$\texttt{s}_S$ = random() \% NR\_PTRS;}\\
      \multicolumn{2}{l}{$\texttt{l}_1$ = random() \% NR\_PTRS;}\\
      \multicolumn{2}{l}{$\texttt{l}_2$ = random() \% NR\_PTRS;}\\
      \multicolumn{2}{l}{\vdots}\\
      \multicolumn{2}{l}{$\texttt{l}_L$ = random() \% NR\_PTRS;}\\
      \multicolumn{2}{l}{analysis\_window \{}\\
      &$\texttt{slots}[\texttt{s}_1]$ = 1;\\
      &$\texttt{slots}[\texttt{s}_2]$ = 2;\\
      &\vdots\\
      &$\texttt{slots}[\texttt{s}_S]$ = $S$;\\
      &\hspace{-2.3mm}\begin{tabular}{lll}
         assert(&\hspace{-2.5mm}$\texttt{slots}[\texttt{l}_1]$ &\hspace{-3mm} != $S+1$ \&\& \\
         &\hspace{-2.5mm}$\texttt{slots}[\texttt{l}_2]$ &\hspace{-3mm} != $S+1$ \&\& \\
         & \vdots \\
         &\hspace{-2.5mm}$\texttt{slots}[\texttt{l}_L]$ &\hspace{-3mm} != $S+1$);\\
       \end{tabular}\\
      \multicolumn{2}{l}{\}}
    \end{tabular}
    }
  }
  {\hfill}
  \raisebox{-6pt}{
  \subfigure[][Interfering thread]{
    \texttt{
      \begin{tabular}{ll}
        \\
        \\
        \\
        \\
        \\
        \\
        \\
        \multicolumn{2}{l}{idx = random() \% NR\_PTRS;}\\
        \multicolumn{2}{l}{analysis\_window \{} \\
        & slots[idx] = 0; \\
        \multicolumn{2}{l}{\}}\\
        \\
        \\
        \\
        \\
        \\
        \\
        \\
      \end{tabular}
    }
  }
  }
  {\hfill}
  \caption{The \bugname{complex\_alias\_easy}$_{L,S}$ test.
    \texttt{NR\_PTRS} is the constant 100.}
  \label{fig:eval:why:complex_aliasing:easy}
\end{sanefig}

\begin{sanefig}
  \biggraph{eval/complex_alias/easy}
  \caption{Memory and time used to analyse the
    \bugname{complex\_alias\_easy}$_{L,S}$ test, in the same style as
    \autoref{fig:eval:why:complex_aliasing:result1}.}
  \label{fig:eval:why:complex_aliasing:result2}
\end{sanefig}

\autoref{fig:eval:why:complex_aliasing:easy} shows another variant of
this test program.  This version breaks the final test into $L$
independent predicates each on a single loaded value, as opposed to
the previous test's single predicate over $L$ values.  {\Technique}'s
lazy aliasing resolution (see \autoref{sect:derive:symbolic_execute})
naturally factorises the resulting aliasing problem into $L$
single-load ones, rather than the previous test program's single
$L$-load one, and so {\technique} now need only consider $(S+1).L$
aliasing configurations where it had previously to consider $(S+1)^L$.

The cost of doing so is shown in
\autoref{fig:eval:why:complex_aliasing:result2}.  As expected,
        {\technique} is able to analyse this variant of the test far
        more quickly and with far less memory, allowing it to scale to
        far larger values of $L$\footnote{The largest successful value
          of $S$ is unchanged, except for different quantisations, as
          it is in both experiments achieved when $L=1$ and $(S+1)^1 =
          (S+1).1$.}.  This behaviour is clearly more useful than
        always exhibiting the prior, poor, performance, but is also
        difficult to characterise crisply: sometimes {\technique} will
        struggle with bugs which depend on even a dozen memory loads;
        at other times, it will be able to process hundred-load bugs
        with little difficulty.  \todo{Need something more here.}

\subsection{Scalability with respect to \gls{alpha}}

\todo{Not brilliantly written, it has to be said.}

\biggraph{eval/alpha/alpha.ttex}

\noindent
Previous sections have investigated scalability with respect to some
measures of the complexity of the \gls{analysiswindow} using
artificial test programs.  This section investigates scalability with
respect to the raw size of the \gls{analysiswindow} using real
programs.  To do so, I selected 1000 instructions at random from MySQL
and analysed each at varying values of \gls{alpha}, recording the time
taken by the various analysis phases.  The results are shown in
\autoref{fig:eval:alpha}.

The first chart, \autoref{fig:eval:alpha:time_per_crashing}, shows how
long each potentially-crashing instruction spends in the initial,
per-crashing instruction, phase of the analysis, excluding failures,
and how that varies with \gls{alpha}.  The probability density
functions were estimated in the same way as those shown in
\autoref{fig:eval:how:per_crashing_times}, except that a censoring
correction was applied near the 300 second timeout, and, as usual, the
grey region gives a 90\% confidence interval computed with a 1000
replicate bootstrap.  The chart also shows the proportion of
instructions which failed in this stage.  The second chart,
\autoref{fig:eval:alpha:time_per_interfering}, shows the time which
each interfering \gls{cfg} requires in the per-interfering \gls{cfg}
phase in the same style.

The overall pattern in these charts is broadly as expected: the time
taken increases rapidly with \gls{alpha}, leading to an unpleasant
increase in the failure rate.  These results suggest that values of
\gls{alpha} above about 50 are unlikely to be practical with this
combination of hardware and program to be analysed.

The third chart, \autoref{fig:eval:alpha:interfering_per_crashing},
shows the number of interfering \glspl{cfg} generated for each
potentially-crashing instruction.  As can be see, this rises rapidly
with increasing values of \gls{alpha} until \gls{alpha} reaches 30, at
which point it begins to fall again.  The initial rise is easily
explained, and simply reflects the fact that with more instructions
there is more scope for the \gls{crashingthread} to race.  The fall at
higher values of \gls{alpha} is a survivor effect caused by failures
in the per-crashing instruction phase of the analysis.  The more
memory accesses a crashing {\StateMachine} has, the more interfering
\glspl{cfg} it will generate, but the more likely it is to fail, and
beyond $\gls{alpha}=30$ the increased failure rate outweighs the
increased number of interfering \glspl{cfg}.

The final chart, \autoref{fig:eval:alpha:vcs_per_interfering}, shows
the proportion of interfering \glspl{cfg} which generate
\glspl{verificationcondition} requiring run-time validation.  It shows
a similar pattern to the number of interfering \glspl{cfg} per
crashing instruction: an initial rise, reflecting an increase in the
complexity of the {\StateMachines}, followed by a fall for higher
values of \gls{alpha} as survivor effects begin to dominate.

The configuration used for this experiment was slightly different from
that used for most of the other experiments:
\begin{itemize}
\item The machine used to run this experiment was a 1.9GHz Opteron
  6168 with 16GiB of memory.
\item {\Implementation} was initially configured to analyse ten
  potentially-crashing instructions in parallel, whereas the previous
  experiments analysed one at a time.  Any instructions which suffered
  an out-of-memory error when run in parallel were re-run in series
  after the experiment completed; an operation was only treated as
  running out of memory if it failed on this final run.  Timed-out
  phases of the analysis were not re-run.
\end{itemize}
The results of this experiment are therefore not directly comparable
with the results of the other experiments.

\section{Discussion}

This evaluation has demonstrated several important properties of
{\technique}:
\begin{itemize}
\item It is able to quickly reproduce and fix bugs in both artificial
  and real test programs.  The generated fixes themselves have low
  enough overhead to be useful in practice.
\item It is able to find at least some previously-unknown bugs in real
  programs.
\item It exhibits reasonable scalability as the complexity of the
  program to be analysed increases.
\end{itemize}
It therefore satisfies the original design goals discussed in
\autoref{sect:intro:overview}.

The chief weakness of the evaluation is that it considers only a small
number of bugs in real programs, and those bugs were themselves
selected because they interact well with {\technique}.  It is hard to
say how these results would generalise to other programs and bugs.
The problem here is fundamentally that the class of bugs considered by
{\technique} is quite small: not only must the program crash in a
detectable way, but it must do so within a few dozen instructions.
Such bugs are a small subset of the already-small set of all
concurrency bugs, and I have been unable to find enough in real
programs to form the basis of a truly convincing evaluation.

Nevertheless, this evaluation has shown that it is possible to find,
reproduce, and fix concurrency bugs in large-scale multithreaded
software given only the program binary and some minimal information on
its memory allocation pattern, and that the generated fixes are
themselves reasonably efficient.  This represents a useful advance
over the state of the art; previous systems either required far more
information about the program (such as AutoPag\cite{Lin2007} and
ConTest\cite{Krena2007}), or had very high overhead without exotic
hardware (such as Atom-Aid\cite{Lucia2009} or AVIO\cite{Lu}), or
targeted a more restricted class of bugs (such as
Kivati\cite{Chew2010} or ToleRace\cite{Kirovski2007}).  I expand on
these comparisons in the next chapter.
