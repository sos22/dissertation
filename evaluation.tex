\newcommand{\biggraph}[1]{\input{#1}}
%\newcommand{\biggraph}[1]{}

\chapter{Evaluation}
\label{chapter:eval}

\begin{sanefig}
  \begin{tabular}{lp{12.7cm}}
    $x \pm^n_\mu y$ & The mean, $x$, of some distribution and the standard deviation of the mean, $y$, calculated by applying the central limit theorem to $n$ samples of the distribution.\\
    & \\
    $x \pm_\mu y$ & The mean, $x$, of some distribution and the standard deviation of the mean, $y$, calculated from distributions derived elsewhere rather than directly from sampled data.\\
    & \\
    $[x,y]^n_b$ & $[x,y]$ form a 90\% confidence interval for some statistic of a distribution, derived by a bootstrap with $b$ replicates over $n$ samples. \\
    & \\
    $z \in [x,y]^n_\infty$ & $z$ is a maximum likelihood estimator of some statistic of a distribution and $[x,y]$ form a 90\% confidence interval for it, calculated by performing a bootstrap over $n$ samples of the distribution and taking the limit as the number of replicates goes to infinity.\\
    & \\
    $0/n$ & A Bernoulli process was sampled $n$ times and did not succeed. \\
    &\\
    $n/n$ & A Bernoulli process was sampled $n$ times and succeeded every time. \\
  \end{tabular}
  \caption{Summary of statistical notation used in this chapter.}
\end{sanefig}

\noindent
Previous chapters have described {\technique} and how it can, under
appropriate circumstances, automate every stage of the debugging
process, from discovering bugs through characterising and reproducing
them to generating fixes.  This chapter provides an experimental
evaluation of the effectiveness and performance of my implementation,
{\implementation}.  This evaluation will consist of four parts:
\begin{itemize}
\item \autoref{sect:eval:does_it_work} investigates whether
  {\implementation} works at all, looking at the time taken to produce
  \glspl{verificationcondition}, \glspl{bugenforcer}, and fixes; the
  effects of \glspl{bugenforcer} and fixes on the frequency with which
  bugs reproduce; and the effects of the fixes on the program's
  behaviour.
\item \autoref{sect:eval:how_does_it_work} then explores some aspects
  of {\implementation}'s performance in more detail, showing how the
  analysis time breaks down across the various phases.
\item Next, \autoref{sect:eval:why_does_it_work} examines the reasons
  for the properties observed in the previous sections and relates
  them back to the design features of {\technique}.
\item Finally, \autoref{sect:eval:does_it_scale} investigates
  {\implementation}'s scalability with respect to bug complexity, using a
  variety of metrics, so as to determine when it is likely to fail.
\end{itemize}
Unless otherwise stated, all experiments were run on a four-core Intel
Q6600 2.40GHz with 8GiB of memory running Ubuntu Lucid Lynx.  The
\gls{w-isolation} assumption was enabled (see
\autoref{sect:derive:w_isolation}), \gls{alpha} was set to 20, both
analysis timeouts were set to five minutes, and the timeout used by
\glspl{bugenforcer} was randomly uniformly distributed between 100 and
200ms.  The system compiler, used to build the \glspl{bugenforcer} and
fixes, as well as {\implementation} itself, was gcc version 4.4.3.

\section{Does it work?}
\label{sect:eval:does_it_work}

This part of the evaluation aims to determine whether
{\implementation} works at all.  In other words, is it able to
reproduce and fix concurrency bugs?  I investigate this using both
artificial bugs, in \autoref{sect:eval:artificial_bugs}, and some real
bugs taken from large existing pieces of software, in
\autoref{sect:eval:does:real}.

\subsection{Artificial bugs}
\label{sect:eval:artificial_bugs}

\begin{sanefig}
  \begin{tabular}{p{8cm}p{6.5cm}}
    \multicolumn{2}{c}{\texttt{\#define NR\_PTRS 100}}\\
    \subfigure[][\RaggedRight {\rm \bugname{toctou}\!} crashing thread]{
      \begin{minipage}{7.2cm}
        \begin{literalC}
          while (1) \clbrace
            idx = rand() \% NR\_PTRS;\\
            analysis\_window() \clbrace
              if (global\_ptrs[idx] != NULL) \clbrace
                *(global\_ptrs[idx]) = 5;
              \crbrace
            \crbrace
          \crbrace
        \end{literalC}
      \end{minipage}
      \label{fig:eval:artificial_bugs:programs:toctou:crashing}
    }
    &
    \subfigure[][{\rm \bugname{toctou}\!} interfering thread]{
      \begin{minipage}{6.2cm}
        \begin{literalC}
          while (1) \clbrace
            idx = rand() \% NR\_PTRS; \\
            analysis\_window \clbrace
              global\_ptrs[idx] = NULL;
            \crbrace \\
            global\_ptrs[idx] = \&t;
          \crbrace
          \\
        \end{literalC}
      \end{minipage}
      \label{fig:eval:artificial_bugs:programs:toctou:interfering}
    } \\
    \subfigure[][{\rm \bugname{multi\_variable}\!} crashing thread]{
      \begin{minipage}{7.2cm}
        \begin{literalC}
          while (1) \clbrace
            analysis\_window \clbrace
              v1 = global1;\\
              v2 = global2;\\
              assert(v1 == v2);
            \crbrace \\
            sleep(500$\mu$s);
          \crbrace
          \\
        \end{literalC}
      \end{minipage}
      \label{fig:eval:artificial_bugs:programs:multi_variable:crashing}
    }
    &
    \subfigure[][\RaggedRight {\rm \bugname{multi\_variable}\!} interfering thread]{
      \begin{minipage}{6.2cm}
        \begin{literalC}
          while (1) \clbrace
            global1 = 5;\\
            global2 = 5;\\
            sleep(500$\mu$s);\\
            analysis\_window \clbrace
              global1 = 7;\\
              global2 = 7;
            \crbrace
          \crbrace
        \end{literalC}
      \end{minipage}
      \label{fig:eval:artificial_bugs:programs:multi_variable:interfering}
    } \\
    \subfigure[][{\rm \bugname{double\_free}\!} active threads]{
      \begin{minipage}{7.2cm}
        \begin{literalC}
          while (1) \clbrace
            analysis\_window \clbrace
              t = global\_ptr; \\
              if (t != NULL) \clbrace
                free(t);
              \crbrace \\
              global\_ptr = NULL;
            \crbrace \\
            sleep(1ms);
          \crbrace
        \end{literalC}
      \end{minipage}
      \label{fig:eval:artificial_bugs:programs:double_free:active}
    }
    &
    \subfigure[][{\rm \bugname{double\_free}\!} environmental thread]{
      \begin{minipage}{6.2cm}
        \begin{literalC}
          \\
          \\
          while (1) \clbrace
            if (global\_ptr == NULL) \clbrace
              global\_ptr = malloc(64);
            \crbrace
          \crbrace
          \\
          \\
          \\
        \end{literalC}
      \end{minipage}
      \label{fig:eval:artificial_bugs:programs:double_free:environmental}
    }
  \end{tabular}
  \caption{Artificial test programs.  {\tt analysis\_window}\hspace{-1pt} shows
    the extent of the \glsentrytext{analysiswindow}, which was specified
    manually for these tests.  The various delays were chosen so that
    the bug reproduced in a reasonable time when the program was run
    with neither an enforcer nor a fix applied.}
  \label{fig:eval:artificial_bugs:programs}
\end{sanefig}

\noindent
I first consider {\implementation}'s behaviour when applied to bugs in
three artificial test programs, shown in
\autoref{fig:eval:artificial_bugs:programs}.  These programs
illustrate several important features of {\technique}:
\begin{itemize}
  \item The \bugname{toctou} test,
    figures~\ref{fig:eval:artificial_bugs:programs:toctou:crashing}
    and~\ref{fig:eval:artificial_bugs:programs:toctou:interfering},
    investigates {\implementation}'s ability to reproduce data-dependent
    bad pointer dereferencing bugs, and in particular the importance
    of the \gls{side condition} checking mechanism.
  \item The \bugname{multi\_variable} test,
    figures~\ref{fig:eval:artificial_bugs:programs:multi_variable:crashing}
    and~\ref{fig:eval:artificial_bugs:programs:multi_variable:interfering},
    shows a multi-variable atomicity violation.  Some previous
    approaches, such as Kivati~\cite{Chew2010}, were not able to handle
    this kind of bug.
  \item The final test, \bugname{double\_free}, demonstrates
    {\implementation}'s ability to handle double free-type bugs.  It
    consists of three threads: two ``active'' threads, shown in
    \autoref{fig:eval:artificial_bugs:programs:double_free:active},
    and one ``environmental'' one, shown in
    \autoref{fig:eval:artificial_bugs:programs:double_free:environmental}.
    It is possible for both active threads to release the same memory
    allocation, causing a double-free bug.  Note that the crashing and
    interfering {\StateMachines} will both represent the active thread
    and the environmental thread will not be represented by
    {\AStateMachine} at all.
\end{itemize}
These experiments clearly do not cover every possible form of program
behaviour, or even a particularly representative subset of possible
behaviours, but they suffice to demonstrate {\technique}'s basic
functionality.

\subsubsection{Computational costs of building \glsentrytext{verificationcondition}s, \glsentrytext{bugenforcer}s, and fixes}

\autoref{tab:eval:artificial_bugs:analysis_time} shows the time taken
to analyse these bugs and build either \glspl{bugenforcer} or fixes
for them.  As might be expected, these very simple bugs are processed
very quickly, at every stage of the process.  These figures provide a
reasonable lower bound on the time which {\implementation} might take to
analyse a bug; realistic ones would, of course, take much longer.

\begin{sanetab}
  \begin{tabbular}{|p{2.4cm}|p{2.83cm}|p{2.83cm}|p{2.83cm}|p{2.83cm}|}
    \hline
    Test program              & \Gls{programmodel}      & \Gls{verificationcondition} & \Gls{bugenforcer} & Fix \\
    \hline
    \bugname{toctou}          & $0.541 \pm^{10}_\mu 0.018$ & $0.527 \pm^{10}_\mu 0.003$ & $0.206 \pm^{10}_\mu 0.003$ & $0.142 \pm^{10}_\mu 0.001$\\
    \bugname{multi\_variable} & $0.662 \pm^{10}_\mu 0.021$ & $0.370 \pm^{10}_\mu 0.002$ & $0.207 \pm^{10}_\mu 0.002$ & $0.135 \pm^{10}_\mu 0.001$\\
    \bugname{double\_free}    & $0.434 \pm^{10}_\mu 0.017$ & $0.342 \pm^{10}_\mu 0.003$ & $0.199 \pm^{10}_\mu 0.003$ & $0.135 \pm^{10}_\mu 0.001$\\
    \hline
  \end{tabbular}
  \caption{Time taken, in seconds, to build the
    \glsentrytext{programmodel}, \glsentrytext{verificationcondition},
    \glsentrytext{bugenforcer}, and fix for the artificial bugs.  Each
    configuration was run eleven times and the results of the first
    run discarded.}
  \label{tab:eval:artificial_bugs:analysis_time}
\end{sanetab}

\subsubsection{Reproducing the bugs}

\begin{sanefig}
  \biggraph{eval/artificial_bugs/cdf1.tex}
  \caption{CDF of time taken to reproduce the bugs in the artificial
    test programs, with and without \glsentrytext{bugenforcer}s, and
    some summary statistics.  All configurations tested 110 times, in
    random order, with the first ten results discarded and a timeout
    after three minutes.  Note log scale.  All times in seconds.
    Means calculated ignoring timeouts.  Grey region gives a 90\%
    confidence interval, computed using the
    Dvoretsky-Kiefer-Wolfowitz-Massart (DKWM)
    inequality~\cite{Massart1990}.  Note that DKWM confidence
    intervals are curve-wise rather than point-wise i.e. there is a
    90\% confidence that the entire curve is within the shaded region,
    rather than that any given point is.}
  \label{fig:eval:artificial_bugs:cdf1}
\end{sanefig}

\noindent
\autoref{fig:eval:artificial_bugs:cdf1} shows how effective the
\glspl{bugenforcer} generated from these bugs are, giving cumulative
distribution functions (CDFs) of the reproduction times and some
summary statistics.  This figure shows that the enforcers are able to
reduce the mean time taken to reproduce these bugs, often by a large
amount.  They are particularly effective at eliminating outliers in
which the bug takes a very long time to reproduce.  This is a useful
property: with fewer outliers, the behaviour of a bug will be,
qualitatively, more predictable, which is likely to make it easier for
a programmer to understand the bug, even without a reduction in
reproduction time.

\subsubsection{Fixing the bugs}

{\implementation} is able to generate fixes for all three of these
\begin{sanetab}
  \begin{tabbular}{|p{5cm}|p{3cm}|p{3cm}|p{3cm}|}
    \hline
                           & \multicolumn{3}{c|}{Time to run main loop, microseconds} \\
    \cline{2-4}
    Test program           & Unfixed & Fixed & Increase \\
    \hline
    \bugname{toctou}       & & &\\
    \hspace{1em}Crashing thread         & $0.62 \pm_{\mu}^{10} 0.03$   & $0.69 \pm_{\mu}^{10} 0.07$ & $0.07 \pm_\mu 0.08$ \\
    \hspace{1em}Interfering thread      & $0.64 \pm_{\mu}^{10} 0.06$   & $0.84 \pm_{\mu}^{10} 0.06$ & $0.20 \pm_\mu 0.08$ \\
    \hline
    \bugname{multi\_variable} & & &\\
    \hspace{1em}Crashing thread         & $561 \pm_{\mu}^{10} 5$       & $556.7 \pm_\mu^{10} 0.3$ & $-4 \pm_\mu 5$\\
    \hspace{1em}Interfering thread      & $561 \pm_{\mu}^{10} 5$       & $556.8 \pm_\mu^{10} 0.3$ & $-4 \pm_\mu 5$\\
    \hline
    \bugname{double\_free}    & & &\\
    \hspace{1em}Active threads          & $1086 \pm_{\mu}^{10} 1$      & $1063.8 \pm_\mu^{10} 0.6$ & $-22 \pm_\mu 1$\\
    \hspace{1em}Environmental thread    & $0.0878 \pm_{\mu}^{10} 0.0008$ & $0.0861 \pm_\mu^{10} 0.0007$ & $0.002 \pm_\mu 0.001$\\
    \hline
  \end{tabbular}
  \caption{Time taken to run a single iteration of the main loop of
    each test, with and without a fix applied.  This experiment was
    structured as eleven batches, with each configuration tested once
    in each batch in random order and the results of the first batch
    discarded.  A configuration was tested by running it for ten
    seconds, restarting whenever the test program crashed, and
    counting the number of times the loop ran during that time.  I
    then calculated the time per iteration as
    $\frac{10\mathrm{s}}{n}$, where $n$ is the number of iterations,
    and present summary statistics for that distribution.}
  \label{tab:eval:artificial_bugs:fixes}
\end{sanetab}
artificial bugs, and these fixes correctly eliminate the bugs and
prevent the programs from crashing.
\autoref{tab:eval:artificial_bugs:fixes} shows the effect these fixes
have on the program's performance, expressed in terms of time taken to
complete the two loops.  These results are difficult to interpret, as
all of the loops contain calls to either \texttt{sleep}, which leads
to obvious distortions in the data, or complex library functions such
as \texttt{rand} or \texttt{malloc}, which interact with the
additional synchronisation in unintuitive ways.  Nevertheless, they
suggest that the cost of a {\technique} critical section is small even
on the scale of microseconds, and hence that {\technique} will be able
to fix bugs in code which runs millions of times per second without
the program as a whole suffering crippling performance degradation.  I
cover this theme in more detail in
\autoref{sect:eval:why:fix_overhead}.

\subsection{Bugs in real programs}
\label{sect:eval:does:real}

The previous section showed that {\implementation} can be used to reproduce
and fix bugs in some simple artificial test programs.  This section
repeats the experiments using two bugs taken from real programs:
\begin{itemize}
\item The first, \bugname{mysql}, is MySQL bug number
  56324~\cite{FFFCorreia2010}.  A simplified version of the buggy code
  is shown in figures~\ref{fig:eval:real_bugs:programs:mysql:crashing}
  and~\ref{fig:eval:real_bugs:programs:mysql:interfering}.  The
  program will crash if the interfering thread sets
  \texttt{PSI\_server} to \texttt{NULL} in between the two accesses to
  that variable in the crashing thread.
\item The second, \bugname{thunderbird}, is Mozilla bug number
  391259~\cite{FFFMery2007}, a time-of-check, time-of-use race in the
  IMAP client component of Thunderbird, a popular open-source e-mail
  client.  The relevant parts of the program are shown in
  figures~\ref{fig:eval:real_bugs:programs:thunderbird:crashing}
  and~\ref{fig:eval:real_bugs:programs:thunderbird:interfering}.  If
  \verb|m_transport| is set to \verb|NULL| by the
  \gls{interferingthread} in between the two accesses in the crashing
  one then the program will crash.
\end{itemize}
{\implementation} is able to reproduce and fix both of these bugs.  For
these tests, unless otherwise noted, I assumed that the crashing
instruction had already been identified, rather than attempting to
discover it automatically using {\technique}.

\begin{sanefig}
  \begin{tabular}{p{8.9cm}p{5.8cm}}
    \subfigure[][{\rm \bugname{mysql\hspace{-1pt}}} crashing thread]{
      \begin{minipage}{8cm}
        \begin{literalC}
          if (PSI\_server) \clbrace
            PSI\_server->delete\_current\_thread();
          \crbrace
        \end{literalC}
      \end{minipage}
      \label{fig:eval:real_bugs:programs:mysql:crashing}
    }
    &
    \subfigure[][{\rm \bugname{mysql\hspace{-1pt}}} interfering thread]{
      \begin{minipage}{5.5cm}
        \begin{literalC}
          \\
          PSI\_server = NULL;\\
        \end{literalC}
      \end{minipage}
      \label{fig:eval:real_bugs:programs:mysql:interfering}
    }\\
    \subfigure[][{\rm \bugname{thunderbird\hspace{-1pt}}} crashing thread]{
      \begin{minipage}{8cm}
        \begin{literalC}
          if (this->m\_transport) \clbrace
            this->m\_transport->SetTimeout();
          \crbrace
        \end{literalC}
      \end{minipage}
      \label{fig:eval:real_bugs:programs:thunderbird:crashing}
    }
    &
    \subfigure[][{\rm \bugname{thunderbird\hspace{-1pt}}} interfering thread]{
      \begin{minipage}{5.5cm}
        \begin{literalC}
          \\
          this->m\_transport = NULL;\\
        \end{literalC}
      \end{minipage}
      \label{fig:eval:real_bugs:programs:thunderbird:interfering}
    }\\
  \end{tabular}
  \caption{Test bugs in real programs.}
  \label{fig:eval:real_bugs:programs}
\end{sanefig}

\subsubsection{Characterising the bugs}

\autoref{tab:eval:real_bugs:analysis_time} shows the time taken to
build the \gls{programmodel} and \glspl{verificationcondition} for
these bugs.  Note that the time to build the \gls{programmodel} is
dramatically larger for real programs than it was for the artificial
ones considered earlier, but the time to generate
\glspl{verificationcondition} is of similar magnitude.  This is
because {\technique} must examine the entire program in order to build
the \gls{programmodel}, but only needs to examine the
\gls{analysiswindow} to build the \glspl{verificationcondition}.  The
high cost of building the model is somewhat mitigated by the fact that
it is built for the program rather than for any particular bug, and so
the cost would be amortised if there were several bugs in the same
program.

\begin{sanetab}
  \begin{tabbular}{|p{2.72cm}|p{5.8cm}|p{5.8cm}|}
    \hline
    Test bug                  & \Gls{programmodel}  & \Glspl{verificationcondition} \\
    \hline
    \bugname{mysql}           & $1088 \pm^{10}_\mu 2$  & $1.13 \pm^{10}_\mu 0.01$ \\
    \bugname{thunderbird}     & $1240 \pm^{10}_\mu 4$ & $0.39 \pm^{10}_\mu 0.01$ \\
    \hline
  \end{tabbular}
  \caption{Time taken, in seconds, to build the static analysis
    component of the \glsentrytext{programmodel} and
    \glsentrytext{verificationcondition}s for the bugs taken from real
    programs.  All tests were run eleven times with the result of the
    first run discarded.}
  \label{tab:eval:real_bugs:analysis_time}
\end{sanetab}

{\Implementation} generated one false positive
\gls{verificationcondition} for each bug, in addition to the desired
true positive.  Both false positives were caused by incompleteness in
{\technique}'s model of the program's behaviour.  In the case of
\bugname{mysql}, the problem was the lack of knowledge of the
program's dataflow structure.  {\Implementation} located another
instruction which could set \texttt{PSI\_server} and which could
potentially race with the \gls{crashingthread}, but in that case the
value stored was always a valid pointer and so the interleaving could
not lead to a crash.  The \bugname{thunderbird} false positive, by
contrast, was caused by an incomplete model of the program's existing
synchronisation structure: {\implementation} located another place in
the program which set \texttt{m\_transport} to \texttt{NULL}, and
correctly identified that interleaving that store with the
\gls{crashingthread} might lead to a crash, but failed to notice that
an existing lock prevented the interleaving from happening.

\subsubsection{Reproducing the bugs}

\begin{sanetab}
  \begin{tabbular}{|p{2.72cm}|l|l|l|}
    \hline
    Bug                   & True positive enforcer & False positive enforcer & Combined enforcer \\
    \hline
    \bugname{mysql}       & $0.566 \pm^{10}_\mu 0.004$ & $0.553 \pm^{10}_\mu 0.003$ & $0.678 \pm^{10}_\mu 0.003$\\
    \bugname{thunderbird} & $0.640 \pm^{10}_\mu 0.003$ & $0.640 \pm^{10}_\mu 0.003$ & $0.710 \pm^{10}_\mu 0.006$\\
    \hline    
  \end{tabbular}
  \caption{Time taken, in seconds, to build the \glsentrytext{bugenforcer}s}
  \label{tab:eval:real_bugs:build_enforcer_times}
\end{sanetab}

\begin{sanetab}
  \begin{tabbular}{|l|p{2.46cm}|p{2.46cm}|p{2.46cm}|p{2.46cm}|}
    \hline
                              & \multicolumn{4}{c|}{Enforcer} \\
    \cline{2-5}
    Bug                       & None   & True positive & False positive & Combined \\
    \hline
    \bugname{mysql}           & 0/100  & 100/100 & 0/100  & 100/100   \\
    \bugname{thunderbird}     & 0/10   &         &        &    \\
    \hspace{1em}100--200ms timeout &   & 0/10    & 0/10   & 0/10  \\
    \hspace{1em}5s timeout    &        & 10/10   & 0/10   & 10/10 \\
    \hline
  \end{tabbular}
  \caption{Reproduction counts for the different bugs and
    configurations.}
  \label{tab:eval:real_bugs:repro_effectiveness}
\end{sanetab}

\noindent
All four \glspl{verificationcondition} can be converted to
\glspl{bugenforcer}.
\autoref{tab:eval:real_bugs:build_enforcer_times} shows how long it
took to do so; as can be seen, this step was very fast.

I then attempted to evaluate the efficacy of the generated enforcers.
The results are shown in
\autoref{tab:eval:real_bugs:repro_effectiveness}.  For the
\bugname{mysql} bug, I selected the \texttt{rpl\_change\_master} test
out of the MySQL test suite, as it runs quickly without manual
intervention and exercises the buggy code, and ran it one hundred
times in each configuration.  As can be seen, the true positive and
combined enforcers were effective at reproducing this bug, and it did
not reproduce at all without an enforcer or with the false positive
enforcer.

For the \bugname{thunderbird} bug, no convenient automated test was
available, and so I exercised the buggy code via manual interaction
with the Thunderbird GUI by clicking on an IMAP folder and then
quickly clicking the close button.  I repeated this ten times in each
configuration, restarting Thunderbird between each attempt.  The IMAP
folder was the only folder in an account on a local Dovecot 1.2.9 IMAP
server which had no other users and no other accounts were configured
in Thunderbird.  The IMAP folder itself was empty.  None of the
generated \glspl{bugenforcer} were able to reproduce this bug using
their default 100--200ms timeout, but increasing the timeout to five
seconds caused the bug to reproduce easily.  The program was still
quite usable even with this long delay as the bug is in code which
executes infrequently and only in a background thread.

This illustrates an important weakness of the {\technique} approach:
the timeout must be tailored to the application being tested, and in
some cases the bug as well.  Too small a timeout will prevent the
threads from properly rendezvousing, preventing the bug from
reproducing at all, while too long a timeout will cause a large probe
effect, also reducing the likelihood of reproduction.  Very roughly,
the timeout must be of the same general scale as the process which
triggers the bug.  In this case, that process involves user
interaction, and so the timeout must be broadly the same scale as
those interactions; five seconds is on that scale, whereas 200ms is
not.

\subsubsection{Fixing the bugs}

\begin{sanetab}
  \begin{tabbular}{|p{3.9cm}|p{10.75cm}|}
    \hline
    Bug                  & Time building fix \\
    \hline
    \bugname{mysql}      & $0.287 \pm_\mu^{10} 0.003$ \\
    \bugname{thunderbird} & $0.373 \pm_\mu^{10} 0.003$ \\
    \hline
  \end{tabbular}
  \caption{Time taken, in seconds, to convert \glsentrytext{verificationcondition}s to fixes.}
  \label{tab:eval:real_bugs:time_building_fixes}
\end{sanetab}

\noindent
These \glspl{verificationcondition} can also be converted to fixes;
the time taken to do so is shown in
\autoref{tab:eval:real_bugs:time_building_fixes}.  The fixes generated
are similar for both bugs: one critical section covering the two loads
in the \gls{crashingthread}, and another covering the store in the
\gls{interferingthread}.  It is hard to validate experimentally that
these fixes are correct, as the bugs reproduce quite rarely even
without the fix,\kern-.5pt\fnote{Due to implementation limitations, it
  is not possible to load a {\implementation} fix and a
  {\implementation} \gls{bugenforcer} into the same program.} but
manual inspection suggested that they had correctly eliminated the
dangerous interleaving.  It is also hard to experimentally evaluate
the performance impact of these fixes, as, in the case of
\bugname{thunderbird}, there is no convenient metric of performance,
beyond noting that performance was qualitatively unaffected, and, in
the case of \bugname{mysql}, the fix is to code which executes
sufficiently rarely that the system-level overhead was immeasurably
small.

These are not the fixes which a human programmer would make.  In
particular, the call to \texttt{delete\_current\_thread}, in
\bugname{mysql}, and \texttt{SetTimeout}, in \bugname{thunderbird},
are not protected in any way.  This means that the
\gls{crashingthread} might continue to execute a method in
\texttt{m\_transport} or \texttt{PSI\_server} after those variables
have been cleared.  In this case, the implementations of those methods
means that this is safe, but doing so does not accord with common
programming practice, and changes in the implementation could render
it unsafe without being visible to {\technique}.  This might cause
{\technique} to generate a fix which is qualitatively incomplete,
despite correctly eliminating all of the identified dangerous
interleavings.

The problem lies in {\technique}'s definition of a ``bug'': an
atomicity violation which might lead to a crash at a particular
instruction.  Once {\technique} has ensured that that specific
instruction cannot crash, it considers the bug to be fixed; if the
program then crashes five instructions later, {\technique} defines
that to be a different bug, requiring a different fix.  This will not
necessarily agree closely with a programmer's or user's idea of what
it means to fix a bug.

\subsubsection{Finding unknown bugs}
\label{sect:how:finding_unknown}

\begin{sanetab}
  \begin{tabbular}{|l|p{4.35cm}|p{4.35cm}|}
    \hline
    Phase & Time taken & Cores used \\
    \hline
    Building \gls{programmodel} & $571 \pm_{\mu}^{10} 1$ & 1\\
    Deriving \glspl{verificationcondition} & $8500 \pm_{\mu}^{10} 100$ & 10 \\
    Converting to \glspl{bugenforcer} & $204 \pm_{\mu}^{10} 3$ & 10 \\
    \hgreyline
    Total & $9300 \pm_{\mu} 100$ & \\
    \hline
  \end{tabbular}
  \caption{Time, in seconds, taken to generate a full suite of
    \glsentrytext{bugenforcer}s for MySQL on a twelve-core AMD Opteron
    6168 with 16GiB of memory running Ubuntu Natty Narwhal.  The
    complete analysis was run eleven times and the results of the
    first run discarded; the results here are averages of the
    remaining ten runs.  The last two phases were parallelised; the
    first was not.}
  \label{tab:eval:does:building_all_enforcers_times}
\end{sanetab}

\noindent
MySQL has an extensive automated test suite, and so {\implementation}
can be used to look for previously unknown bugs by generating every
possible \gls{bugenforcer} and running the test suite under each of
them.  {\implementation} took two and a half hours to generate the
10173 \glspl{bugenforcer} for MySQL (see
\autoref{tab:eval:does:building_all_enforcers_times}).  Note that
these experiments were run on a different computer to those in the
previous sections; see table for details.  To test the effectiveness
of these enforcers, I ran the \texttt{rpl\_change\_master} test
repeatedly with each.  The results are shown in
\autoref{tab:eval:does:finding_unknown}.  Three of the enforcers were
able to reproduce the bugs for which they were designed.  The first,
enforcer A, reproduced the \bugname{mysql} bug, as desired.  The other
two, enforcers B and C, reproduced essentially similar races elsewhere
in MySQL.  I was unaware of these bugs before running this experiment.
All three bugs were very rare without an enforcer, or with the wrong
enforcer, but reproduced very easily when an appropriate enforcer was
used.

It is perhaps surprising that the reproduction rates are lower with an
inappropriate enforcer than they are with no enforcer at all.  This
reflects the fact that randomly adding delays to a program's execution
is not an effective way of reproducing bugs: delaying a thread reduces
the program's effective concurrency, and unless the delays are
carefully positioned this will outweigh the benefits of encouraging it
to explore less-common schedules.

\begin{sanetab}
\begin{tabbular}{|l|l|l|l|}
\hline
         & \multicolumn{3}{c|}{Reproduction rate} \\\cline{2-4}
Enforcer\, & Bug A                         & Bug B                                    & Bug C \\
\hline
None     & 0/10000                       & $0.03 \in [0.007,0.05]^{10000}_{\infty}\%$     & $0.29 \in [0.20,0.38]^{10000}_{\infty}\%$\\
\hgreyline
A        & $90 \in [72,98]^{10}_{\infty}\%$ & 0/10                                     & 0/10 \\
B        & 0/10                          & 10/10                                    & 0/10 \\
C        & 0/10                          & 0/10                                     & 10/10 \\
\hgreyline
Other    & 0/101700                      & $0.014 \in [0.010,0.018]^{101700}_{\infty}\%$ & $0.10 \in [0.08,0.12]^{101700}_{\infty}\%$ \\
\hline
\end{tabbular}
\caption{Effectiveness of {\implementation} at finding previously
  unknown bugs. This experiment was structured as eleven rounds, with
  each enforcer used once in each round and the results of the first
  round discarded.  Apart from stragglers at the end of each round, I
  tested ten enforcers in parallel; the order of
  \glsentrytext{bugenforcer}s, and hence which ran in parallel, was
  chosen randomly in each round.  The system used for this test was
  the same Opteron 6168 as was used to generate the enforcers.  The
  results for the no-enforcer case were produced by running the test
  10,000 times without an enforcer, again running ten instances of the
  test in parallel.}
\label{tab:eval:does:finding_unknown}
\end{sanetab}

\subsection{Dynamic aliasing analysis}

{\technique} relies on an initial dynamic analysis
(\autoref{sect:program_model}) to build a model of the program's
aliasing behaviour, and if this is incomplete then it will not be able
to find all bugs in the program.
Figures~\ref{fig:eval:dyn_convergence:mysqld},
\ref{fig:eval:dyn_convergence:thunderbird},
and~\ref{fig:eval:dyn_convergence:pbzip2} show the number of edges in
the {\implementation} aliasing table during the dynamic analysis
phase, expressed as a proportion of the edges in the final table, as a
function of time, for a variety of test programs and workloads.  These
figures show that the aliasing table had in all cases effectively
converged on its final value within a few minutes, suggesting that,
for these workloads, it would only be necessary to run the program to
be analysed under the dynamic analysis for a few minutes to achieve
adequate coverage.  This is not an unreasonable burden to place on the
user.

\begin{sanefig}
  \begin{tabular}{cc}
    \subfigure[][rpl\_change\_master]{
      \biggraph{eval/dyn_convergence/rpl_change_master.tex}
    } &
    \subfigure[][innodb\_multi\_update]{
      \biggraph{eval/dyn_convergence/innodb_multi_update.tex}
    } \\
    \subfigure[][binlog\_stm\_drop\_tbl]{
      \biggraph{eval/dyn_convergence/binlog_stm_drop_tbl.tex}
    } &
    \subfigure[][timestamp\_basic]{
      \biggraph{eval/dyn_convergence/timestamp_basic.tex}
    }
  \end{tabular}
  \vspace{-12pt}
  \caption{Dynamic aliasing coverage against time for MySQL, using
    some tests out of the test suite.  Dashed vertical lines show
    where the program was restarted.}
  \label{fig:eval:dyn_convergence:mysqld}
\end{sanefig}

\begin{sanefig}
  \biggraph{eval/dyn_convergence/thunderbird}
  \vspace{-24pt}
  \caption{Dynamic aliasing coverage against time for Thunderbird
    during normal usage.  Dashed vertical lines show where the program was
    restarted.}
  \label{fig:eval:dyn_convergence:thunderbird}
\end{sanefig}

\begin{sanefig}
  \biggraph{eval/dyn_convergence/pbzip2}
  \vspace{-24pt}
  \caption{Dynamic aliasing coverage against time for pbzip2 version
    1.1.6 while compressing three randomly-generated 10MiB files.
    Dashed vertical lines show where the program was restarted.}
  \label{fig:eval:dyn_convergence:pbzip2}
\end{sanefig}

I also briefly investigated the performance of the analysis tool
itself, using pbzip2 as a test program.  For these experiments, I
compressed ten randomly-generated 100MiB files with and without the
dynamic analysis.  Without the dynamic analysis, compressing one file
took $7.8 \pm_\mu^{10} 0.1$ seconds; with the dynamic analysis, this
increased to $274 \pm_\mu^{10} 2$ seconds, a factor of roughly
thirty-five.  This is a rather large overhead, and would be infeasible
in a production environment, but is tolerable for something which
needs to run for a few tens of minutes in a development one.  For
comparison, a null Valgrind skin completed this test in $226.6
\pm_\mu^{10} 0.5$ seconds, an overhead of a factor of twenty-nine,
suggesting that most of the overhead of the dynamic analysis tool
comes simply from the fact that it is implemented as a Valgrind skin.
Re-implementing it in a faster analysis framework, such as
PIN~\cite{Luk2005}, might therefore provide a useful speed-up.

\section{How does it work?}
\label{sect:eval:how_does_it_work}
\newcommand{\subphase}[2]{$\mathbb{#1}_{#2}$}
\newcommand{\subcrash}[1]{\subphase{C}{#1}}
\newcommand{\subinterfering}[1]{\subphase{I}{#1}}
\newcommand{\subenf}[1]{\subphase{E}{#1}}
\newcommand{\subfix}[1]{\subphase{F}{#1}}

The previous section demonstrated that {\implementation} works, at a basic
level, for at least some real and artificial bugs.  This section aims
to expand upon this by giving more details of the way in which it
works, by breaking the time and memory usage down into the different
phases of the analysis and determining which phases represent the most
important bottlenecks.  For these experiments, I selected ten thousand
memory-accessing instructions at random from MySQL and produced
\glspl{bugenforcer} and fixes for each in turn, recording the time
spent in each of the various steps of the analysis.

The analysis of a single potentially crashing instruction can be
divided into four phases:
\begin{itemize}
\item \subcrash{} --- per-\gls{crashingthread} analysis work.
  {\implementation} starts analysing a potentially-crashing
  instruction by constructing the crashing {\StateMachine}, and from
  that it builds the interfering \glspl{cfg}.  This work is done once
  for each potentially-crashing instruction.
\item \subinterfering{} --- per-\gls{interferingthread} analysis work.
  Each crashing {\StateMachine} will generate zero or more
  \glspl{interferingthread}, each of which is analysed independently.
\item \subenf{} --- building the \glspl{bugenforcer}.  Each
  \gls{interferingthread} in turn generates zero or one
  \glspl{verificationcondition}.  Each \gls{verificationcondition} is
  processed in isolation to produce a single \gls{bugenforcer}.
\item \subfix{} --- building the fixes.  The
  \glspl{verificationcondition} can instead be converted into fixes.
  Again, each \gls{verificationcondition} is processed in isolation to
  produce a single fix.
\end{itemize}
\begin{sanetab}
  \begin{tabbular}{|l| c| r@{}r@{.}l@{,~}r@{.}l@{}l |c|}
    \hline
                      &         & \multicolumn{7}{c|}{~Average time per \ldots} \\
    \cline{3-9}
    Phase~             & ~Invoked~ & \multicolumn{6}{c|}{Invocation} & Potentially-crashing instruction \\
    \hline
    \subcrash{}       & 1                             & ~~~~~~[&0&82& 1&03&$]_{10000}^{1000}$~~~~~~ & $[0.82, 1.03]_{10000}^{1000}$ \\
    \subinterfering{} & $[2.75, 2.76]_{10000}^{1000}$ & [&0&45& 0&60&$]_{27339}^{1000}$ & $[4.61, 9.27]_{10000}^{1000}$ \\
    \subenf{}         & $[0.37, 0.40]_{10000}^{1000}$ & [&0&33& 0&62&$]_{3838}^{1000}$  & $[0.12, 0.25]_{10000}^{1000}$ \\
    \subfix{}         & $[0.37, 0.40]_{10000}^{1000}$ & [&0&11& 0&12&$]_{3870}^{1000}$  & $[0.04, 0.05]_{10000}^{1000}$ \\
    \hline
  \end{tabbular}
  \caption{Breakdown of analysis time into principal phases.  All
    times in seconds.  The invoked column gives the average number of
    times each phase is invoked for each potentially-crashing
    instruction.}
  \label{tab:eval:phase_breakdown1}
\end{sanetab}
\autoref{tab:eval:phase_breakdown1} shows how often each phase is
invoked and how much time each invocation takes.  As can be seen,
phase \subinterfering{} takes the most time, followed by phase
\subcrash{}; phases \subenf{} and \subfix{} account for a relatively
small phase of the total analysis time.  The following sections
examine each phase in turn, investigating why they take as long as
they do, and hence explaining the performance patterns observed.

\newpage
\subsection{Per-\glsentrytext{crashingthread} analysis}

\begin{sanefig}
  \biggraph{eval/phase_breakdown/per_crashing.tex}
  \caption{Distributions of time taken, in seconds, by the
    \subcrash{i} sub-phases of the analysis; see text for details.}
  \label{fig:eval:how:per_crashing_times}
\end{sanefig}

\noindent
The initial part of the analysis is performed once for each
potentially-crashing instruction.  {\Technique} performs the following
sub-phases for each instruction:
\begin{itemize}
\item \subcrash{0} --- derive the crashing \gls{cfg}
  (\autoref{sect:derive:build_crashing_cfg}).
\item \subcrash{1} --- decompile the crashing \gls{cfg} to produce the
  initial crashing {\StateMachine}
  (\autoref{sect:derive:compile_cfg}).
\item \subcrash{2} --- simplify that initial crashing {\StateMachine},
  eliminating parts which could not possibly influence the bug under
  investigation (\autoref{sect:derive:simplify_sm}).
\item \subcrash{3} --- build the interfering \glspl{cfg} for the
  simplified {\StateMachine} (\autoref{sect:derive:write_side}).
\item \subcrash{4} --- derive the C-atomic assumption
  (Sections~\ref{sect:derive:inferred_assumption}
  and~\ref{sect:derive:w_isolation}).
\item \subcrash{5} -- invoked phase \subinterfering{} so as to process
  each of the interfering \glspl{cfg} produced in \subcrash{3}.
\end{itemize}
\autoref{fig:eval:how:per_crashing_times} shows how much time is spent
in each of these sub-phases.  This figure shows several useful pieces
of information:
\begin{itemize}
\item The main part of the figure shows the probability density
  function (PDF) of the time spent in each part of the analysis.  Note
  that this is shown on a log scale, and that the density is with
  respect to log time.  The kernel used in estimating the probability
  density function is shown below the PDF itself; this is the
  contribution which a single sample makes to the PDF.\fnote{For these
    charts, I used a rectangular kernel of width $2.75Rn^{-0.2}$,
    where $R$ is the log inter-quartile range and $n$ the number of
    samples.  This bandwidth was chosen as it is reasonably robust to
    outliers and minimises the expected mean square error for
    log-Gaussian data.}
\item The median of the distribution is shown as a horizontal line
  across the PDF and its arithmetic mean as a small cross.
\item 90\% confidence intervals for the PDF and median are given by
  grey areas and for the mean by vertical bars.  All confidence
  intervals were calculated using a 1,000 replicate bootstrap.
\item The ``Total'' PDF gives the distribution of the total time taken
  for each potentially-crashing instruction, measured from the start
  of processing to the end.  The ``Defect'' PDF, to its left, shows
  the difference between the total time taken and the sum of all of
  the measured sub-phases.  As can be seen, it is small relative to the
  other quantities measured, which is necessary for the other
  measurements to be meaningful.
  \begin{sanetab}
    \begin{tabbular}{|p{1.85cm}|  c@{}r@{.}l@{,~}r@{.}l@{}l | c@{}r@{.}l@{,~}r@{.}l@{}l  | c@{}r@{.}l@{,~}r@{.}l@{}l | c@{}r@{.}l@{,~}r@{.}l@{}l|}
      \hline
                   & \multicolumn{24}{c|}{Percentage of instructions}\\
      \cline{2-25}
      Sub-phase    & \multicolumn{6}{c|}{Starting sub-phase} & \multicolumn{6}{c|}{Dismissed}  & \multicolumn{6}{c|}{Out of time} & \multicolumn{6}{c|}{Out of memory} \\
      \hline
      \subcrash{0} & \multicolumn{6}{c|}{100}                & [&19&05& 20&35&$]_{\infty}^{10000}$ & \multicolumn{6}{c|}{0/10000}   & \multicolumn{6}{c|}{0/10000} \\
      \subcrash{1} & ~[&79&66& 80&96&$]_{\infty}^{10000}$         & \multicolumn{6}{c|}{0/8031}     & [& 0&01&  0&03&$]_{\infty}^{8031}$ & \multicolumn{6}{c|}{0/8031} \\
      \subcrash{2} & ~[&79&65& 80&95&$]_{\infty}^{10000}$         & \multicolumn{6}{c|}{0/8030}     & [& 0&01&  0&05&$]_{\infty}^{8030}$ & \multicolumn{6}{c|}{0/8030} \\
      \subcrash{3} & ~[&79&63& 80&93&$]_{\infty}^{10000}$         & [&53&28& 55&10&$]_{\infty}^{8028}$ &  \multicolumn{6}{c|}{0/8028}    & \multicolumn{6}{c|}{0/3678} \\
      \subcrash{4} & ~[&36&00& 37&57&$]_{\infty}^{10000}$         & \multicolumn{6}{c|}{0/3678}     & [& 0&02&  0&06&$]_{\infty}^{3678}$ & [& 0&02&  0&11&$]_{\infty}^{3678}$ \\
      \subcrash{5} & ~[&35&97& 37&54&$]_{\infty}^{10000}$         & \multicolumn{6}{c|}{0/3675}     & \multicolumn{6}{c|}{0/3675}     & [& 0&02&  0&06&$]_{\infty}^{3678}$ \\
      \hgreyline
      Total        & \multicolumn{6}{c|}{100}                & [&62&41& 63&98&$]_{\infty}^{10000}$ & [& 0&03&  0&08&$]_{\infty}^{10000}$ & [& 0&02&  0&05&$]_{\infty}^{10000}$ \\
      \hline
    \end{tabbular}
    \caption{Failures and early dismissals during phase \subcrash{}.
      Note that the timeout runs from the start of the per-crashing
      instruction phase, rather than being restarted for each
      sub-phase.}
    \label{tab:eval:how:failures_per_crashing}
  \end{sanetab}
\end{itemize}
Not every instruction completed every sub-phase.  Instructions which
run out of memory or suffered a timeout during an early phase do not
start any of the later ones, and similarly, if the analysis in an
early sub-phase is sufficient to show that a particular instruction
cannot possibly suffer a \gls{sav} then the instruction is dismissed
in that sub-phase and needs no processing in later ones.  The
proportion of instructions which failed or were dismissed in each
phase is shown in \autoref{tab:eval:how:failures_per_crashing}.

The most important observation to draw from these figures, aside from
the gross summary of how long each sub-phase takes, is that most of
the distributions are dominated by their tails, in the sense that the
mean is often more than an order of magnitude greater than the median.
This reflects the fact that many of the algorithms have worst-case
running time far worse than their common case.  Instructions which
happen to hit one of the slow cases take a very long time to complete,
while those which avoid the slow cases complete very quickly.  The
time spent deriving C-atomic, for instance, has a median of 1.3ms and
a mean of 170ms, while the total time taken has a median of 11ms and a
mean of eight seconds.

Aside from those gross features, the distributions also exhibit some
multi-modal behaviour, visible on the chart as a number of ``bulbs''
in the PDFs.  These are accounted for by various special cases within
{\implementation}:
\begin{itemize}
\item The first phase, \subcrash{0}, has a small mode
  at around 20$\mu$s.  The potentially-crashing instructions in this
  bulb are all part of the program's ELF PLT stubs.  {\implementation}
  assumes that these will never crash, allowing it to skip further
  processing with very little work.
\item The same phase also has a mode at about 2ms, which consists of
  instructions which access either the stack or a statically constant
  address.  There is no possibility of these instructions crashing due
  to a race, so {\implementation} can quickly dismiss the instruction
  when it detects one.
\item The next phase, \subcrash{1}, has a mode at about 4ms.  This
  consists of instructions which dereference pointers which the static
  analysis component of the \gls{programmodel} can show to be valid,
  either because they are fixed offsets from the stack pointer or
  because they must have been dereferenced in the same thread before
  reaching this instruction.  The {\StateMachine} is replaced with the
  single state {\stSurvive}.
\item Finally, the fourth phase, \subcrash{3}, has a very large mode
  at about 2ms.  This consists of instructions where none of the
  \gls{speicher}-accessing operations remaining after {\StateMachine}
  simplification could possibly race with another thread according to
  the dynamic component of the \gls{programmodel}.  Such instructions
  will never generate any interfering \glspl{cfg} and can be dismissed
  very quickly.
\end{itemize}
The overall effect of these special cases is that for most
potentially-crashing program instructions, {\implementation} is able
to skip most steps of the analysis.  This is a useful property when
analysing a large number of instructions speculatively.

\subsection{Per-\glsentrytext{interferingthread} analysis}
\label{sect:eval:how:per_interfering}

Phase \subcrash{} generates a large number of pairs of crashing
{\StateMachines} and interfering \glspl{cfg} which must be analysed in
phase \subinterfering{}.  Like phase \subcrash{}, this is divided into
a number of sub-phases:
\begin{itemize}
\item \subinterfering{0} --- decompile the interfering \gls{cfg} into the
  interfering {\StateMachine} (\autoref{sect:derive:build_crashing_cfg}).
\item \subinterfering{1} --- apply additional simplifications to the
  crashing {\StateMachine} which become possible once the interfering
  {\StateMachine} has been identified.
\item \subinterfering{2} --- build and simplify the {\StateMachine}
  used when deriving the \gls{ic-atomic} assumption
  (\autoref{sect:derive:inferred_assumption}).
\item \subinterfering{3} --- symbolically execute the {\StateMachine}
  produced in \subinterfering{2} to produce the \gls{ic-atomic}
  assumption.
\item \subinterfering{4} --- build and simplify the cross-product
  {\StateMachine} (\autoref{sect:using:build_cross_product}).
\item \subinterfering{5} --- symbolically execute the cross-product
  {\StateMachine} to produce the final \gls{verificationcondition}.
\end{itemize}
The time taken to do so is illustrated in
\autoref{fig:eval:how:per_interfering}, in the same style as
\autoref{fig:eval:how:per_crashing_times}; failures and early
dismissals are summarised in
\autoref{tab:eval:how:failures_per_interfering}.  The secondary mode
at about 100$\mu$s in the final phase, \subinterfering{5}, contains
all of the {\StateMachine} pairs where the {\StateMachine} simplifiers
were able to reduce the cross-product {\StateMachine} to the trivial
{\StateMachine} which always survives.

\begin{sanefig}
  \biggraph{eval/phase_breakdown/per_interfering}
  \caption{Time taken by phase \subinterfering{}, in seconds, as
    distributions over the 27535 interfering \glsentrytext{cfg}s
    generated by phase \subcrash{}.}
  \label{fig:eval:how:per_interfering}
\end{sanefig}

\begin{sanetab}
  \begin{tabbular}{|p{1.85cm}|  c@{}r@{.}l@{,~}r@{.}l@{}l | c@{}r@{.}l@{,~}r@{.}l@{}l  | c@{}r@{.}l@{,~}r@{.}l@{}l | c@{}r@{.}l@{,~}r@{.}l@{}l|}
    \hline
                       & \multicolumn{24}{c|}{Percentage of \glspl{cfg}}\\
    \cline{2-25}
    Sub-phase          & \multicolumn{6}{c|}{Starting sub-phase} & \multicolumn{6}{c|}{Dismissed}  & \multicolumn{6}{c|}{Out of time} & \multicolumn{6}{c|}{Out of memory} \\
    \hline
    \subinterfering{0} & \multicolumn{6}{c|}{100}                & \multicolumn{6}{c|}{0/27535}    & [& 0&05&  0&10&$]_{\infty}^{27535}$ & [& 0&00&  0&01&$]_{\infty}^{27535}$ \\
    \subinterfering{1} & ~[&99&89& 99&95&$]_{\infty}^{27535}$         & \multicolumn{6}{c|}{0/27513}    & [& 0&12&  0&20&$]_{\infty}^{27513}$ & \multicolumn{6}{c|}{0/27513} \\
    \subinterfering{2} & ~[&99&81& 99&89&$]_{\infty}^{27535}$         & [&37&43& 38&40&$]_{\infty}^{27471}$ & \multicolumn{6}{c|}{0/27471}    & \multicolumn{6}{c|}{0/27471} \\
    \subinterfering{3} & ~[&61&50& 62&47&$]_{\infty}^{27535}$         & \multicolumn{6}{c|}{0/17055}    & [& 0&21&  0&35&$]_{\infty}^{17055}$ & [& 0&15&  0&27&$]_{\infty}^{17055}$ \\
    \subinterfering{4} & ~[&61&22& 62&18&$]_{\infty}^{27535}$         & \multicolumn{6}{c|}{0/16973}    & [& 0&00&  0&01&$]_{\infty}^{27513}$ & \multicolumn{6}{c|}{0/16973} \\
    \subinterfering{5} & ~[&61&20& 62&18&$]_{\infty}^{27535}$         & \multicolumn{6}{c|}{0/16972}    & [& 0&21&  0&35&$]_{\infty}^{27513}$ & \multicolumn{6}{c|}{0/16972} \\
    \hgreyline
    Total              & \multicolumn{6}{c|}{100}                & [&37&38& 38&34&$]_{\infty}^{27535}$ & [& 0&51&  0&66&$]_{\infty}^{27535}$ & [& 0&09&  0&17&$]_{\infty}^{27535}$ \\
    \hline
  \end{tabbular}
  \caption{Failures and early dismissals during the \subinterfering{}
    phase.  Note that the timeout runs from the start of the
    \subinterfering{} phase, rather than being restarted for each
    sub-phase.}
  \label{tab:eval:how:failures_per_interfering}
\end{sanetab}
As with \autoref{fig:eval:how:per_crashing_times}, this figure shows
that most of the distributions involved are dominated by their tails,
indicating that most of the analysis time is spent processing a small
minority of unusually difficult \glspl{cfg}.  The two symbolic
execution phases are particularly prone to these outliers, because
they must consider every path through the relevant {\StateMachine} and
the number of such paths rises exponentially with the size of the
{\StateMachine}.  The \subcrash{4} per-\gls{crashingthread}
analysis step, which derives the C-atomic assumption by symbolic
execution, likewise shows a particularly long tail in which it is
particularly expensive.

More surprisingly, symbolically executing the \gls{ic-atomic}
{\StateMachine} is more expensive than executing the cross-product
{\StateMachine}, despite having to consider far fewer instruction
orderings.  This is because it has less information about the
configurations in which the {\StateMachines} might start: the
cross-product execution assumes that the \gls{ic-atomic} constraint
holds when the {\StateMachines} start, often eliminating a large
number of possible initial states, whereas the \gls{ic-atomic}
execution can only assume the weaker C-atomic constraint.

\begin{sanefig}
  \biggraph{eval/phase_breakdown/per_interfering_no_w_atomic}
  \caption{Time taken by phase \subinterfering{}, in seconds, with the
    \glsentrytext{ic-atomic}-related sub-phases disabled.}
  \label{fig:eval:how:per_interfering:no_ic_atomic}
\end{sanefig}

This is further illustrated in
\autoref{fig:eval:how:per_interfering:no_ic_atomic}, which shows how
long the various sub-phases take when {\implementation} assumes
\gls{ic-atomic} is the constant \true rather than attempting to derive
it.  This eliminates sub-phases \subinterfering{2} and
\subinterfering{3}, which take 500ms, but increases the cost of the
later sub-phases so that the total time taken was
unchanged.\kern-.5pt\fnote{In fact, the average time taken actually
  \emph{increased} slightly, from $0.52 \in [0.46,
    0.59]_{1000}^{27338}$ to $0.59 \in [0.51, 0.67]_{1000}^{27432}$,
  but that was not statistically significant, and was in any case
  partly influenced by changes in the behaviour of failing runs.}
Disabling \gls{ic-atomic} processing also increased the number of
\glspl{verificationcondition} generated, from 3870 to 6613.  These
extra conditions are all, by construction, false positives, and all
would require run-time verification.

\subsection{Costs of building \glsentrytext{bugenforcer}s}

\begin{sanefig}
  \biggraph{eval/phase_breakdown/build_enforcer}
  \caption{Distributions of time taken, in seconds, for the \subenf{}
    analysis phase to generate \glsentrytext{bugenforcer} from the
    3870 \glsentrytext{verificationcondition}s generated by phase
    \subinterfering{}.}
  \label{fig:eval:how:build_enforcer}
\end{sanefig}

\begin{sanetab}
  \begin{tabbular}{|p{2.5cm} | r@{}r@{.}l@{,~}r@{.}l@{}l | r@{}r@{.}l@{,~}r@{.}l@{}l | r@{}r@{.}l@{,~}r@{.}l@{}l |}
    \hline
               & \multicolumn{18}{c|}{Percentage of \glspl{verificationcondition}} \\
    \cline{2-19}
    Sub-phase  & \multicolumn{6}{c|}{Starting sub-phase} & \multicolumn{6}{c|}{Dismissed} & \multicolumn{6}{c|}{Out of memory} \\
    \hline
    \subenf{0} & \multicolumn{6}{c|}{100}       & \multicolumn{6}{c|}{0/3870} & ~~~\hspace{2pt}~[& 0&51&  0&94&$]_{\infty}^{3870}$~~~\hspace{2pt}~ \\
    \subenf{1} & ~~~[&99&09& 99&51&$]_{\infty}^{3870}$~~~ & \multicolumn{6}{c|}{0/3843} & \multicolumn{6}{c|}{0/3843} \\
    \subenf{2} & ~[&99&09& 99&51&$]_{\infty}^{3870}$ & ~~~\hspace{2pt}~[& 0&07&  0&27&$]_{\infty}^{3843}$~~~\hspace{2pt}~ & ~[& 0&05&  0&16&$]_{\infty}^{3870}$~ \\
    \subenf{3} & ~[&98&83& 99&32&$]_{\infty}^{3870}$ & \multicolumn{6}{c|}{0/3834} & \multicolumn{6}{c|}{0/3834} \\
    \subenf{4} & ~[&98&83& 99&32&$]_{\infty}^{3870}$ & \multicolumn{6}{c|}{0/3834} & ~[& 0&02&  0&11&$]_{\infty}^{3834}$~ \\
    \hgreyline
    Total      & \multicolumn{6}{c|}{100} & ~[& 0&07&  0&26&$]_{\infty}^{3870}$~ & ~[& 0&62&  1&09&$]_{\infty}^{3870}$~ \\
    \hline
  \end{tabbular}
  \caption{Causes of failures converting
    \glsentrytext{verificationcondition}s to
    \glsentrytext{bugenforcer}s.  There were no timeouts in this
    test.}
  \label{fig:eval:how:build_enforcer_failures}
\end{sanetab}

\noindent
\autoref{fig:eval:how:build_enforcer} shows how long it takes to
convert \glspl{verificationcondition} into \glspl{bugenforcer}.  The
figure divides the time taken into five sub-phases:
\begin{itemize}
\item \subenf{0} --- extract the happens-before graph
  (\autoref{sect:enforce:slice_hb_graph}).  This sub-phase is generally
  reasonably quick, with a median time of 20ms, but has a long tail of
  slow and memory-hungry operations.  This reflects the nature of the
  algorithm used: BDD reordering has a good common-case cost but a
  very poor worst-case one.  The \glspl{verificationcondition} which
  avoid the worst-case performance complete very quickly and those
  which do not form the long tail.
\item \subenf{1} --- determining when the verification condition's
  input expressions become available
  (\autoref{sect:enforce:place_vcs}).  This is, unsurprisingly, a very
  quick sub-phase, with relatively few outliers, as the rules governing
  when inputs become available are simple and easily applied.
\item \subenf{2} --- decide how to evaluate the
  non-$\happensBeforeEdge$ component of the
  \gls{verificationcondition} by placing \glspl{side condition} on the
  happens-before and control flow graphs
  (\autoref{sect:enforce:place_vcs}).  Like the first sub-phase, this one
  is implemented using BDD reordering operations, and so is generally
  fast with a long tail of slow operations.  The small bulb of
  \glspl{verificationcondition} which complete in around 20$\mu$s
  consists of the \glspl{verificationcondition} which depend only on
  inputs which are available at the start of the \gls{crashingthread},
  for which the placement problem is trivial.
\item \subenf{3} --- build the patch strategy, expressed as the
  $\mathit{Cont}$ and $\mathit{Patch}$ sets
  (\autoref{sect:enforce:gain_control}).  The secondary mode at around
  2ms consists of \glspl{bugenforcer} which only need to patch
  instructions which are large enough to accommodate a branch
  instruction.  Patching these will never corrupt any other
  instructions, and so building the patch strategy is trivial.
\item \subenf{4} --- compile the resulting enforcer into an ELF shared
  object.  {\Implementation} performs this step by generating a C
  source file and passing it off to the system compiler and linker,
  with the bulk of the time spent in those external programs.  This
  makes it difficult to provide any useful analysis on why this sub-phase
  takes as long as it does.
\end{itemize}
Somewhat surprisingly, {\implementation} was able to eliminate six
\glspl{verificationcondition} whilst placing \glspl{side condition} in
sub-phase \subenf{2}.  This was due to the incompleteness of
{\implementation}'s SMT solver.  The solver makes use of a number of
heuristics based on the \gls{bdd} structure of the
\gls{verificationcondition} as part of its final satisfiability check,
and these heuristics produce slightly different results as the
\gls{side condition} algorithm manipulates that structure.  In those
six \glspl{verificationcondition}, the solver was unable to show that
the original condition was unsatisfiable but was able to show that one
of the rearranged forms was, and hence that the bug could never be
reproduced.  There was therefore no need to generate
\glspl{bugenforcer} for any of them and {\implementation} skipped the
remaining steps involved in building one.

Ignoring those six unsatisfiable \glspl{verificationcondition}, this
phase suffered a total of thirty-two failures, giving a failure rate
of 0.8\%.  The per-\gls{crashingthread} and
per-\gls{interferingthread} both suffered failure rates of 0.7\%;
collectively, these suggest that {\implementation}, with these settings,
will be unable to generate \glspl{bugenforcer} for roughly 2.2\% of
potential bugs of the targeted form.  While obviously worse than a 0\%
failure rate, a 2.2\% one is still reasonably low, and is unlikely to
be a crippling limitation.

\subsection{Costs of building fixes}

\Glspl{verificationcondition} can also be converted into fixes.
\autoref{tab:eval:gen_fix_perf} shows how long that takes, using the
same \glspl{verificationcondition} as used in the previous experiment.
This phase is, again, broken down into a number of sub-phases:
\begin{itemize}
\item \subfix{0} --- find the critical sections which are to be enforced,
  as described in \autoref{sect:fix:identify}.
\item \subfix{1} --- build a patch strategy, determining how the fix
  is to gain control of the program, using the algorithm from
  \autoref{sect:enforce:gain_control}.
\item \subfix{2} --- use the graph gramar given in
  \autoref{sect:fixing:shadowfrag} to generate the
  \gls{shadowfragment} which will form the body of the patch.
\item \subfix{3} --- combine the \gls{shadowfragment} and patch
  strategy and pass the result to the system compiler, in this case gcc
  version 4.3.3, to generate the final patch.
\end{itemize}
As can be seen, the time taken is completely dominated by the system
compiler.  This makes it difficult to explain why the process takes as
long as it does in any meaningful way.  Nevertheless, these results
confirm that building fixes from \glspl{verificationcondition} is
itself a very fast operation, compared to building the
\glspl{verificationcondition} themselves, and so this phase is unlikely
to be the most important barrier to practical use of {\technique}.

\begin{sanetab}
  \centerline{
  \tabcolsep 3.5pt
  \begin{tabbular}{|p{1.85cm}| r@{.}l@{}c@{}r@{.}l | c@{}r@{.}l@{,}r@{.}l@{}l | c@{}r@{.}l@{,}r@{.}l@{}l | c@{}r@{.}l@{,}r@{.}l@{}l|}
    \hline
          &  \multicolumn{5}{c|}{}    & \multicolumn{18}{c|}{Percentiles} \\
    \cline{7-24}
    Sub-phase & \multicolumn{5}{c|}{Mean} & \multicolumn{6}{c|}{$5^{th}$\%} & \multicolumn{6}{c|}{$50^{th}$\%} & \multicolumn{6}{c|}{$95^{th}$\%}  \\
    \hline
    \subfix{0} &   0&53 & $\pm_\mu^{3870}$ & 0&03 &   [& 0&10& 0&11&$]_{1000}^{3870}$ & [&  0&25&  0&26&$]_{1000}^{3870}$ & [&  1&21&  1&44&$]_{1000}^{3870}$ \\
    \subfix{1} &   7&29 & $\pm_\mu^{3870}$ & 0&30 &   [& 0&33& 0&37&$]_{1000}^{3870}$ & [&  0&87&  0&89&$]_{1000}^{3870}$ & [& 35&67& 40&21&$]_{1000}^{3870}$ \\
    \subfix{2} &   1&79 & $\pm_\mu^{3870}$ & 0&09 &   [& 0&24& 0&27&$]_{1000}^{3870}$ & [&  0&54&  0&57&$]_{1000}^{3870}$ & [&  5&64&  9&80&$]_{1000}^{3870}$ \\
    \subfix{3} & 104&45 & $\pm_\mu^{3870}$ & 0&23 &   [&85&96&86&77&$]_{1000}^{3870}$ & [&104&18&105&13&$]_{1000}^{3870}$ & [&120&64&121&71&$]_{1000}^{3870}$ \\
    \hgreyline
    Total      & 114&12 & $\pm_\mu^{3870}$ & 0&40 &   [&89&10&89&96&$]_{1000}^{3870}$ & [&110&25&111&37&$]_{1000}^{3870}$ & [&147&55&152&59&$]_{1000}^{3870}$ \\
    \hline
  \end{tabbular}
  }
  \caption{Time taken to convert the 3870
    \glsentrytext{verificationcondition}s generated by the experiments
    in \autoref{sect:eval:how:per_interfering} into fixes.  All times
    in milliseconds.  There were no failures during this
    experiment.}
  \label{tab:eval:gen_fix_perf}
\end{sanetab}

\section{Why does it work?}
\label{sect:eval:why_does_it_work}

Previous sections have established that {\implementation} works at a basic
level and given some details of its operation.  This section aims to
expand on that by providing some explanations for the properties
observed and showing how they follow from the {\technique} design.

\subsection{Importance of \glsentrytext{side condition} checking}

The most distinctive feature of {\technique}'s \gls{bugenforcer}
mechanism, compared to previous work such as Kivati~\cite{Chew2010} or
MUVI~\cite{Lu2007}, is \gls{side condition} checking, which enables it
to avoid spending time enforcing a particular concurrent ordering if
some aspect of the program's state means that doing so would be
unproductive.  \autoref{fig:eval:indexed_toctou:no_scs} shows the
reproduction time for the \bugname{toctou} test with a full enforcer
and with one which does not perform any \gls{side condition} checking.
This clearly shows not only that reproduction performance without
\gls{side condition} checking is far worse than with a full enforcer,
but also that it is worse than not using an enforcer at all.  Without
\gls{side condition} checking, the enforcer enforces the
happens-before graph every time the buggy code runs, causing the
program to run far more slowly, so the buggy code runs far less
frequently.  In this case, the happens-before graph is quite simple
but the \gls{side condition} has a low probability of succeeding, and
increasing the likelihood of reproducing the happens-before graph is
insufficient to outweigh the reduced number of chances to satisfy the
\gls{side condition}.

\begin{sanefig}
  \biggraph{eval/artificial_bugs/special/indexed_toctou_no_scs.tex}
  \caption{Effect of \glsentrytext{side condition} checking on the time taken to
    reproduce the indexed\_toctou bug.  Each configuration was run 110
    times and the first 10 results discarded; the chart shows a CDF of
    the time taken to reproduce in the remaining 100 runs.  The grey
    regions give 90\% DKWM confidence intervals.  Note log scale.}
  \label{fig:eval:indexed_toctou:no_scs}
\end{sanefig}

The importance of \gls{side condition} checking depends on the probability
of satisfying the condition, and hence, for the \bugname{toctou} test,
on \texttt{NR\_PTRS}.  \autoref{fig:eval:indexed_toctou:nr_ptrs} shows
this dependency.  Reproduction times rise with \texttt{NR\_PTRS},
whether an enforcer is used or not, but do so far more rapidly without
one, indicating that these \glspl{bugenforcer} become relatively more
effective as the probability of a \gls{side condition} passing falls.  This
is an encouraging result: the bugs which are most difficult to
reproduce are also usually the hardest to fix, and so it suggests that
{\technique}'s enforcers are most effective where they are most
useful.

\begin{sanefig}
  \subfigure[][Without enforcer]{ \biggraph{eval/artificial_bugs/special/indexed_toctou_vary_nr_ptrs_no_enforcer.tex} }
  \subfigure[][With enforcer]{ \biggraph{eval/artificial_bugs/special/indexed_toctou_vary_nr_ptrs_enforcer.tex} }
  \caption{Reproduction times with and without an enforcer loaded, for
    varying values of \texttt{NR\_PTRS}.  Note the log scales.  Each
    abscissa was sampled 110 times, discarding the first ten results
    and with the order of tests randomised.  Boxes show interquartile
    range and median with 90\% confidence interval for quantiles in
    grey.  Cross and bars give arithmetic mean and 90\% confidence
    interval for mean.  Confidence intervals computed by a bootstrap
    with 1000 replicates.}
  \label{fig:eval:indexed_toctou:nr_ptrs}
\end{sanefig}

\subsection{Effect of {\StateMachine} simplification}

{\technique} applies various simplifications to {\StateMachines}
before attempting to symbolically execute them, and, as previously
indicated, these simplifications often account for a significant
proportion of the total analysis time.  {\implementation} is nevertheless
faster because of them, as the cost of the simplification is
outweighed by the reduction in the cost of the symbolic execution
steps.  To quantify this, I re-ran the experiments of
\autoref{sect:eval:how_does_it_work} with {\StateMachine}
simplification disabled; the results are shown in
\autoref{tab:eval:why:effects_of_simplification}.  As expected, the
simplifiers reduce the total time taken by the analysis and the number
of failures experienced.  Perhaps surprisingly, they also increased
the number of \glspl{verificationcondition} generated.  This is due to
a survival effect: disabling the simplifiers excludes the most complex
{\StateMachines}, as those tend to fail without simplification, and
those are generally the most likely to generate
\glspl{verificationcondition}.  All of the additional
\glspl{verificationcondition} observed with simplification enabled
corresponded to cases which simply failed with simplification
disabled.

\begin{sanetab}
  \centerline{
  \begin{tabbular}{|l|l|l|}
    \hline
    & \multicolumn{2}{c|}{{\STateMachine} simplification} \\
    \cline{2-3}
    & Enabled & Disabled \\
    \hline
    Mean time to process crashing instruction                            & $[5.3, 11]_{1000}^{10000}$     & $[27, 38]_{1000}^{10000}$\\
    {\ldots} excluding per-\gls{interferingthread} work*                 & $[0.83, 1.03]_{1000}^{9993}$   & $[2.4, 2.9]_{1000}^{9963}$\\
    \Glspl{verificationcondition} per crashing instruction*              & $[0.37, 0.40]_{1000}^{9993}$   & $[0.25, 0.28]_{1000}^{9963}$\\
    Interfering \glspl{cfg} per crashing instruction*                    & $[2.75, 2.76]_{1000}^{9993}$   & $[5.25, 5.27]_{1000}^{9963}$\\
    Failures per crashing instruction (\%)                               & $[0.03, 0.12]_{\infty}^{10000}$ & $[0.27, 0.48]_{\infty}^{10000}$\\
    Mean time to process interfering \gls{cfg}$\dagger$                  & $[0.46, 0.60]_{1000}^{27339}$  & $[1.80, 1.99]_{1000}^{51706}$\\
    \Glspl{verificationcondition} per interfering \gls{cfg}(\%)$\dagger$~ & $[13.8, 14.6]_{\infty}^{27339}$ & $[4.95,5.28]_{\infty}^{51706}$\\
    Failures per interfering \gls{cfg} (\%) *                            & $[0.62, 0.80]_{\infty}^{27535}$ & $[1.3,1.5]_{\infty}^{52434}$\\
    \hline
  \end{tabbular}
  }
  \caption{Effect of {\StateMachine} simplification on analysis
    effectiveness. All times in seconds. *: Excluding failures in the
    per-crashing instruction phase. $\dagger$: Excluding failures in
    either phase.  Note that the data for the simplification-enabled
    case was taken from the experiments reported in
    \autoref{sect:eval:how_does_it_work}, rather than being
    re-collected for this table.}
  \label{tab:eval:why:effects_of_simplification}
\end{sanetab}

\subsection{Effect of the \glsentrytext{w-isolation} assumption}
\label{sect:eval:w_isolation}

{\technique} can optionally make use of the \gls{w-isolation}
assumption to constrain the aliasing problem, and this can sometimes
usefully improve analysis performance at the expense of discovering a
smaller class of bugs.  I evaluated the impact of this assumption by
repeating the experiments of \autoref{sect:eval:how_does_it_work} with
\gls{w-isolation} disabled.  The results are shown in
\autoref{tab:eval:why:w_isolation}.  These are broadly as expected:
the \gls{w-isolation} assumption causes the analysis to complete
slightly more quickly, with a slight reduction in the number of
failures, and causes {\implementation} to generate a slightly smaller
set of \glspl{verificationcondition}.  In this instance, all of the
eliminated \glspl{verificationcondition} were false
positives,\fnote{To confirm this, I converted them all into
  \glspl{bugenforcer} and applied them all to the
  \texttt{rpl\_change\_master} test, in the style of
  \autoref{sect:how:finding_unknown}; none were able to reproduce the
  hypothesised bugs.} and so this is a very reasonable trade-off.

\begin{sanetab}
  \centerline{
  \begin{tabbular}{|l|l|l|}
    \hline
    & \multicolumn{2}{c|}{\Gls{w-isolation} assumption} \\
    \cline{2-3}
    & Enabled & Disabled \\
    \hline
    Mean time to process crashing instruction                            & $[5.3, 11]_{1000}^{10000}$      & $[9.0, 15]_{1000}^{10000}$ \\
    {\ldots} excluding per-\gls{interferingthread} work*                 & $[0.82, 1.03]_{1000}^{9993}$    & $[1.1, 1.4]_{1000}^{9994}$\\
    \Glspl{verificationcondition} per crashing instruction*              & $[0.37, 0.40]_{1000}^{9993}$    & $[0.39, 0.42]_{1000}^{9994}$\\
    Interfering \glspl{cfg} per crashing instruction*                    & $[2.75, 2.76]_{1000}^{9993}$  & $[3.25,3.27]_{1000}^{9994}$ \\
    Failures per crashing instruction (\%)                               & $[0.03, 0.12]_{\infty}^{10000}$  & $[0.02, 0.10]_{\infty}^{10000}$\\
    Mean time to process interfering \gls{cfg}$\dagger$                  & $[0.46, 0.60]_{1000}^{27339}$   & $[0.76, 0.92]_{1000}^{32275}$\\
    \Glspl{verificationcondition} per interfering \gls{cfg}(\%)$\dagger$~ & $[13.8, 14.6]_{\infty}^{27339}$  & $[12.2,12.9]_{\infty}^{32275}$\\
    Failures per interfering \gls{cfg} (\%) *                            & $[0.62, 0.80]_{\infty}^{27535}$  & $[0.81,0.99]_{\infty}^{32569}$\\
    \hline
  \end{tabbular}
  }
  \caption{Effect of the \glsentrytext{w-isolation} assumption on analysis
    effectiveness. All times in seconds.  *: Excluding failures in the
    per-crashing instruction phase. $\dagger$: Excluding failures in
    either phase.}
  \label{tab:eval:why:w_isolation}
\end{sanetab}

\subsection{Effect of the \glsentrytext{programmodel}}

{\technique} uses an \gls{programmodel} to capture certain interesting
parts of the program's behaviour beyond the \gls{analysiswindow}, and
this information is used in a number of places throughout the
analysis.  Some of these, such as the use of the dynamic aliasing
model to derive $\beta$ and $c2i$ when building the interfering
\glspl{cfg}, are essential to the approach, and without them no
progress can be made at all; others, such as the use of hints from the
aliasing model during symbolic execution, are optional, and can be
disabled to produce an analysis which is less effective but still
produces some results.  To quantify these effects, I re-analysed the
10,000 instructions chosen in \autoref{sect:eval:how_does_it_work}
with {\implementation} configured to make minimal use of the static
parts of the \gls{programmodel} and a 1,000 instruction subset with
{\implementation} configured to make minimal use of the dynamic parts.
The results are shown in \autoref{tab:eval:why:program_model}.

\begin{sanetab}
  \newcommand{\HangingRaggedRight}{\raggedright \leftskip 2em \parindent -2.2em }
  \begin{tabbular}{|>{\HangingRaggedRight} p{6.2cm}| >{\RaggedRight \hspace{-1mm}}p{2.55cm}| >{\RaggedRight}p{2.6cm} | >{\RaggedRight}p{2.6cm}|}
    \hline
    & Full model & \raggedright Static disabled & \raggedright Dynamic disabled \tabularnewline
    \hline
    Mean time to process crashing instruction                            & $[5.3, 11]_{1000}^{10000}$     & $[10, 15]_{1000}^{10000}$ & $[170, 260]_{1000}^{1000}$   \\
    {\ldots} excluding per-\gls{interferingthread} work*                 & $[0.82, 1.03]_{1000}^{9993}$   & $[0.95, 1.13]_{1000}^{9966}$ & $[1.8, 3.4]_{1000}^{966}$   \\
    Mean \glspl{verificationcondition} per crashing instruction*         & $[0.37, 0.40]_{1000}^{9993}$   & $[0.40, 0.42]_{1000}^{9966}$ & $[1.64, 1.76]_{1000}^{966}$ \\
    Mean interfering \glspl{cfg} per crashing instruction*               & $[2.75, 2.76]_{1000}^{9993}$   & $[2.76, 2.78]_{1000}^{9966}$ & $[3.26, 3.34]_{1000}^{966}$ \\
    Failures per crashing instruction(\%)                                & $[0.03, 0.12]_{\infty}^{10000}$ & $[0.24, 0.44]_{\infty}^{10000}$ & $[2.4, 4.4]_{\infty}^{1000}$ \\
    Mean time to process interfering \gls{cfg}$\dagger$                  & $[0.46, 0.60]_{1000}^{27339}$  & $[1.14, 1.35]_{1000}^{27260}$ & $[12, 15]_{1000}^{2183}$ \\
    \Glspl{verificationcondition} per interfering \gls{cfg}(\%)$\dagger$ & $[13.8, 14.6]_{\infty}^{27339}$ & $[14.6,15.4]_{\infty}^{27260}$ & $[73.6,76.8]_{\infty}^{2183}$ \\
    Failures per interfering \gls{cfg} (\%)*                             & $[0.62, 0.80]_{\infty}^{27535}$ & $[1.0,1.3]_{\infty}^{27587}$ & $[30,33]_{\infty}^{3187}$ \\
    \hline
  \end{tabbular}
  \caption{Effect of the \glsentrytext{programmodel} assumption on
    analysis effectiveness. For the dynamic disabled column,
    {\implementation} was configured to only use information from the
    dynamic alias analysis when deriving $\beta$ and $i2c$; for the
    static disabled one, it was configured to only use information
    from the static analysis when deriving the static crashing
    \glsentrytext{cfg}.  All times in seconds.  *: Excluding failures
    in the per-crashing instruction phase. $\dagger$: Excluding
    failures in either phase.  Note that the dynamic disabled
    configuration was tested with only 1,000 potentially crashing
    instructions, whereas the other two configurations were each
    tested with 10,000.}
  \label{tab:eval:why:program_model}
\end{sanetab}

These results suggest that the hints from the static analysis are
useful but not critical, giving modest reductions in the analysis
time, in the failure rate, and in the number of
\glspl{verificationcondition} generated.  {\technique} remains useful,
albeit slower and less effective, when the non-essential information
collected by the static analysis is ignored.  The results when
disabling hints from the dynamic analysis are far more dramatic.  The
analysis time and failure rate rise to the point where {\technique} is
effectively useless.  

\subsection{Interaction with the program's existing synchronisation}

\begin{sanefig}
  \subfigure[][\RaggedRight Crashing thread with {\technique}-visible synchronisation]{
    \begin{minipage}{5.1cm}
      \begin{literalC}
        while (1) \clbrace
          analysis\_window \clbrace
            lock(); \\
            if (ptr != 0) \clbrace
              *ptr = 5;
            \crbrace \\
            unlock();
          \crbrace
        \crbrace
      \end{literalC}
    \end{minipage}
    \label{fig:eval:existing_sync:visible}
  }
  \subfigure[][\RaggedRight Crashing thread with {\technique}-invisible synchronisation]{
    \begin{minipage}{5.1cm}
      \begin{literalC}
        while (1) \clbrace
          lock();\\
          analysis\_window \clbrace
            if (ptr != 0) \clbrace
              *ptr = 5;
            \crbrace
          \crbrace \\
          unlock();
        \crbrace
      \end{literalC}
    \end{minipage}
    \label{fig:eval:existing_sync:invisible}
  }
  \subfigure[][Interfering thread]{
    \begin{minipage}{3cm}
      \begin{literalC}
        while (1) \clbrace
          ptr = \&t;\\
          analysis\_window \clbrace
            lock();\\
            ptr = 0;\\
            unlock();
          \crbrace
        \crbrace
        \\
      \end{literalC}
    \end{minipage}
    \label{fig:eval:existing_sync:interfering}
  }
  \vspace{-12pt}
  \caption{A correctly synchronised program.  \texttt{lock()} and
    \texttt{unlock()} acquire and release a global lock,
    respectively.}
  \label{fig:eval:existing_sync}
\end{sanefig}

\noindent
This section briefly explores the effects of any existing
synchronisation on {\technique}'s behaviour, using the test program
shown in \autoref{fig:eval:existing_sync}.  In this (correctly
synchronised) program, the interfering thread modifies a global
variable while the two crashing threads simultaneously make use of it.
The crashing threads differ only in the placement of the
synchronisation operations: the first, in
\autoref{fig:eval:existing_sync:visible}, places the synchronisation
within the \gls{analysiswindow}, making it visible to the {\technique}
analysis, whereas the second, in
\autoref{fig:eval:existing_sync:invisible}, moves it outside of the
window, so {\technique} will be unaware of it.

As expected, {\implementation} produces a \gls{verificationcondition}, and
hence a \gls{bugenforcer}, for the second thread but not for the
first.  When loaded into the program, this enforcer attempts to
enforce a happens-before graph which contradicts the program's
existing synchronisation and therefore deadlocks.  This causes the
enforcer's message operations to time out so the enforcer exits
and allows the program to run normally (beyond suffering reduced
performance).

The \gls{verificationcondition} can also be converted to a ``fix''.
This fix does not fix any actual bugs, as there are none, but does not
otherwise harm the program's execution, beyond a slight loss of
performance.

\subsection{Sources of fix overhead}
\label{sect:eval:why:fix_overhead}

As previously discussed, {\implementation}-generated fixes generally have
low overheads, usually on the order of a few microseconds per critical
section.  This section gives a more detailed break-down of the sources
of that overhead.  All experiments described in this section were
conducted using the test program \bugname{nobug}, shown in
\autoref{fig:eval:why:nobug}.  {\implementation} generates a single
\gls{verificationcondition} for this test program, and can thence
generate a fix for it, but, since the purported bug is a false
positive, the fix has no effect beyond degrading the program's
performance.  \autoref{tab:eval:why:nobugperf} quantifies this
degradation, for several variants of the fix:


\begin{sanefig}
  {\hfill}
  \subfigure[][\Gls{crashingthread}]{
    \begin{minipage}{1cm}
      \begin{literalC}
        while (1) \clbrace
          analysis\_window \clbrace
            x$_0$ = global;\\
            x$_1$ = global;\\
            assert(x$_0$ + x$_1$ != 3);
          \crbrace
        \crbrace
      \end{literalC}
    \end{minipage}
  }
  {\hfill}
  \subfigure[][\Gls{interferingthread}]{
    \begin{minipage}{1cm}
      \begin{literalC}
        \\
        while (1) \clbrace
          analysis\_window \clbrace
            global = 1;
          \crbrace
        \crbrace
        \\
      \end{literalC}
    \end{minipage}
  }
  {\hfill}
  \caption{The {\!\rm \bugname{nobug}\!} test program.}
  \label{fig:eval:why:nobug}
\end{sanefig}

\begin{sanetab}
  \centerline{%
    \setlength{\tabcolsep}{2pt}%
  \begin{tabbular}{|l| c@{}r@{.}l@{,~}r@{.}l@{}l | c@{}r@{.}l@{,~}r@{.}l@{}l | c@{}r@{.}l@{,~}r@{.}l@{}l | c@{}r@{.}l@{,~}r@{.}l@{}l |}
    \hline
                                  & \multicolumn{12}{c|}{[Thread iteration time$]_{1000}^{100}$} & \multicolumn{12}{c|}{[Overhead$]_{1000}$} \\
    \cline{2-25}
    Type of fix                   & \multicolumn{6}{c|}{Crashing} & \multicolumn{6}{c|}{Interfering} & \multicolumn{6}{c|}{Crashing} & \multicolumn{6}{c|}{Interfering} \\
    \hline
    \textit{None}                 & [& 156&9&  157&7&]& [& 117&0&  117&9&]& [&  -0&6&    0&6&]& [&  -0&6&    0&6&] \\
    \textit{Gain control only}    & [& 157&3&  159&5&]& [& 116&6&  117&9&]& [&   0&0&    2&2&]& [&  -1&2&    0&6&] \\
    \textit{No synchronisation}   & [& 157&7&  160&7&]& [& 115&6&  117&6&]& [&   0&2&    3&4&]& [&  -2&2&    0&2&] \\
    \textit{Synchronise crashing} & [& 329&0&  330&9&]& [&  57&8&   58&4&]& [& 171&6&  173&7&]& [& -59&9&  -58&8&] \\
    \textit{Normal}               & [&1136&4& 1230&7&]& [&1359&9& 1416&7&]& [& 978&3& 1072&8&]& [&1244&2& 1299&2&] \\
    \hgreyline
    \textit{Debug registers}      & [&3438&2& 3481&6&]& [&3438&2& 3480&8&]& [&3281&9& 3325&0&]& [&3322&5& 3364&1&] \\
    \hline
  \end{tabbular}
  }
  \caption{Time taken, in nanoseconds, for the {\!\rm \bugname{nobug}\!} test to
    complete each loop iteration with a selection of partial fixes
    applied.  I measured the time taken to complete an iteration of
    the loop by running the test program for ten seconds, counting the
    number of times the loop completed in that time, $n$, and then
    computing the iteration time as $\frac{10s}{n}$.  I repeated this
    procedure 110 times for each configuration, in random order,
    discarding the first ten results, and present 90\% confidence
    intervals for the mean of the remaining 100 samples.  See text for
    descriptions of the types of fix used.}
  \label{tab:eval:why:nobugperf}
\end{sanetab}

\begin{itemize}
\item \textit{None} --- No fix is applied at all.
\item \textit{Gain control only} --- The fix is generated by the usual
  algorithm, except that the $\mathit{newNode}$ function in
  \autoref{fig:fix:graph_grammar} is replaced with the constant
  $\varnothing$.  The resulting fix will gain control of the program
  in the usual way but will return control as soon as the program
  leaves the $\mathit{Cont}$ set.  This configuration measures the
  overheads introduced by simply gaining control of the program at the
  necessary points.
\item \textit{No synchronisation} --- The fix is generated by the
  usual algorithm, except that the ``Acquire lock'' and ``Release
  lock'' sequences in \autoref{fig:fix:graph_grammar} are replaced
  with empty ones.  The resulting patch will gain control of the
  program in the usual way, and will retain control for as long as a
  full patch would, but will never perform any synchronisation
  operations.  This configuration measures the overheads introduced by
  duplicating and rearranging the program code in the critical
  sections.
\item \textit{Synchronise crashing} --- This fix omits the
  \gls{interferingthread} synchronisation operations from the patch
  but retains the \gls{crashingthread} ones, making it possible to
  evaluate the overhead of synchronisation operations in the absence
  of any contention.  Note that the \gls{interferingthread} actually
  runs much \emph{faster} in this configuration than it does in the
  baseline case; this is because slowing down the \gls{crashingthread}
  reduces contention for the \texttt{global} variable, allowing the
  interfering one to make faster progress.
\item \textit{Normal} --- This configuration uses a complete fix,
  generated using the complete algorithms from
  \autoref{sect:enforce:gain_control} and
  \autoref{fig:fix:graph_grammar}.
\item \textit{Debug registers} --- This configuration again uses a
  complete fix, except that rather than gaining control using the
  patch strategy algorithm described in
  \autoref{sect:enforce:gain_control}, it gains control using the
  processor's breakpoint registers~\cite[Chapter 16.2: Debug
    Registers]{Intel2009}.
\end{itemize}
These results show quite clearly that, at least for this test program,
gaining and maintaining control of a program thread using
{\technique}'s patch strategy mechanism is very cheap, almost
unmeasurably so in this experiment.  The synchronisation operations
are comparatively expensive: even an uncontended lock acquire and
release adds 172ns to the loop iteration time, already a greater than
100\% overhead, and the full fix, which introduces lock contention,
adds 1$\mu$s to each crashing iteration and 1.3$\mu$s to each
interfering one.  This suggests that most of the overhead of
{\implementation}'s fixes comes about simply because they use locks to
impose mutual exclusion, and not because of any inefficiencies in
realising that scheme.  Further improvements to performance would
almost certainly involve applying a different type of synchronisation,
and not simply making the current scheme more efficient.

The final line in the table, \textit{Debug registers}, shows the
performance achieved by a complete fix which gains control using
processor breakpoint registers rather than via the patch strategy
mechanism.  The overhead is in this case roughly 3$\mu$s in both the
crashing and interfering loops, a factor of three higher than that
observed with the normal {\implementation} fix and a factor of twenty
higher than that observed with the \gls{crashingthread}-only
{\implementation} fix.  Such high overheads could potentially limit a debug
register-based solution's applicability to bugs in frequently executed
code (and debug register-based systems are in any case less
generically applicable than {\implementation} fixes due to the limited
number of such registers available in most processors).

\section{When does it work?}
\label{sect:eval:does_it_scale}

Previous sections have investigated whether {\implementation} works,
how it works, and why it works.  This section builds upon these by
looking at how {\implementation}'s behaviour depends on the complexity
of the bug to be investigated, quantifying its scalability, and hence
places some constraints on the situations in which {\technique} is
likely to be useful.

\subsection{Scalability to complex happens-before graphs}
\label{sect:eval:complex_hb}

\begin{sanefig}
  {\hfill}
  \subfigure[][Crashing thread]{
    \texttt{
      \begin{tabular}{lll}
        \multicolumn{3}{l}{while (1) \{} \\
        & \multicolumn{2}{l}{analysis\_window \{} \\
        & & $\texttt{x}_1$ = global;\\
        & & $\texttt{x}_2$ = global;\\
        & & $\vdots$ \\
        & & $\texttt{x}_N$ = global;\\
        & & \hspace{-2mm}\begin{tabular}{ll}
          assert(!(&\hspace{-2.5mm}$\texttt{x}_1$ == 1 \&\& \\
          &\hspace{-2.5mm}$\texttt{x}_2$ == 2 \&\& \\
          &$\vdots$ \\
          &\hspace{-2.5mm}$\texttt{x}_N$ == N)); \\
        \end{tabular}\\
        & \multicolumn{2}{l}{\}} \\
        \multicolumn{3}{l}{\}} \\
      \end{tabular}
    }
  }
  {\hfill}
  \subfigure[][Interfering thread]{
    \texttt{
      \begin{tabular}{lll}
        \\
        \\
        \multicolumn{3}{l}{while (1) \{} \\
        & \multicolumn{2}{l}{analysis\_window \{} \\
        & & global = 1;\\
        & & global = 2;\\
        & & $\vdots$ \\
        & & global = N;\\
        & \multicolumn{2}{l}{\}} \\
        \multicolumn{3}{l}{\}} \\
        \\
        \\
      \end{tabular}
    }
  }
  {\hfill}
  \caption{The \bugname{complex\_hb}$_{N}$ test.  This bug will only
    be triggered if $2N-1$ happens-before edges are all correctly
    enforced.}
  \label{fig:eval:why:complex_hb}
\end{sanefig}

\noindent
This section explores {\implementation}'s behaviour as the complexity
of the happens-before graph increases, using the test program shown in
\autoref{fig:eval:why:complex_hb}.  The two threads each consist of a
series of $N$ memory accesses arranged such that the program crashes
if it alternates accesses between the two threads.  The happens-before
graph for this bug therefore contains $2N-1$ edges.

\begin{sanefig}
  \subfigure[][Analysis time, in seconds.  Note log scale.  Each abscissae was
    sampled eleven times, discarding the first, in random order.
    Crosses and bars give the mean and 90\% confidence interval of the
    mean, calculated using the central limit theorem.  The solid line
    shows a least squares regression onto $ae^{bN} + c$ over $7 \leq N
    \leq 20$ extrapolated to the full range of $N$; the dashed one
    shows a quartic regression over the same data.  Grey regions give
    90\% confidence intervals for the regression lines, computed using
    a 1,000 replicate bootstrap.  Note that the regressions minimise
    the sum of squares loss, but are plotted on a logarithmic scale.]{
    \biggraph{eval/complex_hb/complex_hb_build_summaries}
    \label{fig:eval:complex_hb:analysis_time}
  }
  \newcommand{\sosttin}{$\in$}
  \subfigure[][Reproduction time, in seconds.  Each abscissae
    sampled 110 times, in random order, with the first ten results
    discarded.  Cross and bars show mean and 90\% confidence interval,
    derived using a 1000 replicate bootstrap.  Without an enforcer,
    the average reproduction time was
    \protect{$13.5 \in [10.7,16.5]_{1000}^{100}$}
    seconds when $N=2$; higher values of
    $N$ had no reproductions at all within ten minutes.]{
    \biggraph{eval/complex_hb/repro_times.tex}
    \label{fig:eval:why:complex_hb_repro}
  }
  \caption{Effect of $N$ on analysis and reproduction times in the
    \bugname{complex\_hb}$_N$ test.}
\end{sanefig}

\autoref{fig:eval:complex_hb:analysis_time} shows how the time taken
when generating \glspl{verificationcondition} varies with
$N$\kern-1pt.  The time taken clearly increases rapidly with
$N$\kern-1pt, and this will limit the complexity of bugs which can be
analysed with {\technique}.  This is not, however, likely to be the
most important limitation to {\technique}'s scalability: most bugs in
real programs require only two or three edges to be
enforced~\cite{Musuvathi2008}, and {\implementation} was able to
analyse a 79-edge one in under ten minutes.

It is perhaps interesting to note that, although very rapid, the rate
of increase is less than exponential.  The solid line in the figure
shows the least-squares exponential regression on the data for $7 \leq
N \leq 20$, extrapolated over the complete range of $N$.  It
significantly over-estimates the rate at which the time taken
increases.  A quartic regression over the same data, shown as a dotted
line in the figure, gives a much closer fit in the extrapolated
region.  This is because, in this particular test, the {\StateMachine}
simplification step is able to make quite dramatic simplifications to
the structure of the {\StateMachines}, and so there is no need to ever
consider all $2^N$ interleavings of the memory accesses.  These
results appear to be robust to small changes in the boundaries of the
training region.

\autoref{fig:eval:why:complex_hb_repro} shows how long the
\glspl{bugenforcer} take to reproduce these bugs.  As can be seen,
this is very quick, taking just $0.337 \in [0.333,0.344]_{1000}^{100}$
seconds to reproduce, on average, to reproduce a happens-before graph
with 80 edges, and this time appears to be roughly linear in the
number of edges.  Without an enforcer, the bug takes at least ten
minutes to reproduce for all values of $N$ greater than 2.  This
suggests that the \glspl{bugenforcer} will be able to reproduce any
happens-before graph which {\implementation} is able to generate.

\subsection{Scalability with respect to memory access complexity}

\begin{sanefig}
  \centerline{
    \fcolorbox{white}{white}{
    \subfigure[][Crashing thread for \bugname{complex\_alias\_hard}$_{L,S}$ test]{
      \begin{minipage}{\textwidth}
        \tt
        \begin{tabbing}
          s$_1$ = rand()\%NR\_PTRS; s$_2$ = rand()\%NR\_PTRS; \ldots; s$_S$ = rand()\%NR\_PTRS; \\
          l$_1$ = rand()\%NR\_PTRS; l$_2$ = rand()\%NR\_PTRS; \ldots; l$_L$ = rand()\%NR\_PTRS; \\
          analysis\_window \clbrace
            slots[s$_1$] = 0; slots[s$_2$] = 1; \ldots; slots[s$_S$] = $S-1$;\\
            assert((slots[l$_1$]+slots[l$_2$]+\ldots+slots[l$_L$]) != $L.(S+1) + 1$);
          \crbrace
        \end{tabbing}
      \end{minipage}
      }
    }
  }
  \vspace{2mm}
  \centerline{
    \fcolorbox{white}{white}{
    \subfigure[][Crashing thread for \bugname{complex\_alias\_easy}$_{L,S}$ test]{
      \begin{minipage}{\textwidth}
        \tt
        \begin{tabbing}
          s$_1$ = rand()\%NR\_PTRS; s$_2$ = rand()\%NR\_PTRS; \ldots; s$_S$ = rand()\%NR\_PTRS; \\
          l$_1$ = rand()\%NR\_PTRS; l$_2$ = rand()\%NR\_PTRS; \ldots; l$_L$ = rand()\%NR\_PTRS; \\
          analysis\_window \clbrace
            slots[s$_1$] = 0; slots[s$_2$] = 1; \ldots; slots[s$_S$] = $S-1$;\\
            assert(slots[l$_1$]!=$S$ \&\& slots[l$_2$]!=$S$ \&\& \ldots~\&\& slots[l$_L$]!=$S$);
          \crbrace
        \end{tabbing}
      \end{minipage}
    }
    }
  }
  \vspace{2mm}
  \centerline{
    \fcolorbox{white}{white}{
    \subfigure[][Interfering thread for both \bugname{complex\_alias\_hard}$_{L,S}$ and \bugname{complex\_alias\_easy}$_{L,S}$ tests]{
      \parbox{14.25cm}{
        {\hfill}
        \begin{minipage}{\textwidth}
          \tt
          \begin{tabbing}
            idx = rand() \% NR\_PTRS; \\
            analysis\_window \clbrace
              slots[idx] = $S+1$;
            \crbrace
          \end{tabbing}
        \end{minipage}
        {\hfill}
      }
    }
    }
  }
  \caption{Test programs for the complex aliasing tests.
    \texttt{NR\_PTRS} is the constant 100.}
  \label{fig:eval:why:complex_aliasing}
\end{sanefig}

\begin{sanefig}
  \subfigure[][\bugname{complex\_alias\_hard}$_{L,S}$]{
    \biggraph{eval/complex_alias/hard}
  }
  \subfigure[][\bugname{complex\_alias\_easy}$_{L,S}$]{
    \biggraph{eval/complex_alias/easy}
  }
  \caption{Time taken to analyse the
    \bugname{complex\_alias\_hard}$_{L,S}$ and
    \bugname{complex\_alias\_easy}$_{L,S}$ tests, for varying values
    of $L$ and $S$, shown as contour maps.  Each configuration was run
    eleven times, in random order, with the first, highest, and lowest
    values discarded.  Lines show contours of the average of the
    remaining eight values and grey regions show the range.
    Configurations which timed out are shown with a cross; those which
    ran out of memory are shown with a circle.  Configurations which
    timed out on some repeats and ran out of memory on others are
    shown with both.  For the purposes of drawing the contours,
    experiments which failed were treated as if they had completed
    precisely at the timeout; cells in which I made that assumption
    are shown in red.}
  \label{fig:eval:why:complex_aliasing:result1}
\end{sanefig}

\noindent
The previous section showed that {\implementation} scales well to
complicated happens-before graphs; this one investigates how well it
scales to complicated memory access patterns.  The two test programs
used, \bugname{complex\_alias\_hard}$_{L,S}$ and
\bugname{complex\_alias\_easy}$_{L,S}$, are shown in
\autoref{fig:eval:why:complex_aliasing}.  In both cases, the
\gls{crashingthread} \gls{analysiswindow} consists of $S$ stores
followed by $L$ loads and a final assertion on the loaded values; the
\gls{interferingthread}, common to both the easy and hard variants,
consists of a single store.  The difference between the two tests lies
in the final assertion: the hard version performs a single test on the
sum of the loaded values, whereas the easy version performs a separate
test on each value and combines the results with the boolean
connective \texttt{\&\&}.  The cost of analysing these test programs
is shown in \autoref{fig:eval:why:complex_aliasing:result1}.

As can be seen, the cost of analysing the \bugname{hard} variant, on
the left of the figure, rises with both $L$ and $S$, with a much
stronger response to $L$ than to $S$.  The analysis becomes
intractable with even a dozen loads.  This reflects the fact that
{\implementation} effectively solves this aliasing problem by brute
force, considering each combination of $S+1$ values of the $L$ loads
for a total of $(S+1)^L$ aliasing patterns.  This is a rapidly growing
function of both $L$ and $S$, and, for the relevant values of its
inputs, grows more rapidly with $L$ than $S$, conveniently explaining
the graph's most obvious qualitative features.\kern-1pt\fnote{This
  model is, however, a poor quantitative fit for the data, as the cost
  of analysing each aliasing pattern is also a function of $L$ and
  $S$.}

The \bugname{easy} variant, on the right, behaves similarly for small
values of $L$ but exhibits much better scaling behaviour as $L$
increases.  This is because the final tests factorises neatly into $L$
single-load tests, rather than a single $L$-load one, and so
{\implementation}'s lazy aliasing resolution (see
\autoref{sect:derive:symbolic_execute}) can process each load
independently in turn, reducing the number of aliasing patterns which
must be considered to $(S+1).L$.  This factorisation allows
{\implementation} to process hundreds of loads in reasonable time.

This behaviour is clearly more useful than always exhibiting the
unfactorised, exponentially poor, performance, but is also difficult
to characterise crisply.  Sometimes {\implementation} will struggle
with bugs which depend on even a dozen memory loads; at other times,
it will be able to process hundred-load bugs with little difficulty.
Practical results are likely to fall somewhere between these two
extremes.

\subsection{Scalability with respect to \glsentrytext{alpha}}

\input{eval/alpha/alpha.ttex}

\noindent
Previous sections have investigated scalability with respect to some
measures of the complexity of the fragment of program present in the
\gls{analysiswindow}.  This section investigates scalability with
respect to the raw size of the \gls{analysiswindow}.  To do so, I
selected 1000 instructions at random from MySQL and analysed each at
varying values of \gls{alpha}, recording the time taken by the various
analysis phases.  The results are shown in \autoref{fig:eval:alpha}.
For these experiments, I increased the timeout from five to ten
minutes, as that is more appropriate at higher values of \gls{alpha}.
These experiments were conducted on the same Opteron 6168 as those
reported in \autoref{sect:how:finding_unknown}, and, as in those
previous experiments, {\implementation} was configured to analyse ten
potentially-crashing instructions at a time.  Unlike the previous
experiments, here {\implementation} was configured to re-run any steps
which ran out of memory in isolation once the parallel phase had
finished, so as to avoid artifacts caused by contending to allocate
memory at high values of \gls{alpha}.  Steps which timed out were not
re-run, as each thread had a dedicated CPU core and so there was
little contention for CPU time.

The first chart, \autoref{fig:eval:alpha:time_per_crashing}, shows how
long each potentially-crashing instruction spends in phase \subcrash{}
of the analysis, excluding failures, and how that varies with
\gls{alpha}.  The probability density functions were estimated in the
same way as those in \autoref{fig:eval:how:per_crashing_times}, except
that a censoring correction was applied near the 600 second timeout.
As usual, the grey region gives a 90\% confidence interval computed
with a 1000 replicate bootstrap.  The second chart,
\autoref{fig:eval:alpha:time_per_interfering}, shows the time which
each interfering \gls{cfg} required in the \subinterfering{} phase in
the same style.  The failures encountered during these experiments are
summarised in \autoref{fig:eval:alpha:failures}.

The overall pattern in these charts is broadly as expected: the time
taken increases rapidly with \gls{alpha}, leading to an unpleasant
increase in the failure rate.  These results suggest that {\technique}
is unlikely to be a practical method of finding unknown bugs for
values of \gls{alpha} above about 50, for this combination of hardware
and program to be analysed, and that it will be of dubious
effectiveness even for analysing known bugs.  The experiments with
smaller values of \gls{alpha} showed a noticeably lower failure rate
and completed far more quickly, and so those configurations would
probably be more useful.

The fourth chart, \autoref{fig:eval:alpha:interfering_per_crashing},
shows the number of interfering \glspl{cfg} generated for each
potentially-crashing instruction.  As can be see, this rises rapidly
with increasing values of \gls{alpha} until \gls{alpha} reaches 40, at
which point it begins to fall again.  The initial rise is easily
explained, and simply reflects the fact that with more instructions
there is more scope for the \gls{crashingthread} to race.  The fall at
higher values of \gls{alpha} is a survivor effect caused by failures
in the per-crashing instruction phase of the analysis.  The more
memory accesses a crashing {\StateMachine} has, the more interfering
\glspl{cfg} it will generate, but the more likely it is to fail, and
beyond $\gls{alpha}=40$ the increased failure rate outweighs the
increased number of interfering \glspl{cfg}.

The final chart, \autoref{fig:eval:alpha:vcs_per_interfering}, shows
the proportion of interfering \glspl{cfg} which generate
\glspl{verificationcondition} requiring run-time validation.  It shows
a similar pattern to the number of interfering \glspl{cfg} per
crashing instruction: an initial rise, reflecting an increase in the
complexity of the {\StateMachines}, followed by a fall for higher
values of \gls{alpha} as survivor effects begin to dominate.

\section{Discussion}

This evaluation has demonstrated several important properties of
{\technique}:
\begin{itemize}
\item It is able to quickly reproduce and fix bugs in both artificial
  and real test programs, and the generated fixes have low enough
  overhead to be useful in practice.
\item It is able to find at least some bugs in real programs.
\item It exhibits reasonable scalability as the complexity of the
  bugs and programs to be analysed increases.
\end{itemize}
It therefore satisfies the original design goals discussed in
\autoref{sect:intro:overview}.

The chief weakness of the evaluation is that it considers only a small
number of bugs in real programs, and those bugs were themselves
selected because they interact well with {\technique}.  It is hard to
say how these results would generalise to other programs and bugs.
The problem here is fundamentally that the class of bugs considered by
{\technique} is quite small: not only must the program crash in a
detectable way, but it must do so within a few dozen instructions.
Such bugs are a small subset of the already-small set of all
concurrency bugs, and I have been unable to find enough in real
programs to form the basis of a truly convincing evaluation.

Nevertheless, this evaluation has shown that it is possible to find,
reproduce, and fix concurrency bugs in large-scale multithreaded
software given only the program binary and some minimal information on
its memory allocation pattern, and that the generated fixes are
themselves reasonably efficient.  This represents a useful advance
over the state of the art; previous systems either required far more
information about the program (such as AutoPag~\cite{Lin2007} and
ConTest~\cite{FFFKrena2007}), or had very high overhead without exotic
hardware (such as Atom-Aid~\cite{Lucia2009} or AVIO~\cite{Lu}), or
targeted a more restricted class of bugs (such as
Kivati~\cite{Chew2010} or ToleRace~\cite{Kirovski2007}).  I expand on
these comparisons in the next chapter.
