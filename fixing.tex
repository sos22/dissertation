\chapter{Fixing bugs}
\label{sect:fix_global_lock}

In addition to finding bugs, {\technique} can also be used to fix them
by introducing a new global lock.  This ensures that the instructions
involved in the thread \glspl{cfg} cannot execute in parallel,
preventing the bug from happening.  This chapter describes how this is
done in detail.

\section{Identifying the instructions which must be protected}

\begin{figure}
  \hspace{-5mm}\subfigure[][\gls{crashingthread}]{
    \texttt{
      \begin{tabular}{lll}
        1 & \multicolumn{2}{l}{ptr = complicated\_local\_condition();}\\
        2 & \multicolumn{2}{l}{dptr = *ptr;}\\
        3 & \multicolumn{2}{l}{if (dptr != NULL) \{}\\
        4 & &dptr = *ptr1;\\
        5 & &*dptr = 5;\\
        6 & \multicolumn{2}{l}{\}}\\
      \end{tabular}
    }
  }
  \hspace{-10mm}\subfigure[][\Gls{interferingthread}]{
    \texttt{
      \begin{tabular}{ll}
        \\
        \\
        7 & ptr = complicated\_local\_condition();\\
        8 & *ptr = NULL;\\
        \\
        \\
      \end{tabular}
    }
  }
  \caption{An example bug}
  \label{fig:fix_bug:complex_local}
\end{figure}

The first step in producing such a fix is determining which parts of
the dynamic \glspl{cfg} are to be included in the critical sections.
In principle, it is sufficient to use the entire dynamic \gls{cfg} for
both threads: the analysis of \autoref{sect:derive} will only report
atomicity violation bugs, and so making both threads execute
atomically will always eliminate reported bugs.  This is not always a
good choice, though.  Consider, for instance, the threads in
\autoref{fig:fix_bug:complex_local}.  In this example, the
\gls{crashingthread} will crash if statement \texttt{8} intercedes
between statements \texttt{2} and \texttt{4}, and so a reasonable
strategy for fixing this bug would be to make statements \texttt{2},
\texttt{3}, and \texttt{4} execute atomically with respect to
statement \texttt{8}.  The dynamic \glspl{cfg} will include those
instructions, and so would correctly fix the bug, but are also likely
to include at least a suffix of
\texttt{complicated\_local\_condition()}, if not the entire function,
and will therefore protect more than necessary. This will lead to a
higher than necessary loss of concurrency, and hence potentially
higher than necessary performance overhead.

\todo{Not the best bit of writing I've ever done.} The
\gls{verificationcondition} provides the information necessary to
avoid this problem.  As discussed in \autoref{sect:derive}, the
\gls{verificationcondition} includes all of the conditions on
instruction interleaving which influence whether the bug will
reproduce.  Any instruction not mentioned in a happens-before test
$\happensBeforeEdge$ cannot be involved in a race which might cause a
crash, and hence can be omitted from the atomic regions.  It is
therefore sufficient to restrict the protected regions to contain only
paths which start and end with instructions which are mentioned in
$\happensBeforeEdge$ tests.  This eliminates
\texttt{complicated\_local\_condition()} from the critical sections
while leaving statements \texttt{2}, \texttt{3}, \texttt{4}, and
\texttt{8} protected, as desired.

\begin{figure}
  \centerline{
    \texttt{
      \begin{tabular}{l}
        ptr = complicated\_local\_calculation();\\
        *ptr = NULL;\\
        *ptr = NULL;\\
      \end{tabular}
    }
  }
  \caption{A slightly extended version of
    \autoref{fig:fix_bug:complex_local}'s
    \texttt{interfering\_thread}.}
  \label{fig:fix_bug:complex_local2}
\end{figure}

Note that this is not guaranteed to produce an optimal selection of
critical sections, in the sense that sections can sometimes be larger
than is strictly necessary.  Consider, for example, a program with the
same crashing thread as the previous example but an interfering thread
in which the pointer is assigned to twice, as shown in
\autoref{fig:fix_bug:complex_local2}.  There are two obvious ways of
protecting this program:

\begin{itemize}
\item
  Place both loads in the crashing thread in a single critical section and
  both stores in the interfering thread in another one.
\item
  Place both loads in the crashing side in a single critical section,
  but give each store in the interfering thread its own critical
  section.  In other words, drop and re-acquire the lock in between
  the two stores.
\end{itemize}

Both approaches correctly eliminate the bug, but they will have
different performance characteristics.  In particular, dropping and
re-acquiring the lock reduces the size of the critical section, which
might improve concurrency and reduce starvation, but imposes higher
overheads due to the greater number of lock operations.  {\Technique}
uses a simple rule to decide which strategy to use: if the operations
are within \gls{alpha} instructions then it uses a single critical
section and if they are further apart then it uses two.  This is the
simplest approach to implement, as it matches the clustering rules
used in \autoref{sect:derive:write_side}, and generally produces
results which at least appear reasonable.

\label{sect:fixing:rw_afix}
This algorithm is quite similar to that used in
AFix\cite{Jin2011}\footnote{But note that the present author
  implemented that part of {\implementation} in June 2010, before AFix
  was published.}.  There are, however, several differences between
them.  Most obviously, the AFix algorithm considers only simple
two-access critical sections, whereas this algorithm can enforce more
complex $n$-access ones.  Even where there are precisely two accesses
to be protected the set of instructions in the critical section can
differ slightly, because {\technique} will exit the critical section
if the thread leaves the \gls{cfg} in the {\StateMachine}, whereas
AFix exits if the thread cannot reach another protected instruction in
the current function invocation.  This can be either an advantage or a
disadvantage, depending on why an instruction is missing from the
{\StateMachine} \gls{cfg}.  Some instructions will be missing because
they were cut off by the \gls{alpha} limit on the
\gls{analysiswindow}; releasing the lock for these instructions is
usually undesirable, as it re-introduces some of the concurrent
interleavings which the patch was supposed to eliminate.  Other
instructions will be missing because an earlier analysis phase has
shown that the program cannot suffer the bug if it follows that path;
releasing the lock here is safe, and can sometimes lead to better
parallelism and liveness behaviour.

\section{The interpreter}

The conceptually simplest way of introducing these synchronisation
operations is by modifying a hypothetical machine code interpreter so
that it performs the necessary synchronisation operations as the
program runs, and I describe such an approach in this section.  This
is effective, but has extremely high overhead, due to the need to run
the entire program under an interpreter.  Later sections will show how
to reduce this overhead, first by allowing the unprotected components
of the program to run without the interpreter and then by dispensing
with the interpreter completely.

\todo{Linkage} The interpreter's task is to emulate the original
program's machine code without ever allowing two threads to enter
atomic regions at the same time.  These regions are defined in terms
of the dynamic \gls{cfg}, and so the interpreter must manage the
mapping between dynamic \gls{cfg} nodes and the program's static
\gls{cfg}.  Even when the mapping between the two \glspl{cfg} is
unambiguous, the protected regions might overlap, and the interpreter
must ensure that no thread ever self-deadlocks by acquiring the lock
twice.  The solution to these problems is similar to that used by
enforcers: rather than trying to track a thread's current \gls{cfg}
node, the interpreter tracks a set of possible current \gls{cfg}
nodes; rather than acquiring or releasing the lock as threads enter or
leave the \gls{cfg}, the interpreter acquires or releases the lock as
this set becomes non-empty or empty.

\begin{figure}
  \begin{displaymath}
    \begin{array}{llll}
      \textsc{InterpreterState} = & (\mathit{active}: &\textsc{Set}(\textsc{CfgNode}), &\\
      & \,\,\mathit{holdLock}: &\textsc{Bool},\\
      & \,\,\mathit{phase}: & \{\mathbf{CheckForEntry}, \mathbf{Lock}, \\
      &                     & \,\,\,\mathbf{Emul}, \mathbf{Succ}, \mathbf{Unlock}\} &\!\!\!)\\
    \end{array}
  \end{displaymath}
  \caption{\textsc{InterpreterState} type, the state maintained by the
    interpreter.}
  \label{fig:fix_bugs:interpreter_state}
\end{figure}

The interpreter cycles repeatedly through these phases:
\begin{itemize}
\item \textbf{CheckForEntry} The interpreter checks whether the
  current instruction is the entry point of any protected \gls{cfg}
  fragments.  If it is, the relevant \gls{cfg} node is added to the
  current set of active \gls{cfg} nodes.

\item \textbf{Lock} The interpreter now acquires the patch lock, with
  a timeout, provided that it does not currently own it and the set of
  active \gls{cfg} nodes is non-empty.  If the lock times out then the
  interpreter gives up and proceeds without acquiring the lock; this
  introduces a risk of the bug reproducing, but is necessary to avoid
  any potential deadlocks with the program's own synchronisation
  strategy.

\item \textbf{Emul} The interpreter runs the instruction from the
  original program, performing any necessary memory accesses or
  register updates.  This is essentially the same as the phase of the
  same name in the enforcer's LLI loop (see \autoref{sect:enforce:llis}).

\item \textbf{Succ} The \textbf{Emul} phase will have computed the
  instruction pointer of the next instruction to be executed.  This
  can then be compared to the set of currently active \gls{cfg} nodes
  and the protected \gls{cfg} fragments to calculate a new set of
  active \gls{cfg} nodes.  Again, this is analogous to the phase of
  the same name in the enforcer's LLI loop.

\item \textbf{Unlock} Finally, the interpreter can now consider
  releasing the patch lock.  It does so if it currently holds the lock
  and the set of active \gls{cfg} nodes has become empty.  The instruction
  cycle then restarts at \textbf{CheckForEntry}.
\end{itemize}
This scheme ensures that the lock is always held when instructions
from the original program execute if there is any possibility that the
thread is currently executing one of the \gls{cfg} fragments.  At the
same time, it correctly ensures that the lock is never double-acquired
or double-released.  It therefore correctly implements the desired
fix, but at the expense of very high overhead due to running the
entire program in an interpreter.

\section{Running unprotected code without an interpreter}

The common case is that the fix protects a very small fraction of the
total instructions in the program, and so running the entire program
in an interpreter is extremely inefficient.  Fortunately, it is also
easy to fix, using the scheme described in
\autoref{sect:enforce:gain_control}.  The patch strategy algorithm can
arrange to jump to the interpreter whenever the program reaches any
entry point of a protected \gls{cfg} fragment, starting in the
\textbf{CheckForEntry} state with a $\mathit{active} = \varnothing$
and $\mathit{holdLock} = \false$.  The only change needed to the
interpreter itself is the addition of a \textbf{Return} state between
\textbf{CheckForEntry} and \textbf{Lock} which branches back to the
original program if $\mathit{active} = \varnothing$,
$\mathit{holdLock} = \false$, and the current instruction is not in
$\mathit{Cont}$.

\section{Recompiling the protected code with additional synchronisation}

This scheme allows the program to run at native speed when executing
code which does not have to be protected, but still requires it to be
interpreted when in the critical sections.  This can sometimes be an
issue if the bug to be fixed is a rare one in code which is executed
very frequently.  The remaining overhead can be (almost) eliminated
by, in effect, converting the interpreter into a compiler, producing a
new version of the program which has all of the desired
synchronisation and which runs very nearly as fast as the original.

The main complication in building such a compiler is that the compiled
fix has no good way of storing its state: registers and the stack are
unavailable, as they are used by the program to be protected; main
memory does not work, because most of the state needs to be
thread-local; and anything based on system calls is undesirable
because the state needs to be accessed so frequently, sometimes
multiple times per instruction.  The approach taken by
{\implementation} is to encode the per-thread state into the program's
instruction pointer, creating a duplicate of each program instruction
for each \textsc{InterpreterState} which that program instruction
might execute in.  This is practical because the number of
\textsc{InterpreterState}s per program instruction is usually very
small, often just one, and so the number of duplicates is manageable.

One major advantage of this instruction duplication approach is that
the compiler knows, when emitting an instruction, precisely what state
the interpreter is in, and so even a quite simplistic implementation
can still generate reasonably efficient machine code for the
interpreter operations.  Further, most instructions in the original
program can be copied across without modification, and so most
compiler optimisations applied to the original program continue to be
effective in the patched version.

One way of thinking about this is to say that the program's
instruction pointer is replaced with a more complicated structure
containing both the original pointer and the \textsc{InterpreterState}
structure.  The interpreter described above shows how the original
program's \gls{cfg} can be combined with the fix plan to give a new
\gls{cfg} expressed in terms of these extended instruction pointers,
and the compiler then lowers this extended \gls{cfg} back into
ordinary machine code.  The lowering process itself is easiest to
think about as a kind of partial evaluation\cite{Jones1993} or
supercompilation\cite{Sorensen2008} of the interpreter, fixing the
program machine code and the intended synchronisation while leaving
the program's inputs unspecified.

\begin{itemize}
\item \textbf{Lock} phases partially evaluate to either the machine
  code for a lock operation (if the lock is not currently held and the
  set of active \gls{cfg} nodes is non-empty) or a no-op (otherwise).

\item \textbf{Unlock} phases likewise evaluate to either the machine
  code for an unlock operation or a no-op.
\item \textbf{Return} partially evaluates to either a no-op (usually)
  or a branch back to the original program (if the set of active
  \gls{cfg} nodes is empty and the current instruction pointer is not
  in the $\mathit{Cont}$ set).

\item \textbf{CheckForEntry} evaluates to a fragment of machine code
  which compares the current instruction pointer and stack to those
  present in the entry points of the various \gls{cfg} fragments which
  are to be protected, branching to an appropriate
  \textsc{InterpreterState} if one matches.  In many cases the
  information in the current \textsc{InterpreterState} will be
  sufficient to determine where all of these branches will go, in
  which case the resulting machine code fragment will be empty.

\item \textbf{Emul} and \textbf{Succ} will usually partially evaluate
  to the program's original instruction, which can be emitted
  unchanged into the final patch.  The two exceptions are instruction
  pointer-relative addressing modes, which must be re-encoded to still
  refer to the same data after moving the instruction, and control
  flow transfer instructions, which are discussed below.
\end{itemize}
The result of partially evaluating the nodes in the extended \gls{cfg}
is a set of fragments of machine code which can be stitched together
and combined with the \textsc{PatchStrategy} to form a complete fix.

Control flow instructions require special handling in this model.
Most program instructions can be copied verbatim into the generated
fix as part of the \textbf{Emul} phase, but copying a control flow
transfer would cause the patch to lose control of the program's
execution, with undesirable results.

Direct branch instructions, which set the instruction pointer to a
constant value, are simple to handle.  In the interpreter, they are
implemented by updating the $\mathit{active}$ set to reflect the
thread's new potential locations in the dynamic \gls{cfg}, and, since
the target of the branch is a constant, the same approach can be used
in the compiler.  The only difference is that updating
$\mathit{active}$ now means emitting a branch to an appropriate
\textsc{InterpreterState}.

Direct call instructions, which jump to a function at a constant
address after pushing a return address, require only slightly more
care.  In the common case, where the called function is part of the
main program binary, these can be treated as a push followed by an
ordinary direct branch, reducing the problem to the previous case.
Calls to library functions, such as \texttt{malloc} or
\texttt{printf}, are more problematic.  The fix generation process has
two options for handling these, both bad:
\begin{itemize}
\item It could call into the library function whilst holding the lock.
  This ensures that the desired atomic blocks behave atomically, but
  at the cost of a significant risk of deadlocks if the called
  function is something like \texttt{pthread\_mutex\_lock}.
\item It could release the lock while calling into the library
  function.  This is much less likely to deadlock, but also much
  less likely to correctly eliminate the bug.
\end{itemize}
{\Implementation} always chooses to hold the lock when calling library
functions from a patch and relies on the \textbf{Lock} timeout to
mitigate the damage from deadlocks.  These timeouts might themselves
lead to incomplete protection, but generally happen far less
frequently than library calls, and so present a far less severe
problem\footnote{Note that library calls are not the only possible
  cause of deadlocks here, as the program might implement its own
  synchronisation primitives\cite{Jannesari2010}, and so the timeout
  would still be necessary even if the patch lock were dropped during
  library calls.}.

Indirect control flow transfers, which set the instruction pointer to
a computed value, form the final class of instructions requiring
special handling.  They are difficult to handle in the compiler as the
target is not available at compile time, and the compiler must emit
code to perform appropriate runtime checks, along with the code for
all of the needed \textsc{InterpreterState}s.  I describe here how to
handle simple indirect jumps; generalising to indirect calls and
return instructions is straightforwards.

It is worthwhile considering again what the interpreter does when
confronted with an indirect jump (generalising to indirect calls and
return instructions is straightforward).  There are three cases to
consider.  Most simply, there might be an edge in the \gls{cfg}
matching the desired control flow transfer, in which case the
interpreter just updates $\mathit{active}$ and continues.
Alternatively, there might not be such an edge, in which case the
interpreter will set $\mathit{active}$ to $\varnothing$ and release
the lock.  It will then either continue interpreting, if the current
instruction is in $\mathit{Cont}$, or return to the original program,
otherwise.  Importantly, there are a finite (and usually small) number
of possible targets of the branch which will cause the interpreter to
continue interpreting, and so the compiler can just emit a conditional
branch to an appropriate \textsc{InterpreterState} for each of them
and a single indirect branch for the remaining case where the
interpreter exits\footnote{There is a slight complication here that
  the calculation of the target address might involve a load from
  memory, and hence might suffer a race, and the compiler must be
  careful not to drop the lock prematurely if that happens.
  {\Implementation}'s patches correctly avoid this issue.}.
