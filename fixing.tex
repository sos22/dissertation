\chapter{Fixing bugs}
\label{sect:fix_global_lock}

In addition to finding bugs, {\technique} can also be used to fix
them.  The basic approach here is to binary patch the program to
introduce a new global lock covering the program's relevant
instructions, preventing them from executing in parallel and hence
preventing the bug from occurring.  The relevant instructions are
duplicated into a binary patch, unrolling loops and tracing across
function boundaries in a way which reflects the function inlining and
loop unrolling performed during the initial dynamic \gls{cfg}
generation phase, and the duplicates modified to acquire and release
the lock at appropriate points.  The original program is then patched
to branch to the duplicates when necessary.

\section{Identifying the instructions which must be protected}

\begin{figure}
  \hspace{-5mm}\subfigure[][\texttt{crashing\_thread}]{
    \texttt{
      \begin{tabular}{ll}
        \multicolumn{2}{l}{ptr = complicated\_local\_calculation();}\\
        \multicolumn{2}{l}{dptr = *ptr;}\\
        \multicolumn{2}{l}{if (dptr != NULL) \{}\\
        &dptr = *ptr;\\
        &*dptr = 5;\\
        \multicolumn{2}{l}{\}}\\
      \end{tabular}
    }
  }
  \hspace{-10mm}\subfigure[][\texttt{interfering\_thread}]{
    \texttt{
      \begin{tabular}{l}
        \\
        \\
        ptr = complicated\_local\_calculation();\\
        *ptr = NULL;\\
        \\
        \\
      \end{tabular}
    }
  }
  \caption{An example bug}
  \label{fig:fix_bug:complex_local}
\end{figure}

The first step in producing such a fix is correctly identifying the
instructions which must be included in the critical sections.  These
will be a subset of the instructions involved in the dynamic
\gls{cfg}.  As an example, consider the threads illustrated in
\autoref{fig:fix_bug:complex_local}.  Here, the crashing thread
computes some pointer using entirely local operations, loads from it
once and then, if the result is non-\texttt{NULL}, loads from it again
and uses the resulting pointer.  Meanwhile, the interfering thread
sets a potentially coincident memory location to \texttt{NULL}.  The
crashing thread clearly has a potential time-of-check, time-of-use
race bug.  The {\StateMachines} generated by {\technique} will include
the buggy code itself but might also include part or all of
\texttt{complicated\_local\_calculation()} and a side-condition which
requires the two pointers to match up.  This extra information is
useful when analysing the bug (\autoref{sect:using:check_realness}) or
when attempting to reproduce it (\autoref{sect:reproducing_bugs}), but
cannot be used by this kind of instruction-level fix, so including it
in the fix is unhelpful and would tend to lead to unnecessarily large
critical sections.  The fix generating process must therefore select a
useful subset of the instructions in the control-flow graph.

The approach taken here is simple:

\begin{itemize}
\item
  Extract all of the happens-before edges from the bug summary's
  verification condition.  These entirely capture the
  instruction-interleaving parts of the bug to be fixed, and, since
  instruction-interleaving is the only thing which can be influenced
  by inserting locks, the resulting set of edges contains all of the
  useful information in the condition.
\item
  Identify all of the \gls{cfg} nodes which are mentioned in one of those
  happens-before edges.
\item
  Trim the \gls{cfg} such that every path starts and ends in one of those
  mentioned nodes.  All such paths will be included in a critical
  section, and no such paths will be permitted to execute in parallel.
\end{itemize}

In this way the \gls{cfg} is restricted to just those instructions which are
involved in the interleaving which is to be prevented.

\begin{figure}
  \centerline{
    \texttt{
      \begin{tabular}{l}
        ptr = complicated\_local\_calculation();\\
        *ptr = NULL;\\
        *ptr = NULL;\\
      \end{tabular}
    }
  }
  \caption{A slightly extended version of
    \autoref{fig:fix_bug:complex_local}'s
    \texttt{interfering\_thread}.}
  \label{fig:fix_bug:complex_local2}
\end{figure}

Note that this is not guaranteed to produce an optimal selection of
critical sections, in the sense that sections can sometimes be larger
than is strictly necessary.  Consider, for example, a program with the
same crashing thread as the previous example but an interfering thread
in which the pointer is assigned to twice, as shown in
\autoref{fig:fix_bug:complex_local2}.  There are two obvious ways of
protecting this program:

\begin{itemize}
\item
  Place both loads in the crashing thread in a single critical section and
  both stores in the interfering thread in another one.
\item
  Place both loads in the crashing side in a single critical section,
  but give each store in the interfering thread its own critical
  section.  In other words, drop and re-acquire the lock in between
  the two stores.
\end{itemize}

Both approaches correctly eliminate the bug, but they will have
different performance characteristics.  In particular, dropping and
re-acquiring the lock reduces the size of the critical section, which
might improve concurrency and reduce starvation, but imposes higher
overheads due to the greater number of lock operations.  In principle
the verification condition contains enough information to determine
whether dropping the lock is safe, but {\technique} does not make use
of this information, and always uses the former strategy.

\label{sect:fixing:rw_afix}
This algorithm is quite similar to that used in
AFix\cite{Jin2011}\footnote{But note that the present author
  implemented that part of {\implementation} in June 2010, before AFix
  was published.}.  There are, however, several differences between
them.  Most obviously, the AFix algorithm considers only simple
two-access critical sections, whereas this algorithm can enforce more
complex $n$-access ones.  Even where there are precisely two accesses
to be protected the set of instructions in the critical section can
differ slightly, because {\technique} will exit the critical section
if the thread leaves the \gls{cfg} in the {\StateMachine}, whereas
AFix exits if the thread cannot reach another protected instruction in
the current function invocation.  This is sometimes an advantage and
sometimes a disadvantage, depending on why an instruction is missing
from the {\StateMachine} \gls{cfg}.  Some instructions will be missing
because they were cut off by the \gls{alpha} limit on the
\gls{analysiswindow}; releasing the lock for these instructions is
usually undesirable, as it re-introduces some of the concurrent
interleavings which the patch was supposed to eliminate.  Other
instructions will be missing because an earlier analysis phase has
shown that the program cannot suffer the bug if it follows that path;
releasing the lock here is safe, and can sometimes lead to better
parallelism and liveness behaviour.

\section{The interpreter}

The conceptually simplest way of introducing these synchronisation
operations is by modifying a machine code interpreter so that it
performs the necessary synchronisation operations as the program run,
and I describe such an approach in this section.  This is effective,
but has extremely high overhead, due to the need to run the entire
program under an interpreter.  Later sections will show to reduce this
overhead, first by allowing the unprotected components of the program
to run without the interpreter and then by dispensing with the
interpreter completely.

\todo{Linkage} The goal of the interpreter is to emulate the original
program's machine code in a way which ensures that if one thread
enters a protected region then no other thread is able to enter a
protected region until the original thread has left its protected
region.  As with the happens-before edges of an enforcer, these
regions are defined in terms of the dynamic \gls{cfg}, which might not
match up with program's static \gls{cfg}, and the interpreter must
still maintain the protected regions correctly even when its position
in the \gls{cfg} is ambiguous.  Even when the mapping between the two
\glspl{cfg} is unambiguous, the protected regions might overlap, and
the interpreter must then ensure that no thread ever self-deadlocks by
acquiring the lock twice.  The solution to these problems is similar
to that used by enforcers: the interpreter keeps track of the set of
\gls{cfg} nodes which each thread might potentially be executing and
acquires the lock whenever this set goes from empty to non-empty and
releases it whenever it goes from non-empty to empty.

\begin{figure}
  \begin{displaymath}
    \begin{array}{llll}
      \textsc{InterpreterState} = & (\mathit{active}: &\textsc{Set}(\textsc{CfgNode}), &\\
      & \,\,\mathit{holdLock}: &\textsc{Bool},\\
      & \,\,\mathit{phase}: & \{\mathbf{CheckForEntry}, \mathbf{Lock}, \\
      &                     & \,\,\,\mathbf{Emul}, \mathbf{Succ}, \mathbf{Unlock}\} &\!\!\!)\\
    \end{array}
  \end{displaymath}
  \caption{\textsc{InterpreterState} type, the state maintained by the
    interpreter.}
  \label{fig:fix_bugs:interpreter_state}
\end{figure}

When running, the interpreter cycles repeatedly through these phases:

\begin{itemize}
\item \textbf{CheckForEntry} The interpreter checks whether the
  current instruction is the entry point of any other \gls{cfg}
  fragments.  If it is, the relevant \gls{cfg} node is added to the
  current set of active \gls{cfg} nodes.  Note that this potentially
  involves checking the thread's function call stack in addition to
  its current instruction pointer, due to the way that both
  {\StateMachines} and fixes can cross function boundaries.

\item \textbf{Lock} The interpreter now acquires the patch lock, with
  a timeout, provided that it does not currently own it and the set of
  active \gls{cfg} nodes is non-empty.  If the lock times out then the
  interpreter gives up on trying to protect the program; this
  introduces a risk of the bug reproducing, but is necessary to avoid
  any potential deadlocks with the program's own synchronisation
  strategy.

\item \textbf{Emul} The interpreter runs the instruction from the
  original program, performing any necessary memory accesses or
  register updates.  This is essentially the same as the phase of the
  same name in the enforcer's LLI loop (see \autoref{sect:enforce:llis}).

\item \textbf{Succ} The \textbf{Emul} phase will have computed the
  instruction pointer of the next instruction to be executed.  This
  can then be compared to the set of currently active \gls{cfg} nodes and to
  the \gls{cfg} fragment which is to be protected to calculate a new set of
  active \gls{cfg} nodes.  Again, this is analogous to the phase of the same
  name in the enforcer's LLI loop.

\item \textbf{Unlock} Finally, the interpreter can now consider
  releasing the patch lock.  It does so if it currently holds the lock
  and the set of active \gls{cfg} nodes has become empty.  The instruction
  cycle then restarts at \textbf{CheckForEntry}.
\end{itemize}

This scheme ensures that the lock is always held when instructions
from the original program execute if there is any possibility that the
thread is currently executing one of the \gls{cfg} fragments.  At the same
time, it correctly ensures that the lock is never double-acquired or
double-released.  It therefore correctly implements the desired fix,
but at the expense of potentially very high overhead.

\section{Running unprotected code without an interpreter}

The most important source of undesired overhead in this scheme is that
the entire program must run in the interpreter, even the parts which
are not protected by the fix.  The common case is that the fix
protects a very small fraction of the total instructions in the
program, and so this is extremely inefficient.  Fortunately, it is
also reasonably easy to fix.  \autoref{sect:enforce:gain_control} has
already described a scheme for binary patching a program to gain
control at a defined set of instructions, and this can be used
unmodified here.  The patch strategy will arrange to branch to the
interpreter whenever a thread enters a protected \gls{cfg} fragment,
starting it at the \textbf{CheckForEntry} phase with an empty set of
\gls{cfg} nodes and not holding the lock.  The interpreter will also
gain an additional \textbf{Return} phase between the existing
\textbf{CheckForEntry} and \textbf{Lock} phases which transfers
control from the interpreter back to the original program if the
active \gls{cfg} node set has become empty and the program is not
currently executing a $\mathit{Cont}$ instruction.

One possibly surprising property of this design is that, even with
this refinement, the interpreter can still sometimes run while not
holding the lock if the program is executing $\mathit{Cont}$
instructions.  An alternative approach would be to simply acquire the
lock when the interpreter starts running and release it when the
interpreter exits.  This would be a valid approach, and would perhaps
result in a very slightly simpler implementation, but at the expense
of enlarging the size of the critical sections slightly.  In practice
this choice very rarely makes any meaningful difference.  The main
exception occurs if protecting the $\mathit{Cont}$ set would cause the
critical section to span an entire loop rather than just a single
iteration of it, which could potentially aggravate the liveness and
fairness issues which are inherent to any lock-based scheme.

\section{Recompiling the protected code with additional synchronisation}

This scheme allows the program to run at native speed when executing
code which does not have to be protected, but still requires it to be
interpreted when in the critical sections.  This can sometimes be an
issue if the bug to be fixed is a rare one in code which is executed
very frequently.  {\Implementation} includes a mechanism to recompile
the protected code back into machine code with the necessary
additional synchronisation added, completely eliminating the run-time
interpreter and hence removing most of the overhead of the fix.

The main complication here is that the compiled fix has no good way of
storing its state: registers and the stack are unavailable, as they
are used by the program to be protected; main memory does not work,
because most of the state needs to be thread-local; and anything based
on system calls is undesirable because the state needs to be accessed
so frequently, sometimes multiple times per instruction.  The approach
taken by {\implementation} is to encode the per-thread state into the
program's instruction pointer, creating a duplicate of each program
instruction for each interpreter state which that program instruction
might execute in.  This is practical because the number of interpreter
states per program instruction is usually very small, often just one,
and so the number of duplicates is manageable.

One major advantage of this instruction duplication approach is that
the partial evaluator knows, when emitting an instruction, precisely
what state the interpreter is in, and so even a quite simplistic
implementation can still generate reasonably efficient machine code
for the interpreter operations.  Further, most instructions in the
original program can be copied across without modification, and so
most compiler optimisations applied to the original program continue
to be effective in the patched version.

One way of thinking about this is to say that the program's
instruction pointer is replaced with a more complicated structure
containing both the original pointer and the \textsc{InterpreterState}
structure described in Figure~\ref{fig:fix_bugs:interpreter_state}.
The interpreter described above shows how the original program's
\gls{cfg} can be combined with the fix plan to give a new \gls{cfg}
expressed in terms of these extended instruction pointers, and the
compiler then lowers this extended \gls{cfg} back into ordinary
machine code.  The lowering process itself is easiest to think about
as a kind of partial evaluation\cite{Jones1993} or
supercompilation\cite{Sorensen2008} of the interpreter, fixing the
program machine code and the intended synchronisation while leaving
the program's inputs unspecified.

\begin{itemize}
\item \textbf{Lock} phases partially evaluate to either the machine
  code for a lock operation (if the lock is not currently held and the
  set of active \gls{cfg} nodes is non-empty) or a no-op (otherwise).

\item \textbf{Unlock} phases likewise evaluate to either the machine
  code for an unlock operation or a no-op.
\item \textbf{Return} partially evaluates to either a no-op (usually)
  or a branch back to the original program (if the set of active
  \gls{cfg} nodes is empty and the current instruction pointer is not
  in the $\mathit{Cont}$ set).

\item \textbf{CheckForEntry} evaluates to a fragment of machine code
  which compares the current instruction pointer and stack to those
  present in the entry points of the various \gls{cfg} fragments which
  are to be protected, branching to an appropriate
  \textsc{InterpreterState} if one matches.  In many cases the
  information in the current \textsc{InterpreterState} will be
  sufficient to determine where all of these branches will go, in
  which case the resulting machine code fragment will be empty.

\item \textbf{Emul} and \textbf{Succ} will usually partially evaluate
  to the program's original instruction, which can be emitted
  unchanged into the final patch.  The two exceptions are instruction
  pointer-relative addressing modes, which must be re-encoded to still
  refer to the same data after moving the instruction, and control
  flow transfer instructions, which are discussed in the next section.
\end{itemize}

The result of partially evaluating the nodes in the extended \gls{cfg}
is a set of fragments of machine code which can be stitched together
to form the new patch.

\section{Control flow instructions}

Most of the program's original instructions are copied into the patch
verbatim as part of the \textbf{Emul} phase.  The main exceptions are
control flow instructions, which set the instruction pointer to some
other value.  If these were included verbatim in the patch then
{\implementation} would lose control of the program's execution, with
undesirable results.  For the AMD64 architecture, there are three main
types of control flow instructions: direct jumps, direct calls, and
indirect transfers.  I consider each in turn.

\subsection{Direct jumps}

Direct jump instructions set the current instruction pointer to a
constant value.  In the interpreter, they just have the effect of
updating the $\mathit{active}$ set to reflect the thread's new
potential locations in the dynamic \gls{cfg}.  Since the target of the
branch is a constant, precisely the same approach can be taken in the
compiler, except that in this case updating the $\mathit{active}$
means emitting a \texttt{jmp} instruction to the appropriate
\textsc{InterpreterState}.

\subsection{Direct call instructions}

A direct call instruction is used to call a function when the address
of the function is known at compile time.  Their effect is to push the
current instruction pointer on the stack and to then set the current
instruction pointer to a given target value.  {\Implementation}'s
behaviour here depends on the function which is to be called.

\texttt{Call}s to functions in the program itself are the easiest to
handle.  The simplest case is when the called function itself needs to
be protected.  These can be handled by converting the \texttt{call}
instruction into a \texttt{push} instruction, pushing the return
address on the stack, followed by a \texttt{jmp} instruction which
branches to the part of the patch which implements the called
function.  Alternatively, it might be that the called function does
not need to be protected.  In that case, the lock, if held, should be
released and control transferred back to the original program.

\texttt{Call}s to library functions, such as \texttt{malloc} or
\texttt{printf}, require more care.  The main analysis phase of
       {\technique} treats library functions as if they were a special
       kind of instruction (see
       \autoref{sect:derive:library_functions}), with the result
       that the \gls{cfg} to be protected will sometimes include calls
       to library functions even when the definitions of those library
       functions are unavailable.  The fix generation process has two
       options for handling them, both bad:

\begin{itemize}
\item It could call into the library function whilst holding the lock.
  This ensures that the desired atomic blocks behave atomically, but
  at the cost of a significant risk of deadlocks if the called
  function is something like \texttt{pthread\_mutex\_lock}.
\item It could release the lock while calling into the library
  function.  This is much less likely to deadlock, but also much
  less likely to correctly eliminate the bug.
\end{itemize}

{\Implementation} always chooses to hold the lock when calling library
functions from a patch, mitigating the damage from deadlocks by
applying a timeout whenever it acquires the patch lock.  These timeout
might themselves lead to incomplete protection, but generally happen
less frequently than library calls, and so present a less severe
problem.  Note that library calls are not the only possible cause of
deadlocks here, as the program might implement its own synchronisation
primitives\cite{Jannesari2010}, and so the timeout would still be
necessary even if the patch lock were dropped during library calls.

\subsection{Indirect control-flow transfer instructions}

Indirect control-flow transfer instructions are those which set the
instruction pointer to a calculated value; this includes indirect
jumps, indirect calls, and return instructions.  They are difficult to
handle in the compiler as the target is not available at compile time.
The compiler must ensure that it generates code for every state which
might be reached, along with appropriate branches to activate that
code at appropriate times.

There are three cases which need to be considered\footnote{I assume
  here that the instruction is an indirect jump; generalising to
  indirect calls and return instructions is straightforward.
  \todo{That is a lie; it's not straightforward, it's just really
    fiddly and gory and I don't want to talk about it.}}:

\begin{itemize}
\item There might be an edge in the \gls{cfg} corresponding to the
  branch.  In that case, the patch must branch to the target of the
  jump without releasing the lock.
\item There might not be any such edge, indicating that the lock
  should be released, but the instruction might be in the
  $\mathit{Cont}$ set, so the patch cannot jump directly back to the
  program's original code.
\item The target might not be in either the fragment to be protected
  or in $\mathit{Cont}$, in which case the patch should release the
  lock and return to the program's original code.
\end{itemize}

Fortunately, the set of targets which fit into the first two cases is
finite, easily determined at compile time, and usually small, and so
the compiler can simply generate appropriate code fragments for each
of them.  It is then easy to emit a series of conditional branches
which select the appropriate fragment at run time, or perform a simple
indirect jump which returns to the original program if none of them
match\footnote{There is a slight complication here that the
  calculation of the target address might involve a load from memory,
  and hence might suffer a race, and the compiler must be careful not
  to drop the lock prematurely if that happens.  {\Implementation}'s
  patches correctly avoid this issue.}.
